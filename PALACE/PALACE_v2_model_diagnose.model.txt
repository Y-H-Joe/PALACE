smi_encoder.embedding.weight shape: torch.Size([166, 64])
tensor([[ 1.0131, -0.2699, -1.8087,  ...,  0.9555,  1.4440,  0.4578],
        [-0.8163,  0.5424, -1.4801,  ..., -0.3295, -0.7485, -1.9519],
        [ 0.0252,  0.2658,  0.8077,  ...,  0.3764, -2.3035,  1.3408],
        ...,
        [ 0.4416,  0.4689,  0.8651,  ...,  0.0217,  0.1627,  1.3577],
        [-0.3841, -0.9819, -2.5312,  ...,  1.4526, -0.4719, -0.4409],
        [-0.0962, -0.0663, -0.2366,  ..., -0.4563,  0.6916, -0.1244]])
tensor([[ 1.0131, -0.2699, -1.8087,  ...,  0.9555,  1.4440,  0.4578],
        [-0.8111,  0.5380, -1.4588,  ..., -0.3259, -0.7482, -1.9483],
        [ 0.0252,  0.2658,  0.8077,  ...,  0.3764, -2.3035,  1.3408],
        ...,
        [ 0.4416,  0.4689,  0.8651,  ...,  0.0217,  0.1627,  1.3577],
        [-0.3841, -0.9819, -2.5312,  ...,  1.4526, -0.4719, -0.4409],
        [-0.0962, -0.0663, -0.2366,  ..., -0.4563,  0.6916, -0.1244]])
##########################################################
smi_encoder.encoder.layers.0.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.0358, -0.0733,  0.0426,  ..., -0.0554, -0.1505,  0.0886],
        [-0.1389, -0.0028, -0.0981,  ..., -0.1081, -0.0789,  0.1082],
        [-0.0739,  0.0640,  0.0730,  ...,  0.0664, -0.0450, -0.1453],
        ...,
        [-0.1419,  0.0214, -0.0171,  ..., -0.0403,  0.0725, -0.1000],
        [ 0.0373, -0.0542,  0.0393,  ...,  0.0492,  0.1418, -0.0834],
        [ 0.0776, -0.0937, -0.1047,  ..., -0.0646, -0.0834,  0.0258]])
tensor([[-0.0263, -0.0844,  0.0569,  ..., -0.0409, -0.1573,  0.0827],
        [-0.1246, -0.0331, -0.1031,  ..., -0.0922, -0.0803,  0.1127],
        [-0.0775,  0.0451,  0.0705,  ...,  0.1095, -0.0644, -0.1272],
        ...,
        [-0.1551,  0.0256, -0.0315,  ..., -0.0299,  0.0788, -0.1075],
        [ 0.0232, -0.0613,  0.0463,  ...,  0.0723,  0.1448, -0.0849],
        [ 0.0782, -0.0579, -0.1030,  ..., -0.0716, -0.1025,  0.0269]])
##########################################################
smi_encoder.encoder.layers.0.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 3.8074e-03,  1.4843e-02, -2.7149e-03,  2.3283e-02,  2.3397e-02,
         2.3664e-02, -9.8092e-03, -3.0180e-02, -3.1502e-03,  6.0279e-04,
         1.5627e-02,  8.0858e-03, -7.6756e-03, -1.1886e-02,  1.4772e-02,
        -3.0635e-03, -1.5902e-02,  5.1806e-03, -1.3894e-02, -2.5654e-02,
        -2.0288e-02,  1.4273e-02, -2.2555e-02, -2.3998e-02,  1.7035e-02,
        -3.0818e-02,  3.7367e-03, -7.8864e-03,  1.0786e-03, -8.1846e-03,
        -2.3979e-02,  1.0981e-02, -5.2537e-03,  4.4471e-03, -7.5215e-03,
        -1.1307e-02,  4.4682e-03, -3.8492e-03, -6.8072e-03, -3.8167e-03,
         1.8293e-03,  1.3073e-02,  1.4241e-02,  9.1070e-03, -6.7513e-03,
        -5.4107e-03, -1.8472e-02, -1.6042e-02,  5.5963e-03, -1.0812e-03,
        -8.6071e-03,  6.2897e-03, -4.2690e-03,  1.3126e-02, -1.3606e-02,
        -3.1847e-03, -1.3477e-02,  1.3296e-02, -2.2508e-02, -1.7317e-02,
        -2.9796e-03,  6.9597e-04,  2.4955e-03,  1.2351e-02, -1.5114e-04,
        -1.6574e-04,  5.3750e-05, -4.3691e-05, -3.0308e-05,  3.1054e-05,
        -1.2401e-04, -2.3742e-05, -3.2773e-04,  1.2874e-04,  9.0340e-05,
        -6.9165e-05,  5.7841e-05,  2.9541e-04, -1.9990e-04, -8.2482e-05,
         1.2372e-04, -2.7775e-04,  1.6599e-04, -7.4865e-05,  3.0985e-04,
        -5.7029e-05, -1.5651e-04,  1.2979e-04,  6.2486e-05,  1.7962e-04,
        -4.2329e-05,  1.3492e-04,  2.1912e-05,  9.2447e-06,  1.7051e-04,
        -2.5819e-04, -1.7413e-04,  1.1749e-04, -1.5082e-04,  1.9056e-04,
        -2.6413e-04, -9.7896e-05, -4.5700e-04, -1.2588e-04,  6.8637e-05,
        -1.9694e-04, -4.3258e-05,  4.3565e-05, -2.2012e-04, -2.3933e-04,
         3.5412e-04,  2.0400e-04, -3.8162e-04,  4.9212e-04, -4.1620e-05,
        -2.7386e-04,  2.6949e-04,  7.0642e-05, -8.8504e-05,  1.7142e-04,
        -3.1567e-04,  1.1894e-05, -7.7343e-05, -1.2929e-05,  1.4992e-04,
        -3.4762e-05, -3.0639e-04,  9.3737e-05, -2.3694e-02, -7.7261e-03,
        -4.2057e-03, -1.0902e-02,  6.3359e-03,  4.7536e-03,  4.1768e-03,
         4.2277e-03,  3.1136e-02, -1.4909e-02, -2.6065e-03,  7.9424e-03,
         3.0849e-03,  1.8083e-03,  7.0088e-03,  9.1813e-04,  2.0354e-03,
        -1.3905e-02,  2.4240e-03, -8.7127e-03, -6.9330e-03, -3.8405e-03,
         1.0032e-02,  1.2509e-02, -2.3808e-03, -7.8078e-03, -4.4127e-03,
        -2.3730e-04,  6.8262e-03, -3.0664e-04,  8.1723e-03, -1.2874e-03,
        -1.1795e-03, -9.9131e-03, -7.6012e-03, -6.3989e-03,  4.9834e-04,
        -1.4598e-02,  5.3255e-03,  6.3706e-03, -5.2180e-03, -4.6757e-03,
        -2.6614e-03, -8.3254e-03, -4.4422e-03, -6.4067e-05,  2.0189e-04,
        -8.2424e-03,  1.2678e-04,  6.2551e-03,  1.5167e-02, -5.6487e-03,
        -7.4662e-04,  3.1819e-03, -7.3092e-03,  8.6610e-03, -2.2212e-03,
        -5.8089e-03,  3.1190e-03, -1.1793e-03, -6.1903e-03,  5.0575e-03,
        -3.1035e-03,  3.7878e-03])
##########################################################
smi_encoder.encoder.layers.0.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[ 0.0505,  0.0281, -0.0763,  ..., -0.1009, -0.0134, -0.0966],
        [ 0.0685, -0.1013,  0.0551,  ...,  0.0990,  0.0783,  0.0768],
        [ 0.0946,  0.0698, -0.1162,  ...,  0.0208, -0.0469, -0.1210],
        ...,
        [-0.0241, -0.0221, -0.0948,  ..., -0.0118, -0.0531, -0.0943],
        [-0.0603, -0.0441,  0.0700,  ..., -0.0913, -0.0121, -0.0685],
        [ 0.0983,  0.0556,  0.0573,  ..., -0.1142, -0.0500, -0.0667]])
tensor([[ 0.0682,  0.0629, -0.0334,  ..., -0.1218, -0.0180, -0.0780],
        [ 0.0510, -0.1013,  0.0476,  ...,  0.0976,  0.0696,  0.0786],
        [ 0.1105,  0.0576, -0.1423,  ...,  0.0382, -0.0418, -0.1345],
        ...,
        [-0.0109, -0.0381, -0.0462,  ..., -0.0283, -0.0521, -0.1026],
        [-0.0462, -0.0625,  0.0406,  ..., -0.1016,  0.0227, -0.0660],
        [ 0.1065,  0.0291,  0.0438,  ..., -0.1110, -0.0547, -0.0891]])
##########################################################
smi_encoder.encoder.layers.0.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-3.4464e-03, -1.2643e-04,  1.1387e-03,  3.1775e-04, -4.6490e-03,
        -4.5252e-03, -3.4370e-03,  2.8836e-03, -6.2974e-04, -5.6572e-03,
         1.9896e-02, -8.5126e-03, -1.2841e-02,  1.3576e-03,  2.2349e-03,
        -7.5203e-04,  4.5402e-05, -1.3123e-03, -6.0928e-03,  1.1930e-02,
         2.5496e-03,  5.9370e-04, -7.4619e-03,  1.0027e-02,  9.9082e-03,
        -1.8720e-03,  4.7750e-03,  1.0201e-02,  6.6196e-03, -4.9289e-03,
        -1.0138e-02,  3.7753e-03, -1.3018e-02, -2.5559e-03, -7.5073e-03,
        -4.5806e-03, -6.2135e-03,  6.2878e-03,  7.1362e-03, -1.0831e-02,
        -9.8582e-03, -1.8883e-02, -7.1854e-03,  1.4701e-04,  7.7168e-03,
         8.8430e-03, -1.2336e-02,  1.8918e-02, -3.0336e-03, -1.0438e-02,
        -4.0749e-03,  3.1063e-03,  5.4568e-03, -4.1076e-04,  1.0029e-02,
        -6.9878e-03, -1.5084e-02,  5.7234e-03,  1.0384e-02, -8.8528e-03,
         2.0969e-03,  1.0306e-02,  2.8678e-03,  5.6978e-03])
##########################################################
smi_encoder.encoder.layers.0.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0629, -0.1874, -0.0500,  ..., -0.1747,  0.2041,  0.2287],
        [ 0.1014,  0.0558,  0.0449,  ..., -0.0387, -0.0043,  0.2323],
        [-0.2040, -0.1949, -0.0781,  ..., -0.1111, -0.0464, -0.1064],
        ...,
        [-0.0152,  0.1600, -0.0234,  ...,  0.0683,  0.0351, -0.1645],
        [-0.1553, -0.0999, -0.1674,  ..., -0.1333, -0.0115,  0.0219],
        [ 0.2368, -0.1150,  0.0318,  ..., -0.1710, -0.0040, -0.0919]])
tensor([[-0.0832, -0.1736, -0.0343,  ..., -0.1461,  0.2268,  0.2523],
        [ 0.1217,  0.0663,  0.0676,  ..., -0.0466, -0.0149,  0.2487],
        [-0.1868, -0.1991, -0.0501,  ..., -0.0924, -0.0403, -0.0932],
        ...,
        [-0.0084,  0.1541, -0.0417,  ...,  0.0741,  0.0422, -0.1805],
        [-0.2113, -0.1067, -0.1538,  ..., -0.1085, -0.0315,  0.0287],
        [ 0.2247, -0.0965,  0.0273,  ..., -0.1755, -0.0408, -0.0979]])
##########################################################
smi_encoder.encoder.layers.0.linear1.bias shape: torch.Size([32])
tensor([ 0.0265,  0.0136, -0.0210,  0.0027, -0.0674, -0.1189, -0.0668, -0.0568,
         0.0029, -0.0659,  0.0457, -0.0814, -0.0737, -0.0350, -0.0698,  0.1224,
        -0.1128,  0.0504, -0.0740, -0.0980, -0.0536, -0.0131,  0.0313,  0.1215,
         0.0630,  0.0584, -0.0864, -0.0665,  0.0044,  0.0623, -0.0866,  0.1139])
tensor([ 0.0139,  0.0052, -0.0507, -0.0175, -0.0816, -0.1422, -0.0802, -0.0627,
         0.0005, -0.0894,  0.0413, -0.0891, -0.1015, -0.0329, -0.0808,  0.0996,
        -0.1016,  0.0240, -0.0715, -0.1013, -0.0565, -0.0217,  0.0065,  0.1070,
         0.0510,  0.0459, -0.0742, -0.0953, -0.0078,  0.0568, -0.0827,  0.1169])
##########################################################
smi_encoder.encoder.layers.0.linear2.weight shape: torch.Size([64, 32])
tensor([[-0.0811, -0.0650, -0.0338,  ..., -0.1505, -0.0433,  0.0562],
        [-0.1773,  0.2322,  0.1426,  ...,  0.0845,  0.1685, -0.0353],
        [ 0.0838,  0.2016, -0.1442,  ..., -0.0638,  0.0425,  0.2276],
        ...,
        [ 0.0009, -0.1881, -0.1897,  ...,  0.0075,  0.0792, -0.0749],
        [-0.0251,  0.1708,  0.0208,  ...,  0.1241,  0.0239,  0.2100],
        [ 0.0124, -0.1669, -0.1871,  ...,  0.0439,  0.1504, -0.0431]])
tensor([[-0.0848, -0.0887, -0.0370,  ..., -0.1515, -0.0697,  0.0498],
        [-0.1719,  0.2449,  0.1355,  ...,  0.0867,  0.1674, -0.0363],
        [ 0.0823,  0.1931, -0.1317,  ..., -0.0675,  0.0303,  0.2439],
        ...,
        [ 0.0216, -0.1948, -0.1833,  ...,  0.0108,  0.0964, -0.0714],
        [-0.0167,  0.1952,  0.0156,  ...,  0.1237,  0.0187,  0.2107],
        [ 0.0277, -0.1674, -0.1775,  ...,  0.0419,  0.1709, -0.0416]])
##########################################################
smi_encoder.encoder.layers.0.linear2.bias shape: torch.Size([64])
tensor([ 0.0875, -0.0321,  0.1277,  0.0822, -0.0944, -0.1434, -0.0990, -0.0041,
        -0.1743,  0.1611, -0.1640, -0.1156, -0.0205, -0.1404, -0.0378,  0.1105,
         0.1631,  0.0154, -0.1641, -0.1482,  0.1592, -0.1401, -0.1145,  0.0984,
        -0.1376, -0.1562, -0.1402,  0.0036, -0.0225,  0.1115,  0.0603, -0.1478,
         0.0907,  0.1302, -0.1054, -0.0769, -0.1333,  0.1158,  0.1605, -0.1397,
         0.1643, -0.0051,  0.1235, -0.0827, -0.0647,  0.1514,  0.1478,  0.1083,
         0.0950,  0.1503, -0.0010, -0.1094,  0.0350, -0.1165, -0.0464,  0.0679,
         0.0534, -0.0086, -0.0377, -0.1163,  0.0117, -0.1611, -0.0763,  0.0680])
tensor([ 0.0801, -0.0316,  0.1263,  0.0850, -0.1006, -0.1425, -0.1075,  0.0003,
        -0.1710,  0.1539, -0.1541, -0.1225, -0.0238, -0.1291, -0.0295,  0.0995,
         0.1656,  0.0096, -0.1596, -0.1329,  0.1582, -0.1380, -0.1253,  0.1077,
        -0.1394, -0.1594, -0.1384,  0.0095, -0.0155,  0.1066,  0.0530, -0.1438,
         0.0830,  0.1281, -0.1007, -0.0879, -0.1484,  0.1167,  0.1708, -0.1432,
         0.1572, -0.0095,  0.1181, -0.0791, -0.0560,  0.1532,  0.1497,  0.1196,
         0.0859,  0.1417, -0.0021, -0.1099,  0.0416, -0.1131, -0.0421,  0.0618,
         0.0490, -0.0088, -0.0217, -0.1305,  0.0149, -0.1498, -0.0751,  0.0752])
##########################################################
smi_encoder.encoder.layers.0.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0024, 0.9969, 0.9969, 1.0154, 0.9909, 1.0083, 1.0167, 0.9909, 0.9909,
        0.9750, 1.0003, 0.9876, 1.0100, 0.9992, 0.9904, 1.0014, 0.9963, 1.0122,
        1.0342, 0.9482, 0.9926, 1.0157, 0.9794, 0.9946, 0.9962, 1.0270, 0.9505,
        1.0167, 0.9845, 0.9932, 1.0048, 1.0066, 1.0127, 1.0360, 1.0240, 1.0054,
        0.9856, 1.0011, 0.9784, 1.0034, 0.9920, 1.0186, 1.0215, 1.0043, 1.0012,
        1.0013, 1.0003, 1.0022, 1.0198, 1.0096, 1.0060, 0.9903, 1.0037, 1.0223,
        1.0057, 1.0025, 0.9813, 0.9851, 0.9957, 0.9643, 1.0079, 1.0110, 0.9767,
        0.9950])
##########################################################
smi_encoder.encoder.layers.0.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0010,  0.0009,  0.0013,  0.0003, -0.0059, -0.0047, -0.0025,  0.0052,
         0.0008, -0.0054,  0.0196, -0.0081, -0.0136,  0.0047,  0.0032,  0.0014,
         0.0019, -0.0015, -0.0055,  0.0143,  0.0050,  0.0010, -0.0067,  0.0140,
         0.0127, -0.0022,  0.0044,  0.0126,  0.0069, -0.0031, -0.0090,  0.0049,
        -0.0137, -0.0040, -0.0032, -0.0025, -0.0056,  0.0068,  0.0067, -0.0068,
        -0.0098, -0.0171, -0.0076,  0.0008,  0.0075,  0.0108, -0.0136,  0.0195,
        -0.0011, -0.0097, -0.0043,  0.0038,  0.0066,  0.0005,  0.0103, -0.0048,
        -0.0150,  0.0088,  0.0111, -0.0089,  0.0033,  0.0127,  0.0036,  0.0067])
##########################################################
smi_encoder.encoder.layers.0.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0185, 1.0089, 1.0003, 1.0172, 0.9993, 1.0203, 1.0031, 0.9967, 0.9977,
        0.9876, 0.9949, 0.9941, 1.0074, 0.9873, 0.9913, 0.9918, 1.0115, 1.0149,
        1.0171, 0.9671, 1.0048, 1.0141, 0.9930, 1.0093, 0.9983, 1.0129, 0.9973,
        1.0127, 1.0274, 0.9903, 0.9989, 0.9942, 1.0116, 1.0192, 1.0384, 1.0091,
        0.9829, 1.0026, 0.9691, 1.0005, 1.0104, 1.0041, 1.0263, 0.9969, 1.0063,
        1.0002, 1.0106, 1.0146, 1.0167, 1.0046, 0.9942, 0.9909, 1.0008, 1.0353,
        1.0038, 1.0029, 1.0000, 0.9802, 0.9914, 0.9593, 1.0255, 1.0055, 0.9893,
        0.9912])
##########################################################
smi_encoder.encoder.layers.0.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0050, -0.0008, -0.0013, -0.0049, -0.0052,  0.0006, -0.0064,  0.0027,
        -0.0002, -0.0084,  0.0063, -0.0092,  0.0012,  0.0115,  0.0100, -0.0090,
         0.0073,  0.0024,  0.0067,  0.0142,  0.0002,  0.0036, -0.0087,  0.0115,
        -0.0052, -0.0063,  0.0023,  0.0042,  0.0037, -0.0048, -0.0052,  0.0050,
        -0.0091, -0.0021,  0.0052, -0.0129, -0.0150,  0.0005,  0.0072, -0.0029,
        -0.0098, -0.0009, -0.0021,  0.0065,  0.0043,  0.0035,  0.0025,  0.0092,
        -0.0122, -0.0048, -0.0026,  0.0004,  0.0013,  0.0014,  0.0010, -0.0076,
        -0.0059,  0.0013,  0.0091, -0.0140,  0.0013,  0.0112,  0.0006,  0.0091])
##########################################################
smi_encoder.encoder.layers.1.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.0358, -0.0733,  0.0426,  ..., -0.0554, -0.1505,  0.0886],
        [-0.1389, -0.0028, -0.0981,  ..., -0.1081, -0.0789,  0.1082],
        [-0.0739,  0.0640,  0.0730,  ...,  0.0664, -0.0450, -0.1453],
        ...,
        [-0.1419,  0.0214, -0.0171,  ..., -0.0403,  0.0725, -0.1000],
        [ 0.0373, -0.0542,  0.0393,  ...,  0.0492,  0.1418, -0.0834],
        [ 0.0776, -0.0937, -0.1047,  ..., -0.0646, -0.0834,  0.0258]])
tensor([[-0.0523, -0.0387,  0.0093,  ..., -0.1012, -0.1342,  0.0621],
        [-0.1664,  0.0021, -0.1228,  ..., -0.1000, -0.0806,  0.0953],
        [-0.1037,  0.0908,  0.0712,  ...,  0.0643, -0.0284, -0.1702],
        ...,
        [-0.1357,  0.0339,  0.0170,  ..., -0.0411,  0.0669, -0.0950],
        [ 0.0415, -0.0512,  0.0361,  ...,  0.0468,  0.1322, -0.0858],
        [ 0.1123, -0.0989, -0.1041,  ..., -0.0683, -0.0867,  0.0334]])
##########################################################
smi_encoder.encoder.layers.1.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 3.4929e-02,  3.8288e-04,  1.9931e-02,  2.4545e-02, -2.6188e-02,
        -2.2537e-02, -2.0154e-02, -7.0494e-03, -2.0645e-02,  7.5009e-03,
         2.1472e-02,  1.6906e-02, -2.4987e-02,  2.5018e-02,  3.3027e-02,
         8.2981e-03, -7.5097e-03,  3.5743e-04, -2.6355e-02,  2.3378e-02,
        -5.7228e-03,  1.2296e-02,  1.7181e-02,  2.7116e-02, -1.0658e-02,
        -3.3373e-02,  2.3549e-02, -3.6818e-02, -1.2673e-02, -4.6015e-03,
         1.8235e-02,  5.8187e-03,  1.4914e-02, -5.2314e-03,  3.6605e-03,
        -1.4060e-02, -2.2910e-02,  1.5208e-02,  2.4913e-02, -3.7551e-02,
         7.0294e-03, -2.7677e-02,  3.8207e-02, -2.1595e-02, -3.8149e-02,
         2.3609e-02,  2.0861e-03, -1.1302e-02, -2.4376e-02,  2.3844e-02,
         2.5590e-02,  1.5542e-02, -2.1349e-02,  4.6007e-02,  9.0489e-03,
        -1.2688e-02, -2.4601e-02, -3.4304e-02,  1.1582e-02,  3.6068e-02,
        -2.9501e-02, -2.8057e-02,  9.7104e-03, -8.8632e-03, -2.7099e-05,
        -4.1165e-05, -7.5375e-06, -2.2206e-05, -6.7636e-05,  6.9269e-05,
         7.7121e-06, -2.0585e-05, -1.7980e-06,  1.5256e-05,  1.1486e-05,
        -2.7787e-05, -4.9477e-05, -1.1358e-05,  1.9740e-05,  2.9036e-05,
        -1.3900e-05, -1.5982e-05,  2.1376e-05, -3.9245e-06, -4.6141e-06,
         1.0233e-05,  8.1196e-06,  2.6265e-05,  1.8345e-05,  1.2139e-05,
        -3.1268e-05, -2.2778e-05,  5.0515e-05,  6.1630e-06,  1.0978e-05,
        -5.7720e-05, -2.0568e-05,  2.8011e-05,  2.6736e-05,  5.6927e-05,
        -1.2550e-05, -3.3936e-05, -9.2628e-06, -2.5199e-06, -1.9892e-05,
        -1.2532e-05, -5.9102e-05,  3.1037e-05, -3.7549e-05, -3.9637e-05,
         5.4425e-05,  5.0857e-05, -2.8439e-05, -1.0001e-05, -3.8066e-05,
        -1.8098e-06,  3.1485e-05, -2.9828e-05, -2.3987e-05, -7.0371e-05,
        -4.8032e-05,  4.7543e-05,  2.5416e-05, -4.0038e-05, -5.8772e-05,
         8.7828e-06,  7.6774e-06, -9.5431e-05,  1.2672e-04, -3.8916e-03,
        -2.5374e-03,  3.2603e-03, -6.1791e-03, -6.9886e-04,  1.0931e-02,
         8.9342e-03,  1.8153e-02, -1.1250e-02,  2.6316e-03, -4.8838e-03,
         1.8676e-03,  7.9977e-04,  1.0803e-02, -4.4149e-03,  8.8967e-03,
        -1.6275e-03,  5.9818e-03, -1.2945e-02, -6.5496e-03, -4.5904e-03,
         2.4472e-03,  7.3579e-03, -2.9021e-03, -6.4780e-03, -1.2546e-04,
         4.5303e-03, -8.2209e-04,  5.8915e-03,  1.0421e-03, -7.4292e-03,
         1.1130e-02, -4.6833e-03, -8.1037e-04, -3.7702e-05, -2.6143e-03,
         6.9058e-03, -7.2659e-03,  7.7958e-03, -6.8331e-03,  1.7147e-03,
        -1.6823e-04, -7.4091e-03, -2.5515e-03,  1.3499e-02, -5.1356e-03,
        -1.0133e-03,  7.3448e-04,  7.0225e-03,  2.4526e-03, -9.5837e-03,
        -6.8716e-03, -1.7614e-03,  1.4334e-03,  1.5797e-02,  1.4950e-03,
         1.7342e-03, -1.0156e-03, -1.8081e-03,  2.8396e-03, -8.8738e-03,
        -2.8566e-03, -7.3240e-03])
##########################################################
smi_encoder.encoder.layers.1.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[ 0.0505,  0.0281, -0.0763,  ..., -0.1009, -0.0134, -0.0966],
        [ 0.0685, -0.1013,  0.0551,  ...,  0.0990,  0.0783,  0.0768],
        [ 0.0946,  0.0698, -0.1162,  ...,  0.0208, -0.0469, -0.1210],
        ...,
        [-0.0241, -0.0221, -0.0948,  ..., -0.0118, -0.0531, -0.0943],
        [-0.0603, -0.0441,  0.0700,  ..., -0.0913, -0.0121, -0.0685],
        [ 0.0983,  0.0556,  0.0573,  ..., -0.1142, -0.0500, -0.0667]])
tensor([[ 3.8765e-05,  1.6068e-02, -6.6027e-02,  ..., -9.8635e-02,
         -2.0868e-02, -1.1775e-01],
        [ 7.3708e-02, -1.0623e-01,  4.0605e-02,  ...,  9.5709e-02,
          6.1794e-02,  7.5230e-02],
        [ 1.1830e-01,  7.8892e-02, -8.7920e-02,  ...,  2.6857e-02,
         -3.8080e-02, -1.4976e-01],
        ...,
        [-1.8766e-02, -1.2284e-02, -6.9591e-02,  ..., -3.9290e-03,
         -2.5572e-02, -8.8219e-02],
        [-6.6362e-02, -4.5206e-02,  6.3307e-02,  ..., -8.6136e-02,
         -1.5502e-02, -7.8236e-02],
        [ 1.0514e-01,  6.7268e-02,  5.2746e-02,  ..., -1.0581e-01,
         -4.5454e-02, -4.5734e-02]])
##########################################################
smi_encoder.encoder.layers.1.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-4.4990e-03, -9.5689e-04, -3.0968e-04, -3.2414e-03, -6.3665e-03,
         4.4536e-03, -1.7852e-03,  4.1989e-03, -4.5042e-05, -7.7637e-03,
         5.3130e-03, -7.6930e-03, -2.0303e-03,  3.8840e-03,  3.0050e-03,
        -9.4427e-04,  5.2661e-03, -2.6046e-03,  6.5503e-03,  1.9571e-02,
        -2.1271e-03,  3.2023e-03,  2.1431e-03,  1.0173e-02,  3.5792e-04,
        -7.2158e-03, -7.0338e-04,  1.7092e-03,  4.2259e-03, -6.4425e-03,
        -3.0530e-03,  4.2224e-03, -1.0511e-02,  4.5543e-04,  7.8895e-03,
        -7.5475e-03, -1.4670e-02,  1.1883e-03,  8.2807e-03, -8.0941e-03,
        -7.0197e-03, -3.4734e-03, -4.4769e-03, -3.7472e-03,  2.0343e-03,
         2.9144e-03,  6.7868e-03,  4.9850e-03, -8.9260e-03, -5.5855e-03,
         2.2930e-03, -6.0295e-03, -1.6853e-03,  8.5152e-04,  1.8827e-03,
        -2.0860e-03, -4.2548e-03, -6.5978e-05,  7.3846e-03, -1.0058e-02,
         2.1444e-03,  1.0158e-02,  4.1841e-03,  6.8696e-03])
##########################################################
smi_encoder.encoder.layers.1.linear1.weight shape: torch.Size([32, 64])
tensor([[ 0.0585, -0.2243,  0.1562,  ...,  0.2398,  0.2475,  0.1085],
        [ 0.1208,  0.0746, -0.2384,  ...,  0.2495, -0.0146, -0.2008],
        [-0.1316, -0.0968, -0.1711,  ...,  0.1306, -0.1049, -0.1052],
        ...,
        [ 0.0308, -0.1636, -0.1909,  ...,  0.1323,  0.2367, -0.1243],
        [-0.0452,  0.1050, -0.2390,  ..., -0.0709, -0.0879,  0.1829],
        [ 0.0323,  0.0990, -0.2124,  ...,  0.2455, -0.1173, -0.1523]])
tensor([[ 0.0656, -0.2216,  0.1763,  ...,  0.2365,  0.2531,  0.1106],
        [ 0.1217,  0.0706, -0.2348,  ...,  0.2589, -0.0334, -0.2093],
        [-0.0933, -0.0864, -0.1426,  ...,  0.1501, -0.1256, -0.1090],
        ...,
        [ 0.0124, -0.1763, -0.1811,  ...,  0.1602,  0.2163, -0.1226],
        [-0.0364,  0.1171, -0.2539,  ..., -0.0910, -0.0951,  0.1570],
        [ 0.0325,  0.1034, -0.2203,  ...,  0.2348, -0.1172, -0.1561]])
##########################################################
smi_encoder.encoder.layers.1.linear1.bias shape: torch.Size([32])
tensor([ 0.0265,  0.0136, -0.0210,  0.0027, -0.0674, -0.1189, -0.0668, -0.0568,
         0.0029, -0.0659,  0.0457, -0.0814, -0.0737, -0.0350, -0.0698,  0.1224,
        -0.1128,  0.0504, -0.0740, -0.0980, -0.0536, -0.0131,  0.0313,  0.1215,
         0.0630,  0.0584, -0.0864, -0.0665,  0.0044,  0.0623, -0.0866,  0.1139])
tensor([ 0.0241,  0.0056, -0.0290, -0.0152, -0.1027, -0.1278, -0.0751, -0.0676,
        -0.0175, -0.0840,  0.0348, -0.0910, -0.0768, -0.0517, -0.0714,  0.1176,
        -0.1253,  0.0442, -0.0870, -0.0919, -0.0614, -0.0127,  0.0180,  0.1048,
         0.0502,  0.0502, -0.0919, -0.0708, -0.0232,  0.0488, -0.0856,  0.1086])
##########################################################
smi_encoder.encoder.layers.1.linear2.weight shape: torch.Size([64, 32])
tensor([[ 0.1376, -0.0985, -0.0170,  ...,  0.0971, -0.1493,  0.1500],
        [ 0.2238,  0.2483,  0.0581,  ..., -0.0127,  0.2287,  0.1502],
        [-0.0643, -0.2293, -0.0167,  ..., -0.0528, -0.2242, -0.2023],
        ...,
        [-0.1802, -0.0286, -0.1583,  ...,  0.1061, -0.1642,  0.2317],
        [-0.1587, -0.1862,  0.1481,  ..., -0.0105, -0.0729, -0.0471],
        [ 0.1902,  0.2258, -0.0356,  ..., -0.0505, -0.2215, -0.0887]])
tensor([[ 0.1422, -0.0886,  0.0005,  ...,  0.0970, -0.1447,  0.1358],
        [ 0.2125,  0.2740,  0.0426,  ..., -0.0162,  0.2477,  0.1398],
        [-0.0704, -0.2153, -0.0245,  ..., -0.0421, -0.2435, -0.2001],
        ...,
        [-0.1592, -0.0146, -0.1252,  ...,  0.1291, -0.1410,  0.2377],
        [-0.1421, -0.2160,  0.1100,  ..., -0.0130, -0.1006, -0.0569],
        [ 0.2048,  0.2479, -0.0049,  ..., -0.0530, -0.2182, -0.0648]])
##########################################################
smi_encoder.encoder.layers.1.linear2.bias shape: torch.Size([64])
tensor([ 0.0875, -0.0321,  0.1277,  0.0822, -0.0944, -0.1434, -0.0990, -0.0041,
        -0.1743,  0.1611, -0.1640, -0.1156, -0.0205, -0.1404, -0.0378,  0.1105,
         0.1631,  0.0154, -0.1641, -0.1482,  0.1592, -0.1401, -0.1145,  0.0984,
        -0.1376, -0.1562, -0.1402,  0.0036, -0.0225,  0.1115,  0.0603, -0.1478,
         0.0907,  0.1302, -0.1054, -0.0769, -0.1333,  0.1158,  0.1605, -0.1397,
         0.1643, -0.0051,  0.1235, -0.0827, -0.0647,  0.1514,  0.1478,  0.1083,
         0.0950,  0.1503, -0.0010, -0.1094,  0.0350, -0.1165, -0.0464,  0.0679,
         0.0534, -0.0086, -0.0377, -0.1163,  0.0117, -0.1611, -0.0763,  0.0680])
tensor([ 8.6545e-02, -3.0604e-02,  1.2391e-01,  7.3928e-02, -9.6313e-02,
        -1.4162e-01, -9.4277e-02, -8.1359e-06, -1.7069e-01,  1.5370e-01,
        -1.5627e-01, -1.1633e-01, -1.8170e-02, -1.4299e-01, -2.9019e-02,
         1.0311e-01,  1.7096e-01,  8.8570e-03, -1.5592e-01, -1.3622e-01,
         1.6130e-01, -1.3722e-01, -1.1263e-01,  1.0141e-01, -1.3803e-01,
        -1.5910e-01, -1.4196e-01,  1.2082e-03, -2.1468e-02,  9.3401e-02,
         5.5399e-02, -1.4220e-01,  8.3299e-02,  1.2109e-01, -9.4206e-02,
        -8.1441e-02, -1.4704e-01,  1.1557e-01,  1.6436e-01, -1.4412e-01,
         1.4913e-01, -1.1310e-02,  1.1880e-01, -8.3745e-02, -4.7670e-02,
         1.5718e-01,  1.5024e-01,  1.1114e-01,  9.1871e-02,  1.3686e-01,
         1.7382e-03, -1.1269e-01,  3.2553e-02, -1.1886e-01, -4.8259e-02,
         7.1270e-02,  4.8751e-02, -6.4800e-04, -3.9170e-02, -1.1688e-01,
         1.2172e-02, -1.4462e-01, -7.4132e-02,  7.1966e-02])
##########################################################
smi_encoder.encoder.layers.1.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0073, 1.0059, 1.0060, 1.0110, 0.9905, 1.0141, 1.0021, 0.9984, 0.9905,
        0.9839, 0.9881, 0.9891, 1.0010, 0.9945, 0.9850, 0.9995, 1.0037, 1.0184,
        1.0064, 0.9617, 1.0111, 1.0070, 0.9925, 1.0123, 0.9927, 0.9999, 1.0025,
        0.9967, 1.0213, 0.9891, 0.9989, 1.0027, 1.0083, 1.0207, 1.0150, 1.0043,
        0.9824, 0.9966, 0.9655, 1.0076, 1.0215, 0.9997, 1.0166, 1.0010, 1.0030,
        0.9884, 1.0033, 1.0134, 1.0049, 1.0107, 1.0013, 1.0061, 0.9962, 1.0197,
        1.0051, 1.0061, 1.0023, 0.9759, 0.9912, 0.9516, 1.0243, 1.0072, 0.9931,
        0.9908])
##########################################################
smi_encoder.encoder.layers.1.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-6.0534e-03, -1.0992e-03,  6.0952e-05, -5.0424e-03, -6.9547e-03,
         4.7373e-03, -9.7414e-04,  4.0783e-03, -3.2119e-06, -7.9754e-03,
         4.9733e-03, -8.4800e-03, -2.4759e-03,  5.3094e-03,  3.6730e-03,
        -1.5366e-03,  5.7048e-03, -2.7291e-03,  6.5703e-03,  2.1679e-02,
        -1.9781e-03,  3.0340e-03,  1.6826e-03,  1.0247e-02,  1.2316e-03,
        -6.5981e-03,  1.2375e-03,  1.3081e-03,  4.8363e-03, -6.0016e-03,
        -1.7382e-03,  3.9761e-03, -9.3676e-03,  1.6717e-03,  9.3556e-03,
        -6.4410e-03, -1.5964e-02,  1.2627e-03,  9.7098e-03, -8.3161e-03,
        -6.6454e-03, -2.2462e-03, -5.4583e-03, -3.0240e-03,  1.5274e-03,
         2.5664e-03,  7.0354e-03,  5.3943e-03, -9.0902e-03, -6.1252e-03,
         3.3507e-03, -7.0927e-03, -2.2123e-03,  5.4062e-04,  1.8593e-03,
        -2.2674e-03, -4.8688e-03, -2.9468e-04,  7.5954e-03, -1.0384e-02,
         2.3560e-03,  1.1442e-02,  5.9322e-03,  6.4375e-03])
##########################################################
smi_encoder.encoder.layers.1.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0178, 1.0172, 1.0007, 1.0153, 0.9988, 1.0148, 0.9936, 0.9938, 0.9963,
        0.9643, 0.9998, 0.9980, 0.9878, 1.0229, 0.9815, 0.9970, 1.0039, 1.0184,
        1.0093, 0.9771, 1.0284, 1.0196, 1.0226, 0.9907, 1.0000, 1.0135, 0.9865,
        1.0316, 1.0089, 0.9722, 0.9999, 0.9873, 0.9947, 1.0085, 0.9761, 1.0195,
        0.9968, 1.0002, 0.9854, 1.0185, 1.0048, 1.0121, 1.0235, 1.0140, 1.0012,
        0.9920, 1.0083, 1.0344, 1.0089, 0.9918, 1.0080, 1.0032, 0.9969, 1.0170,
        1.0175, 1.0157, 1.0137, 0.9773, 1.0129, 0.9725, 1.0373, 1.0018, 0.9881,
        1.0009])
##########################################################
smi_encoder.encoder.layers.1.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0015,  0.0006, -0.0049, -0.0102, -0.0009,  0.0011,  0.0033,  0.0029,
         0.0016, -0.0090,  0.0030, -0.0022,  0.0048, -0.0004,  0.0116, -0.0069,
         0.0103, -0.0017,  0.0069,  0.0103,  0.0055,  0.0018, -0.0014,  0.0051,
        -0.0063, -0.0064, -0.0010, -0.0031, -0.0010, -0.0157, -0.0007,  0.0056,
        -0.0092, -0.0095,  0.0095, -0.0038, -0.0136,  0.0004,  0.0017, -0.0036,
        -0.0118,  0.0004, -0.0011, -0.0011,  0.0156,  0.0035,  0.0015,  0.0012,
        -0.0036, -0.0069,  0.0005,  0.0002, -0.0039, -0.0008, -0.0030,  0.0012,
        -0.0069,  0.0067, -0.0066,  0.0012,  0.0012,  0.0153,  0.0003,  0.0042])
##########################################################
smi_encoder.encoder.layers.2.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.0358, -0.0733,  0.0426,  ..., -0.0554, -0.1505,  0.0886],
        [-0.1389, -0.0028, -0.0981,  ..., -0.1081, -0.0789,  0.1082],
        [-0.0739,  0.0640,  0.0730,  ...,  0.0664, -0.0450, -0.1453],
        ...,
        [-0.1419,  0.0214, -0.0171,  ..., -0.0403,  0.0725, -0.1000],
        [ 0.0373, -0.0542,  0.0393,  ...,  0.0492,  0.1418, -0.0834],
        [ 0.0776, -0.0937, -0.1047,  ..., -0.0646, -0.0834,  0.0258]])
tensor([[-0.0101, -0.1176,  0.0743,  ..., -0.0994, -0.1242,  0.0743],
        [-0.1088, -0.0332, -0.0880,  ..., -0.0894, -0.0539,  0.1303],
        [-0.1159,  0.0930,  0.0675,  ...,  0.0485, -0.0451, -0.1698],
        ...,
        [-0.1460,  0.0088, -0.0149,  ..., -0.0483,  0.0658, -0.0942],
        [ 0.0631, -0.0638,  0.0539,  ...,  0.0660,  0.1637, -0.0889],
        [ 0.0880, -0.0968, -0.0834,  ..., -0.0598, -0.0673,  0.0250]])
##########################################################
smi_encoder.encoder.layers.2.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 1.1031e-02, -1.1294e-02,  3.4725e-02,  3.7090e-02, -2.7095e-02,
        -2.3208e-02, -2.7226e-02, -1.2110e-02, -1.7164e-02,  2.2207e-02,
         3.6049e-04,  9.7690e-03, -3.0948e-02,  2.7208e-02,  3.8811e-02,
        -1.3176e-02,  8.0986e-04, -1.3025e-03, -1.0507e-02,  2.0720e-02,
         1.3941e-02,  9.0839e-03,  2.5299e-02,  3.0162e-02, -2.1830e-02,
        -1.3373e-02,  3.0031e-02, -2.1678e-02,  1.3446e-03, -6.9489e-04,
         9.5496e-05, -2.0458e-02,  2.4909e-02,  7.1545e-03, -1.9856e-03,
         1.1146e-02, -1.4377e-02,  9.8126e-04,  3.1870e-02, -3.1736e-02,
         8.5247e-03, -2.0674e-02,  2.6046e-02,  2.2808e-02, -2.9540e-02,
         1.0236e-02,  3.8257e-02, -2.4420e-02, -1.8741e-02,  1.3189e-02,
         3.9970e-03,  2.2311e-03,  5.3225e-03,  3.0607e-02, -9.5712e-03,
        -4.6648e-02, -1.6150e-02, -2.8274e-02,  1.2004e-02,  2.8023e-02,
        -2.6477e-02, -2.4813e-02,  1.0008e-03,  1.1175e-02, -2.7976e-05,
        -1.3778e-05, -1.6975e-05,  1.2863e-05, -1.3083e-05, -7.5357e-05,
        -2.2666e-05,  3.4142e-05, -1.9426e-05, -2.0815e-05, -7.8952e-06,
        -1.2876e-05, -5.2018e-05,  2.8454e-05,  1.7602e-05, -1.7867e-05,
         3.0650e-06, -9.6211e-06,  9.0849e-06, -6.0176e-05, -6.0714e-06,
         2.3891e-05,  1.7280e-05,  5.7461e-06, -2.5378e-05,  2.5981e-05,
         3.8148e-06, -4.9163e-06,  1.8939e-05, -1.5911e-05,  3.3436e-05,
        -3.5301e-05,  5.0601e-05,  2.3163e-05, -1.3717e-05,  5.0564e-06,
        -1.7162e-05,  5.2451e-05, -4.5893e-05,  1.2824e-05, -8.5193e-05,
        -8.4310e-05, -3.5233e-05, -2.2253e-05, -2.5422e-05,  2.4306e-05,
         8.1894e-06, -2.3463e-05, -4.5243e-05,  4.2109e-06, -1.0176e-05,
         1.6079e-05,  6.6234e-05,  8.0685e-06, -3.3154e-06,  2.5652e-05,
        -7.5116e-05, -3.6123e-05, -9.3360e-06,  1.5466e-05,  4.5221e-09,
         1.2998e-05, -2.2002e-05, -2.2158e-05,  5.2510e-03, -1.0287e-02,
        -8.3451e-03,  1.4451e-03,  1.1785e-04, -8.1091e-03,  2.8243e-03,
         4.2468e-03,  5.0437e-03, -6.7008e-03, -1.3494e-04, -1.4896e-02,
        -1.0163e-02,  3.0081e-03,  6.3017e-03,  1.7613e-03,  1.1233e-02,
        -4.9748e-03, -2.7570e-03, -7.2021e-03,  3.2684e-03, -1.0033e-02,
         1.2423e-03,  6.2433e-05,  7.9409e-03, -4.5783e-03, -9.1553e-03,
         6.0878e-03, -2.7935e-03,  1.1105e-02,  1.6155e-03, -6.7104e-03,
         6.0530e-03,  3.2052e-03, -1.0770e-02, -1.9918e-03, -8.1498e-04,
         2.3960e-03,  4.4301e-03,  8.2532e-03, -6.1571e-03, -2.9410e-03,
         8.1876e-03, -5.2936e-03,  2.9500e-03,  9.9713e-03, -7.0618e-04,
        -1.7686e-03,  5.1665e-03,  3.1130e-03, -4.6555e-03, -8.0799e-03,
        -1.1112e-02, -1.6790e-04, -5.8255e-05,  1.3373e-02,  9.3918e-03,
        -3.4229e-03, -8.1847e-03, -4.4532e-03, -1.5251e-03, -9.0110e-03,
        -4.4319e-03,  5.8643e-04])
##########################################################
smi_encoder.encoder.layers.2.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[ 0.0505,  0.0281, -0.0763,  ..., -0.1009, -0.0134, -0.0966],
        [ 0.0685, -0.1013,  0.0551,  ...,  0.0990,  0.0783,  0.0768],
        [ 0.0946,  0.0698, -0.1162,  ...,  0.0208, -0.0469, -0.1210],
        ...,
        [-0.0241, -0.0221, -0.0948,  ..., -0.0118, -0.0531, -0.0943],
        [-0.0603, -0.0441,  0.0700,  ..., -0.0913, -0.0121, -0.0685],
        [ 0.0983,  0.0556,  0.0573,  ..., -0.1142, -0.0500, -0.0667]])
tensor([[ 0.0270,  0.0360, -0.0936,  ..., -0.1002, -0.0278, -0.0866],
        [ 0.0565, -0.0959,  0.0625,  ...,  0.0974,  0.0678,  0.0776],
        [ 0.0919,  0.0733, -0.0995,  ...,  0.0145, -0.0257, -0.1425],
        ...,
        [-0.0286, -0.0158, -0.0773,  ..., -0.0160, -0.0476, -0.0763],
        [-0.0448, -0.0487,  0.0464,  ..., -0.0891, -0.0062, -0.0766],
        [ 0.0796,  0.0583,  0.0630,  ..., -0.1132, -0.0544, -0.0721]])
##########################################################
smi_encoder.encoder.layers.2.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-9.4408e-04,  1.0102e-03, -7.3820e-03, -3.1567e-03, -5.0523e-03,
         3.2935e-03,  7.8865e-03,  2.9381e-03, -6.4574e-04, -1.9758e-03,
         1.5713e-03, -1.4714e-03,  6.6728e-04, -4.0479e-03,  5.7934e-03,
         1.8462e-03,  3.3172e-03, -1.2914e-02,  7.5990e-03,  9.8235e-03,
         1.6213e-03,  1.5538e-03,  1.9027e-03,  5.1611e-03, -1.8547e-03,
        -3.9354e-03, -6.7253e-03, -4.4896e-03,  1.8972e-03, -1.3799e-02,
         2.1384e-03,  1.1204e-02, -1.1208e-02, -7.9345e-03,  1.3615e-02,
         5.0241e-03, -1.4559e-02,  4.5688e-04,  3.4178e-03, -3.7412e-03,
        -6.0972e-03,  3.7657e-03,  9.5029e-05, -2.7728e-03,  5.4849e-03,
        -1.9004e-03,  3.8116e-03,  9.2515e-04, -1.8867e-03, -7.9491e-03,
         7.8864e-03, -5.9444e-03, -1.7273e-03, -1.5421e-03, -3.9367e-04,
         8.0132e-03, -6.0188e-03,  5.6577e-03, -8.8129e-03,  4.0555e-05,
         2.4256e-03,  1.2631e-02, -2.4551e-03, -2.2136e-03])
##########################################################
smi_encoder.encoder.layers.2.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0917,  0.1786,  0.1488,  ..., -0.1822, -0.2023,  0.1424],
        [ 0.2117,  0.0578, -0.1329,  ...,  0.2452,  0.1023,  0.1713],
        [ 0.2236, -0.1299,  0.1969,  ..., -0.0936, -0.1537, -0.1491],
        ...,
        [ 0.1789,  0.0421, -0.1572,  ..., -0.0209,  0.1040, -0.1289],
        [-0.0367, -0.0098, -0.1794,  ...,  0.1616,  0.0448,  0.0845],
        [ 0.0516,  0.1475, -0.2289,  ..., -0.0570, -0.1611, -0.2117]])
tensor([[-0.1168,  0.1587,  0.1593,  ..., -0.1771, -0.2132,  0.1430],
        [ 0.2213,  0.0313, -0.1245,  ...,  0.2617,  0.0429,  0.1858],
        [ 0.1970, -0.1483,  0.2302,  ..., -0.0782, -0.1437, -0.1443],
        ...,
        [ 0.1737,  0.0290, -0.1602,  ..., -0.0268,  0.0567, -0.1231],
        [-0.0005, -0.0147, -0.1718,  ...,  0.2207,  0.0462,  0.0773],
        [ 0.0979,  0.1511, -0.2374,  ..., -0.0759, -0.1693, -0.2106]])
##########################################################
smi_encoder.encoder.layers.2.linear1.bias shape: torch.Size([32])
tensor([ 0.0265,  0.0136, -0.0210,  0.0027, -0.0674, -0.1189, -0.0668, -0.0568,
         0.0029, -0.0659,  0.0457, -0.0814, -0.0737, -0.0350, -0.0698,  0.1224,
        -0.1128,  0.0504, -0.0740, -0.0980, -0.0536, -0.0131,  0.0313,  0.1215,
         0.0630,  0.0584, -0.0864, -0.0665,  0.0044,  0.0623, -0.0866,  0.1139])
tensor([ 0.0043, -0.0072, -0.0295,  0.0036, -0.0732, -0.1361, -0.0699, -0.0583,
        -0.0042, -0.0750,  0.0358, -0.0962, -0.0875, -0.0560, -0.0800,  0.1018,
        -0.1300,  0.0437, -0.0787, -0.0984, -0.0594, -0.0384,  0.0213,  0.1271,
         0.0652,  0.0268, -0.0762, -0.0761, -0.0045,  0.0478, -0.0899,  0.0979])
##########################################################
smi_encoder.encoder.layers.2.linear2.weight shape: torch.Size([64, 32])
tensor([[ 0.0410,  0.2472,  0.2103,  ..., -0.0078,  0.0164, -0.1022],
        [-0.2384, -0.0099, -0.1419,  ..., -0.0011,  0.0280, -0.0318],
        [ 0.2215, -0.0899,  0.0076,  ..., -0.0364,  0.1213,  0.2131],
        ...,
        [ 0.1376,  0.0674,  0.0880,  ..., -0.0924, -0.0733, -0.1851],
        [-0.2384,  0.0703, -0.0787,  ..., -0.2042, -0.1702,  0.1703],
        [ 0.1602,  0.1914,  0.1005,  ...,  0.1032,  0.1519, -0.2475]])
tensor([[ 0.0081,  0.1997,  0.2139,  ..., -0.0113,  0.0575, -0.0987],
        [-0.2001,  0.0182, -0.1458,  ...,  0.0325,  0.0382, -0.0280],
        [ 0.2131, -0.0880, -0.0052,  ..., -0.0685,  0.0790,  0.2171],
        ...,
        [ 0.1314,  0.1049,  0.0810,  ..., -0.0785, -0.0590, -0.1737],
        [-0.2275,  0.0306, -0.0698,  ..., -0.2331, -0.2278,  0.1654],
        [ 0.1705,  0.1857,  0.1244,  ...,  0.1027,  0.1577, -0.2546]])
##########################################################
smi_encoder.encoder.layers.2.linear2.bias shape: torch.Size([64])
tensor([ 0.0875, -0.0321,  0.1277,  0.0822, -0.0944, -0.1434, -0.0990, -0.0041,
        -0.1743,  0.1611, -0.1640, -0.1156, -0.0205, -0.1404, -0.0378,  0.1105,
         0.1631,  0.0154, -0.1641, -0.1482,  0.1592, -0.1401, -0.1145,  0.0984,
        -0.1376, -0.1562, -0.1402,  0.0036, -0.0225,  0.1115,  0.0603, -0.1478,
         0.0907,  0.1302, -0.1054, -0.0769, -0.1333,  0.1158,  0.1605, -0.1397,
         0.1643, -0.0051,  0.1235, -0.0827, -0.0647,  0.1514,  0.1478,  0.1083,
         0.0950,  0.1503, -0.0010, -0.1094,  0.0350, -0.1165, -0.0464,  0.0679,
         0.0534, -0.0086, -0.0377, -0.1163,  0.0117, -0.1611, -0.0763,  0.0680])
tensor([ 0.0820, -0.0212,  0.1162,  0.0814, -0.0933, -0.1400, -0.0832, -0.0063,
        -0.1696,  0.1491, -0.1578, -0.1179, -0.0204, -0.1445, -0.0302,  0.1109,
         0.1575,  0.0027, -0.1567, -0.1469,  0.1630, -0.1420, -0.1197,  0.0949,
        -0.1419, -0.1583, -0.1355, -0.0061, -0.0213,  0.0901,  0.0645, -0.1362,
         0.0810,  0.1293, -0.0930, -0.0700, -0.1404,  0.1081,  0.1665, -0.1374,
         0.1708, -0.0022,  0.1254, -0.0861, -0.0712,  0.1451,  0.1586,  0.1118,
         0.0923,  0.1409,  0.0026, -0.1197,  0.0315, -0.1172, -0.0412,  0.0740,
         0.0453,  0.0030, -0.0355, -0.1161,  0.0115, -0.1467, -0.0832,  0.0609])
##########################################################
smi_encoder.encoder.layers.2.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9918, 1.0111, 1.0035, 1.0136, 0.9826, 1.0116, 0.9907, 0.9889, 0.9776,
        0.9497, 0.9978, 0.9945, 0.9875, 1.0130, 0.9826, 0.9969, 1.0137, 1.0211,
        1.0016, 0.9722, 1.0194, 1.0160, 0.9994, 0.9816, 1.0094, 1.0073, 0.9780,
        1.0101, 0.9984, 0.9693, 0.9903, 0.9765, 0.9920, 1.0134, 0.9452, 1.0318,
        1.0060, 0.9990, 0.9787, 1.0203, 1.0139, 1.0015, 1.0155, 1.0139, 1.0041,
        0.9965, 1.0042, 1.0381, 1.0146, 0.9862, 1.0193, 1.0160, 0.9820, 1.0043,
        1.0173, 1.0259, 0.9969, 0.9910, 1.0096, 0.9736, 1.0212, 0.9872, 0.9811,
        1.0055])
##########################################################
smi_encoder.encoder.layers.2.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-1.0006e-03,  9.6353e-04, -6.6869e-03, -3.8894e-03, -5.9253e-03,
         3.3397e-03,  8.1084e-03,  3.3761e-03, -3.7464e-04, -2.2191e-03,
         1.7962e-03, -1.0228e-03,  1.4533e-03, -3.7412e-03,  7.2336e-03,
         2.3488e-03,  2.8318e-03, -1.1747e-02,  7.4150e-03,  1.3719e-02,
         2.8373e-03,  5.5569e-04,  2.1632e-03,  4.1580e-03,  2.3670e-04,
        -4.7695e-03, -6.0164e-03, -4.4964e-03,  2.0103e-03, -1.4360e-02,
         2.5933e-03,  1.2418e-02, -1.0091e-02, -7.4668e-03,  1.3513e-02,
         7.4717e-03, -1.4499e-02,  3.9038e-04,  4.6787e-03, -2.8691e-03,
        -5.2604e-03,  3.9170e-03, -4.6551e-04, -3.3845e-03,  6.6415e-03,
        -1.6481e-03,  4.8408e-03,  1.5445e-03, -6.6465e-04, -6.7995e-03,
         8.0086e-03, -6.6093e-03, -2.1222e-03, -8.3178e-04,  1.1062e-03,
         9.2661e-03, -7.0937e-03,  4.8170e-03, -9.3842e-03,  8.9381e-05,
         3.8260e-03,  1.2945e-02, -8.1280e-04, -4.3025e-03])
##########################################################
smi_encoder.encoder.layers.2.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0074, 1.0262, 1.0376, 1.0194, 1.0059, 1.0468, 0.9841, 1.0194, 1.0160,
        0.9781, 1.0007, 1.0055, 1.0068, 0.9990, 0.9794, 0.9986, 1.0083, 1.0040,
        1.0113, 1.0189, 1.0282, 1.0304, 1.0126, 0.9939, 1.0110, 1.0270, 0.9850,
        1.0378, 1.0057, 0.9650, 0.9962, 0.9846, 0.9908, 1.0475, 1.0013, 1.0565,
        1.0358, 1.0179, 0.9933, 1.0264, 1.0418, 0.9994, 1.0045, 1.0183, 1.0257,
        0.9915, 1.0132, 1.0389, 1.0131, 0.9993, 0.9993, 1.0319, 0.9902, 1.0215,
        1.0209, 1.0048, 0.9856, 0.9878, 1.0119, 0.9927, 1.0147, 0.9946, 0.9806,
        1.0147])
##########################################################
smi_encoder.encoder.layers.2.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0032,  0.0067, -0.0154, -0.0021, -0.0031,  0.0034,  0.0080, -0.0011,
        -0.0060, -0.0069,  0.0038, -0.0055, -0.0017, -0.0046,  0.0046,  0.0018,
        -0.0032, -0.0073,  0.0050,  0.0012,  0.0075, -0.0019, -0.0042,  0.0015,
        -0.0079, -0.0130,  0.0015, -0.0082, -0.0020, -0.0200,  0.0087,  0.0086,
        -0.0082, -0.0034,  0.0118,  0.0005, -0.0067, -0.0022,  0.0066, -0.0002,
         0.0006,  0.0043,  0.0028, -0.0043, -0.0085, -0.0035,  0.0031,  0.0010,
        -0.0039, -0.0002,  0.0038, -0.0082, -0.0042,  0.0008, -0.0005,  0.0080,
        -0.0052,  0.0108, -0.0067,  0.0024,  0.0002,  0.0046, -0.0078, -0.0056])
##########################################################
prot_encoder.embedding.weight shape: torch.Size([166, 64])
tensor([[-0.2079,  1.0140, -1.1043,  ...,  0.4444, -0.8896, -0.6878],
        [ 0.5944, -0.8499, -1.1996,  ..., -0.7780,  0.6863,  0.0978],
        [-0.8942, -0.6882, -1.0023,  ..., -0.7508,  0.6727,  0.3388],
        ...,
        [ 0.1225,  0.1419, -0.5128,  ..., -0.0438, -0.7894,  0.9765],
        [-1.5060,  1.1782, -0.5882,  ...,  1.2845, -1.4379, -0.1962],
        [ 0.1942,  2.2988, -1.5137,  ..., -0.1487,  0.5204,  0.7415]])
tensor([[-0.2079,  1.0140, -1.1043,  ...,  0.4444, -0.8896, -0.6878],
        [ 0.5887, -0.8335, -1.1582,  ..., -0.7579,  0.6770,  0.0984],
        [-0.9755, -0.7374, -1.0162,  ..., -0.7992,  0.6695,  0.4136],
        ...,
        [ 0.1225,  0.1419, -0.5128,  ..., -0.0438, -0.7894,  0.9765],
        [-1.5060,  1.1782, -0.5882,  ...,  1.2845, -1.4379, -0.1962],
        [ 0.1942,  2.2988, -1.5137,  ..., -0.1487,  0.5204,  0.7415]])
##########################################################
prot_encoder.conv1d.weight shape: torch.Size([300, 2500, 1])
tensor([[[ 0.0097],
         [ 0.0026],
         [-0.0161],
         ...,
         [-0.0042],
         [-0.0103],
         [ 0.0064]],

        [[-0.0144],
         [ 0.0025],
         [-0.0161],
         ...,
         [-0.0115],
         [ 0.0027],
         [-0.0082]],

        [[-0.0025],
         [ 0.0139],
         [ 0.0075],
         ...,
         [ 0.0040],
         [ 0.0153],
         [-0.0021]],

        ...,

        [[-0.0130],
         [-0.0115],
         [-0.0116],
         ...,
         [ 0.0028],
         [-0.0157],
         [ 0.0150]],

        [[-0.0049],
         [-0.0036],
         [ 0.0031],
         ...,
         [-0.0008],
         [-0.0183],
         [ 0.0101]],

        [[-0.0162],
         [-0.0071],
         [-0.0026],
         ...,
         [ 0.0093],
         [-0.0123],
         [ 0.0028]]])
tensor([[[ 4.3574e-02],
         [-1.0405e-02],
         [ 2.1817e-03],
         ...,
         [-3.5254e-03],
         [-9.5743e-03],
         [ 7.1468e-03]],

        [[-4.5631e-02],
         [-5.1005e-02],
         [-1.6851e-02],
         ...,
         [-1.1959e-02],
         [ 2.1971e-03],
         [-8.6968e-03]],

        [[ 9.0026e-02],
         [-2.6073e-02],
         [ 4.8143e-03],
         ...,
         [ 3.2473e-03],
         [ 1.4561e-02],
         [-2.8617e-03]],

        ...,

        [[-9.3517e-03],
         [-9.1919e-03],
         [-7.7588e-02],
         ...,
         [ 8.3409e-04],
         [-1.7642e-02],
         [ 1.3037e-02]],

        [[ 1.1570e-02],
         [-1.8006e-02],
         [-2.7934e-03],
         ...,
         [-3.7880e-03],
         [-2.1339e-02],
         [ 7.1062e-03]],

        [[-1.5943e-02],
         [-1.8632e-02],
         [-6.1230e-02],
         ...,
         [ 6.4370e-03],
         [-1.5174e-02],
         [-6.1477e-05]]])
##########################################################
prot_encoder.conv1d.bias shape: torch.Size([300])
tensor([ 1.0961e-02, -7.5747e-03,  7.3613e-03, -2.2572e-03, -8.4273e-03,
         4.4395e-03, -2.8804e-03,  1.6813e-02,  1.1970e-02, -1.6178e-03,
        -2.0583e-03,  6.2757e-03, -1.7893e-04,  8.4382e-04, -1.0739e-02,
        -1.9431e-03,  5.9090e-03, -1.2069e-02, -2.8860e-05, -1.3425e-02,
         7.1548e-03, -8.3632e-03, -7.4330e-03, -1.3029e-02,  5.0159e-03,
        -1.8247e-02, -1.4689e-02,  7.9698e-03,  6.6907e-03, -1.2383e-02,
         3.4365e-03,  1.0109e-02,  4.4672e-04, -1.3195e-02,  1.1583e-02,
        -1.5830e-02,  1.6885e-02, -5.1676e-03, -1.6724e-02, -1.8946e-02,
         5.2629e-03, -1.2744e-02, -1.8056e-02, -1.6513e-02, -1.1116e-02,
         1.7251e-02,  1.8417e-02, -1.7480e-02, -6.8700e-03, -1.3795e-03,
        -2.5110e-03, -5.7480e-03, -4.6329e-03, -1.1653e-02, -1.3035e-02,
         1.7637e-02,  9.8439e-03,  3.1917e-03, -1.9543e-02,  1.8379e-03,
         1.7382e-02, -1.4812e-02, -3.9300e-03, -1.8352e-03, -1.0687e-02,
        -1.8960e-02,  1.2747e-02,  1.5117e-02,  1.6851e-02,  1.0688e-02,
        -9.5431e-03, -1.9151e-02,  2.9464e-03, -1.8798e-02, -1.9325e-02,
        -1.5714e-02,  1.3938e-02, -1.1052e-02,  1.6370e-02,  1.5875e-02,
        -1.5697e-02, -4.4388e-04,  1.2565e-02,  1.1108e-03,  2.9912e-03,
         1.8536e-02,  6.8040e-03, -4.1048e-03, -1.4411e-02, -1.6853e-02,
         8.9830e-03,  3.6016e-04,  5.9036e-03, -7.1900e-03,  1.2840e-02,
         8.7241e-03,  1.2855e-02,  1.9170e-02,  8.3106e-03,  8.5479e-03,
        -6.8038e-03,  1.8935e-02,  6.7809e-03,  4.9791e-03,  1.8474e-02,
         7.4845e-03,  1.9502e-02, -1.2514e-02,  1.4216e-02,  1.9550e-02,
         1.9992e-02,  1.2611e-02,  1.6451e-02,  2.5133e-03, -1.7608e-02,
        -3.4263e-05,  1.2212e-02, -9.0141e-03,  1.5364e-02,  8.8909e-03,
        -4.6087e-03,  5.5145e-03, -1.6808e-02, -3.5716e-03,  1.6538e-03,
         1.2274e-03, -3.2945e-03, -1.5686e-02,  7.5597e-03,  1.0298e-02,
        -1.9714e-02, -1.1587e-02,  4.2300e-03,  1.4370e-03,  7.3165e-03,
         9.9657e-03, -1.4422e-02, -5.4513e-04,  1.7000e-02, -5.0991e-03,
        -1.6097e-02,  1.3398e-02, -1.0319e-02, -1.8265e-02, -1.1097e-02,
        -9.0814e-03,  5.9715e-03,  7.4692e-03, -1.0800e-02, -4.9538e-04,
         7.3065e-03, -5.2214e-03, -1.5973e-02, -1.4612e-02, -3.3473e-03,
         1.3796e-02, -1.6023e-02,  1.2934e-02,  1.9798e-03,  1.9799e-02,
         9.1178e-03,  4.1071e-03,  1.7145e-02, -8.3218e-03,  1.4828e-02,
        -2.3501e-05, -1.0953e-04, -5.1037e-03, -8.8331e-03,  5.7234e-03,
         2.5301e-03, -1.2660e-02,  5.5907e-03, -7.6805e-03,  5.8608e-03,
         1.0602e-02,  1.4493e-02, -1.7100e-02,  8.2846e-03, -1.5922e-02,
        -4.0986e-03,  1.5250e-02, -3.0811e-03,  3.3764e-03, -8.6462e-03,
        -1.8025e-02,  5.5926e-03,  3.7609e-03,  1.6353e-02, -1.8737e-02,
         1.2600e-02,  7.9202e-03,  1.3382e-02, -9.3638e-03, -5.3135e-03,
         1.0967e-02,  1.8299e-02, -7.1927e-04,  1.9987e-03, -1.4725e-02,
         8.3378e-03,  6.7156e-03, -1.4205e-03,  1.2489e-02, -1.7889e-02,
        -7.2779e-03, -1.7488e-02, -1.9053e-02,  8.3948e-03, -1.9040e-02,
        -1.0584e-02, -1.4330e-02,  3.8289e-03,  1.9865e-02,  7.3359e-03,
        -7.3287e-03, -1.7226e-02, -1.3944e-02, -1.3557e-02,  2.2558e-03,
        -1.1533e-02,  1.6425e-02, -1.0494e-02, -1.6108e-02,  1.3135e-02,
        -5.1134e-03, -1.6952e-02,  1.7608e-02,  4.3901e-03,  1.6680e-02,
        -1.5012e-02, -9.4916e-03, -1.4688e-02,  1.8819e-02, -1.3662e-02,
        -6.9317e-03,  1.8186e-02,  1.1664e-02,  1.7445e-02, -1.3138e-03,
        -8.8247e-03, -1.8541e-02, -1.4953e-02, -1.9941e-02,  9.1550e-03,
        -1.7667e-02,  5.2482e-03,  1.9039e-02, -1.2785e-02,  1.8086e-03,
        -1.4849e-02,  9.3145e-03, -1.8662e-02, -8.1419e-03,  5.5324e-03,
        -1.4803e-02,  7.6802e-03, -1.9973e-03, -1.8181e-02, -1.6648e-02,
        -2.6304e-03,  1.9132e-02, -1.3153e-02, -1.8206e-02, -6.5931e-03,
         2.7980e-03, -1.6211e-02, -7.1995e-03, -1.1003e-02,  1.3669e-02,
         7.8916e-03, -4.5760e-03,  3.0578e-03, -1.8622e-02, -7.5748e-03,
         1.9561e-02,  1.2425e-02,  1.2728e-02,  3.1006e-03, -8.3535e-03,
         1.0689e-03,  2.3089e-03, -5.2326e-03,  1.3291e-02, -3.7479e-03,
        -1.3178e-02, -9.3191e-04,  1.5382e-02, -1.5782e-02, -2.7707e-03,
         1.8506e-02,  1.4497e-02,  1.5027e-02, -1.7805e-02, -2.6043e-03,
         1.7593e-02, -1.4326e-02, -1.4960e-02,  1.8117e-02,  4.0035e-03])
tensor([ 4.0934e-04, -1.9085e-02,  1.2417e-01,  1.1383e-01, -9.2404e-03,
         4.9727e-02,  7.7054e-02,  2.7254e-02,  7.5356e-02, -4.4732e-02,
         4.2797e-02,  6.5735e-02, -6.5375e-02,  8.5629e-02,  2.7563e-02,
         6.8754e-03, -4.6837e-02,  1.1219e-02, -2.3465e-02, -1.2156e-02,
         3.9355e-02,  1.6050e-02, -5.4639e-03, -2.8136e-02, -6.4836e-02,
         5.1285e-02, -1.7716e-02,  1.8307e-02,  6.3213e-02,  4.9455e-02,
         7.0462e-02,  3.4962e-02, -4.0513e-03, -1.0168e-02, -6.9421e-03,
        -9.3540e-03,  3.6651e-02, -3.3314e-02, -2.5830e-02, -9.1025e-02,
         3.8165e-02, -3.5058e-02, -1.7685e-02, -2.5252e-02, -1.6171e-02,
        -3.7409e-03,  6.0017e-02, -3.7096e-02,  3.9642e-02,  7.8102e-03,
         4.0388e-02, -7.8869e-02,  1.2614e-02,  2.1882e-02, -2.9313e-02,
        -3.9952e-02, -4.8497e-02,  9.3136e-03, -2.2340e-02, -4.3087e-02,
         2.6002e-02, -4.5347e-02,  1.1329e-02,  1.2578e-02, -4.4368e-02,
        -1.5840e-03,  3.4516e-02,  6.5090e-03,  3.6152e-02, -5.5425e-02,
        -2.4511e-02, -2.6974e-02,  7.8331e-04, -4.2528e-02, -1.6751e-03,
        -4.4936e-03,  1.4065e-02, -2.6828e-02,  2.8727e-02, -6.5572e-02,
        -5.4045e-03,  5.8458e-02,  4.0486e-02,  4.4800e-02,  5.1000e-02,
         5.2599e-02,  5.8671e-02,  7.1811e-02, -7.5873e-02,  2.6691e-02,
         1.2809e-02, -2.0369e-02,  1.8960e-02, -1.9971e-02,  1.2224e-02,
         1.8922e-03, -3.2135e-02,  3.9546e-02, -7.4253e-02,  6.9488e-02,
         2.6793e-02,  6.8928e-02, -4.2034e-03, -2.5633e-02,  5.7976e-02,
         7.7627e-03,  1.9894e-02, -2.9843e-02,  5.9911e-02,  7.1015e-02,
         4.0373e-02,  4.9178e-02,  5.0110e-02,  7.5877e-03,  9.6322e-03,
        -2.0804e-02, -6.1215e-02,  4.0001e-02,  6.1073e-02, -5.4080e-02,
         1.4122e-02,  8.2649e-02,  1.8467e-02,  6.4404e-03, -3.0715e-02,
         5.8666e-02, -1.5485e-02, -2.7536e-02,  6.7281e-02,  4.3017e-02,
        -6.3631e-02, -4.5059e-02,  2.3034e-02,  2.7201e-02,  5.1373e-02,
         3.6524e-02, -6.5278e-02,  2.8707e-02,  4.2495e-03,  4.1350e-02,
         2.7105e-02,  1.6348e-02, -8.8458e-03,  2.2919e-02,  1.9061e-03,
        -2.0070e-02,  1.9679e-02,  7.3287e-03,  9.5890e-03, -2.4317e-02,
         3.9361e-02, -7.0801e-03, -2.3082e-02,  3.5358e-03, -3.0093e-02,
         5.9976e-03, -2.0418e-02,  3.2936e-02, -1.3587e-03,  6.9935e-02,
        -1.9317e-02,  8.4875e-04,  4.2229e-02,  1.1875e-02,  2.1758e-02,
        -2.9823e-02,  3.8201e-02,  1.0894e-02, -1.0099e-02,  5.7185e-02,
         1.5259e-02, -3.3422e-02,  4.6423e-02, -5.1457e-02, -4.0334e-02,
         4.0277e-02,  1.0690e-02, -1.5224e-02,  1.2565e-02,  1.5378e-02,
        -3.1322e-02,  3.7481e-02, -2.4211e-02, -2.3104e-03,  3.7018e-03,
        -3.3398e-02, -1.4092e-02,  2.1102e-02, -4.4780e-02, -3.9673e-02,
        -7.2094e-03, -1.6028e-02, -2.6486e-02, -3.0394e-02, -2.8096e-02,
         1.2312e-02,  2.5035e-03, -6.5973e-03, -1.0676e-02, -2.4602e-02,
        -1.3963e-02, -2.5262e-02, -1.1977e-02,  2.1057e-03, -3.4343e-02,
        -2.4972e-02, -1.3257e-02, -1.7035e-02, -2.9682e-03, -2.2749e-02,
        -6.1761e-03, -1.3828e-02, -2.7414e-02,  1.1716e-04,  3.3616e-02,
         6.4228e-03, -3.9683e-02,  7.0307e-03,  2.2623e-03,  1.2884e-02,
        -2.7579e-02,  1.9896e-02, -1.6697e-02, -5.0832e-02, -1.2886e-03,
         9.3202e-03, -3.6406e-02,  1.3917e-02,  3.0369e-02,  1.9713e-02,
        -1.3939e-02, -4.2925e-03,  1.1485e-02, -5.3743e-03,  5.1748e-03,
        -2.1699e-02, -1.6887e-03,  4.3939e-03,  1.1291e-02,  5.0568e-03,
        -1.3438e-02, -3.5671e-02, -2.9100e-02, -5.0735e-02, -4.2199e-03,
        -3.7854e-02, -4.7523e-03,  2.6550e-02, -2.6739e-02,  2.3020e-03,
        -2.2901e-02,  3.2325e-02, -1.9574e-02, -2.2373e-02,  2.1958e-02,
        -3.9995e-03, -1.0068e-02, -1.5524e-02, -3.4630e-02, -4.5085e-02,
         2.8778e-04,  2.5203e-02, -3.3007e-02,  6.4935e-03, -1.9292e-02,
        -4.3033e-02, -2.6069e-02, -3.4999e-02, -2.5841e-02, -1.7799e-02,
         3.0576e-03, -5.2440e-03, -4.4398e-03, -7.1256e-03, -1.3299e-02,
         6.7505e-03,  1.0710e-02,  1.5197e-02, -1.3257e-03,  2.1478e-02,
         4.3351e-02,  1.1530e-02, -9.8407e-03,  9.9671e-03,  9.0302e-03,
        -9.7254e-03, -9.5920e-03,  3.2024e-02, -2.3665e-02,  5.7357e-03,
         2.8773e-02,  7.6525e-03,  1.0622e-02, -2.8088e-02,  1.6142e-02,
         1.6860e-02, -1.1662e-02, -3.1238e-02,  1.9096e-04, -3.5445e-03])
##########################################################
prot_encoder.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[ 4.6604e-02,  1.8338e-01,  6.2220e-02,  ..., -3.2589e-05,
         -7.7624e-02, -1.5595e-01],
        [-2.1403e-01,  1.4145e-02,  1.7534e-01,  ...,  1.8537e-01,
          1.2118e-01,  2.0222e-02],
        [ 1.6187e-01, -1.1018e-01, -2.3167e-01,  ..., -2.3265e-03,
         -2.9104e-02,  1.1352e-01],
        ...,
        [ 1.5588e-01,  1.6871e-02,  2.2605e-01,  ..., -1.4311e-01,
         -9.9308e-02,  1.1349e-01],
        [-1.7703e-01, -1.1423e-01,  7.5093e-02,  ..., -7.0908e-02,
         -1.0474e-01, -2.4568e-01],
        [-1.1332e-01,  1.5659e-01, -2.1786e-01,  ...,  8.3517e-02,
         -1.5561e-01,  1.4227e-01]])
tensor([[ 0.0605,  0.1888,  0.0546,  ...,  0.0126, -0.0815, -0.2420],
        [-0.2085,  0.0031,  0.1722,  ...,  0.1638,  0.1297,  0.0062],
        [ 0.1807, -0.0958, -0.2430,  ...,  0.0180, -0.0550,  0.0045],
        ...,
        [ 0.1592,  0.0291,  0.2238,  ..., -0.1322, -0.1025,  0.0620],
        [-0.2067, -0.0909,  0.1024,  ..., -0.0542, -0.1251, -0.2654],
        [-0.1024,  0.1550, -0.2246,  ...,  0.0868, -0.1453,  0.1202]])
##########################################################
prot_encoder.ffn.dense1.bias shape: torch.Size([32])
tensor([-0.0720, -0.0761, -0.0194,  0.1054,  0.1043, -0.0617, -0.0915, -0.0043,
        -0.1016, -0.0790, -0.0857, -0.1166, -0.1205, -0.0660, -0.0371, -0.1021,
         0.0226,  0.1134, -0.0109,  0.0079, -0.0358, -0.0397, -0.0815,  0.0767,
         0.0904, -0.0875, -0.0589,  0.0462, -0.0307, -0.1185, -0.0040, -0.0035])
tensor([-0.0890, -0.0877,  0.0123,  0.0936,  0.1398, -0.0701, -0.1100, -0.0251,
        -0.0871, -0.1059, -0.0797, -0.0993, -0.1213, -0.0765, -0.0405, -0.1261,
         0.0149,  0.1125, -0.0100, -0.0203, -0.0309, -0.0223, -0.0935,  0.0665,
         0.0926, -0.0817, -0.0460,  0.0681, -0.0096, -0.1157, -0.0314,  0.0125])
##########################################################
prot_encoder.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[ 0.1052,  0.2306,  0.1951,  ...,  0.0969, -0.0673,  0.0263],
        [-0.1447,  0.1457,  0.1438,  ...,  0.1966,  0.0212,  0.0816],
        [ 0.1204, -0.2330,  0.1373,  ..., -0.0439, -0.0443, -0.1636],
        ...,
        [ 0.1024, -0.1929,  0.2101,  ...,  0.2492, -0.2321, -0.0334],
        [ 0.0360, -0.0142, -0.0527,  ..., -0.0444,  0.1341,  0.1103],
        [ 0.0318,  0.1884,  0.2136,  ...,  0.0571,  0.0811, -0.1091]])
tensor([[ 0.1317,  0.2183,  0.3129,  ...,  0.1074, -0.0671,  0.0345],
        [-0.1569,  0.1453,  0.2011,  ...,  0.1977,  0.0337,  0.0709],
        [ 0.1140, -0.2357,  0.1017,  ..., -0.0283, -0.0294, -0.1853],
        ...,
        [ 0.1093, -0.2286,  0.3085,  ...,  0.2430, -0.2354, -0.0231],
        [ 0.0390, -0.0030, -0.1141,  ..., -0.0608,  0.1210,  0.1148],
        [ 0.0132,  0.1844,  0.2196,  ...,  0.0646,  0.0727, -0.1241]])
##########################################################
prot_encoder.ffn.dense2.bias shape: torch.Size([64])
tensor([-1.7128e-01,  7.4145e-02, -3.5501e-02, -1.3960e-01,  1.2546e-01,
        -1.3029e-01,  1.1498e-01,  4.9122e-02, -1.6888e-01,  8.7467e-02,
        -1.4658e-01,  1.6644e-01,  2.4369e-02, -1.4319e-01, -1.2218e-01,
         1.1668e-01,  5.1674e-02, -1.1507e-01,  1.6386e-01, -1.1915e-02,
        -8.9868e-02, -1.7023e-01, -2.9152e-02,  1.5756e-03,  1.5269e-01,
         7.2274e-02,  9.5117e-02,  1.7376e-01, -1.5762e-01,  5.6502e-02,
         9.9489e-02,  1.3894e-01, -1.5407e-01,  6.6434e-02,  1.6568e-01,
        -2.1361e-02, -1.5368e-01, -5.1499e-02,  2.2042e-02, -1.8562e-02,
        -9.6989e-02,  8.0711e-02, -1.4160e-01, -1.1035e-01, -1.5237e-02,
        -1.2563e-01, -1.5507e-01, -1.1002e-02, -1.0765e-04,  1.7369e-01,
         4.5221e-02, -1.2867e-01, -1.1128e-02, -3.3520e-02,  1.2738e-01,
        -3.8562e-02,  3.2357e-02,  1.1178e-01, -2.8583e-02, -1.0507e-01,
         1.1730e-01,  9.4292e-04, -1.2584e-01, -8.0008e-02])
tensor([-0.1759,  0.0727, -0.0423, -0.1466,  0.1130, -0.1317,  0.1247,  0.0391,
        -0.1709,  0.0823, -0.1523,  0.1429,  0.0224, -0.1362, -0.1273,  0.1216,
         0.0530, -0.1011,  0.1408, -0.0100, -0.0971, -0.1616, -0.0139, -0.0101,
         0.1583,  0.0663,  0.1014,  0.1673, -0.1448,  0.0449,  0.0910,  0.1392,
        -0.1324,  0.0641,  0.1614, -0.0274, -0.1579, -0.0549,  0.0373, -0.0217,
        -0.0969,  0.0913, -0.1169, -0.1207, -0.0081, -0.1344, -0.1413, -0.0105,
         0.0076,  0.1664,  0.0424, -0.1458, -0.0199, -0.0158,  0.1162, -0.0369,
         0.0586,  0.1061, -0.0330, -0.0916,  0.1215,  0.0187, -0.1199, -0.0848])
##########################################################
prot_encoder.addnorm.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0793, 0.9921, 0.9866, 1.1071, 1.0054, 1.0299, 1.0113, 1.0305, 0.9992,
        1.0224, 1.0645, 1.0203, 1.0191, 1.0178, 0.9643, 1.1106, 1.0070, 1.0484,
        1.0153, 0.9845, 0.9828, 0.9714, 0.9702, 0.9721, 1.0055, 0.9926, 0.9729,
        0.9928, 1.0270, 1.0094, 1.0826, 0.9575, 1.0310, 1.0601, 1.1074, 0.9778,
        1.0472, 1.0132, 1.0593, 0.9629, 1.0271, 0.9812, 1.0249, 1.1267, 0.9670,
        1.0079, 0.9882, 1.0180, 1.0675, 1.0243, 1.0137, 1.0082, 0.9898, 1.1289,
        1.0054, 1.0857, 0.9849, 1.0884, 0.9693, 0.9633, 1.1467, 1.0154, 1.0139,
        1.0855])
##########################################################
prot_encoder.addnorm.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0017,  0.0019,  0.0055,  0.0099, -0.0040, -0.0053,  0.0183,  0.0101,
        -0.0095,  0.0012, -0.0019, -0.0069, -0.0006,  0.0123,  0.0001,  0.0087,
         0.0107,  0.0046, -0.0214,  0.0059,  0.0033,  0.0057,  0.0005,  0.0038,
         0.0096, -0.0037, -0.0003, -0.0024,  0.0118, -0.0153, -0.0021, -0.0063,
         0.0110, -0.0015, -0.0014,  0.0005, -0.0023, -0.0026,  0.0014, -0.0030,
        -0.0009,  0.0107,  0.0191,  0.0012,  0.0060, -0.0014,  0.0055, -0.0171,
        -0.0026, -0.0066, -0.0025,  0.0036,  0.0003, -0.0003,  0.0025,  0.0031,
         0.0135, -0.0025, -0.0048,  0.0174, -0.0023, -0.0114, -0.0073, -0.0089])
##########################################################
prot_encoder.encoder.layers.0.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.1389,  0.0864,  0.0177,  ..., -0.0343, -0.0347, -0.0606],
        [ 0.0853, -0.0975, -0.0916,  ...,  0.0327, -0.1052, -0.0648],
        [-0.0511,  0.1404,  0.0097,  ..., -0.0347,  0.0460,  0.1434],
        ...,
        [-0.0066,  0.1418,  0.0997,  ..., -0.1376, -0.0229, -0.0357],
        [-0.0050,  0.0051, -0.0048,  ..., -0.0775, -0.0128,  0.1432],
        [ 0.1376,  0.0801,  0.1365,  ...,  0.0095,  0.0951,  0.0239]])
tensor([[-0.1443,  0.0778,  0.0053,  ..., -0.0474, -0.0091, -0.0413],
        [ 0.0674, -0.0954, -0.0944,  ...,  0.0305, -0.0894, -0.0476],
        [-0.0490,  0.1308, -0.0018,  ..., -0.0497,  0.0697,  0.1526],
        ...,
        [ 0.0019,  0.1254,  0.0854,  ..., -0.1609,  0.0057, -0.0467],
        [-0.0397, -0.0136, -0.0029,  ..., -0.1089, -0.0059,  0.1537],
        [ 0.1276,  0.0839,  0.1353,  ...,  0.0176,  0.1014,  0.0391]])
##########################################################
prot_encoder.encoder.layers.0.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 1.0276e-02,  7.8551e-03,  5.6668e-03,  3.6965e-03, -2.9009e-03,
        -5.5025e-03, -1.2732e-02, -1.7409e-02, -7.1244e-03, -8.4511e-03,
        -3.4582e-03, -6.8978e-03,  2.4152e-03, -1.6557e-02, -6.4778e-03,
        -6.5102e-03,  6.0042e-03,  3.0575e-02, -8.8392e-03, -1.3878e-02,
        -5.1663e-03, -6.9406e-03, -7.0762e-03,  6.0257e-03, -3.1850e-03,
        -6.7756e-03,  7.9194e-04, -1.8130e-03, -4.2630e-03, -9.9973e-03,
         1.4219e-02,  7.4607e-03,  1.1730e-02, -8.8311e-03, -1.1122e-02,
        -2.0539e-03,  3.2415e-03, -9.4503e-03,  1.5773e-03,  8.0488e-03,
        -4.9238e-03, -4.7614e-03,  4.6146e-03,  1.2177e-02,  6.5807e-03,
        -7.2848e-03,  5.1235e-03,  2.2764e-03,  3.1056e-03, -6.4220e-03,
        -1.0371e-02,  1.4368e-02, -1.4931e-03,  6.8980e-03, -4.0196e-03,
         9.9201e-03,  1.0223e-02,  6.3882e-03,  6.7623e-03, -2.4459e-04,
        -8.3473e-03, -1.1754e-02,  2.1102e-03,  8.3179e-03,  5.6871e-07,
        -2.2209e-06, -1.1666e-05,  4.3393e-07, -1.0112e-06, -1.0522e-05,
         1.7846e-05, -2.2499e-06,  2.0785e-06,  4.5515e-06,  8.1004e-06,
         2.1627e-05, -1.7369e-06,  1.5025e-05,  1.4176e-05,  1.6670e-06,
        -5.4717e-06,  3.5312e-07,  1.0524e-05,  2.5626e-06, -1.0683e-05,
         3.0485e-05,  1.5616e-06,  4.4910e-06, -3.2582e-06, -4.2092e-06,
         1.1463e-05,  1.5793e-05, -1.0106e-05,  6.2317e-06,  4.1578e-06,
         9.5105e-06, -9.0611e-06, -6.3517e-06, -1.3396e-06,  1.4399e-06,
        -2.4997e-06, -5.0446e-06, -9.1993e-06, -1.3229e-05,  2.8717e-05,
        -2.5176e-05,  9.9864e-07,  5.2347e-06,  3.2244e-06,  1.3983e-06,
        -5.3327e-06, -2.1259e-06,  1.2261e-06, -1.2266e-05,  1.2538e-06,
         6.7217e-07,  2.1892e-06, -5.3686e-07,  3.8059e-06,  1.4102e-05,
        -5.6197e-07,  2.3692e-06, -2.9004e-06,  3.2628e-06,  2.3257e-05,
        -1.5218e-06, -5.6100e-06, -2.4599e-06,  1.1815e-02,  6.4940e-04,
        -1.1610e-02,  3.1828e-03,  1.3974e-03, -2.9665e-03,  6.4667e-03,
         5.9317e-03, -1.9926e-03,  1.1473e-02,  7.0447e-03, -1.3298e-02,
         4.8578e-03,  4.6543e-03,  1.1279e-02,  1.3248e-02, -6.9727e-03,
         1.0671e-02,  2.7975e-03, -6.5424e-03,  1.1878e-04,  1.0423e-02,
        -9.3457e-03, -1.0482e-02, -7.0002e-03, -6.4459e-03, -7.7350e-03,
         6.3510e-03, -1.2200e-02,  5.4899e-04,  5.9616e-03, -3.5479e-03,
        -5.8613e-03,  7.3826e-03, -5.6543e-03, -2.8021e-03,  6.1147e-03,
         8.8218e-03, -2.9624e-03,  1.8025e-02, -8.0853e-03, -5.2597e-03,
        -2.1869e-03,  3.2353e-03,  2.8708e-03, -1.2517e-03,  2.7384e-03,
        -1.0994e-02,  1.0777e-02,  1.4360e-02,  9.9040e-03, -9.8284e-03,
         1.4727e-04, -5.5827e-03, -5.6032e-03, -1.1113e-02,  1.0698e-02,
         1.0889e-02,  7.0856e-03,  5.4905e-03,  1.3121e-02,  1.2796e-03,
        -2.0919e-03, -1.1648e-03])
##########################################################
prot_encoder.encoder.layers.0.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[-0.0919, -0.0690, -0.0837,  ...,  0.0922, -0.0186, -0.0546],
        [ 0.0607,  0.1172,  0.0153,  ...,  0.0571, -0.0497,  0.0013],
        [-0.0438,  0.0766, -0.1010,  ..., -0.0142, -0.0172,  0.0573],
        ...,
        [ 0.0030,  0.0623,  0.0659,  ..., -0.0108, -0.0355,  0.0810],
        [-0.0243, -0.0474,  0.0117,  ...,  0.0163,  0.0175, -0.0264],
        [ 0.0260,  0.0725,  0.0015,  ...,  0.0999,  0.0904, -0.1014]])
tensor([[-0.0972, -0.0619, -0.0848,  ...,  0.0969, -0.0284, -0.0532],
        [ 0.0575,  0.1323,  0.0523,  ...,  0.0557, -0.0552, -0.0073],
        [-0.0495,  0.0684, -0.0985,  ..., -0.0140, -0.0272,  0.0565],
        ...,
        [-0.0080,  0.0726,  0.0743,  ..., -0.0116, -0.0308,  0.0827],
        [-0.0144, -0.0425,  0.0080,  ...,  0.0100,  0.0181, -0.0162],
        [ 0.0342,  0.1025,  0.0164,  ...,  0.0913,  0.0856, -0.1033]])
##########################################################
prot_encoder.encoder.layers.0.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 3.3343e-03,  3.9494e-04, -4.7022e-03,  2.5968e-03,  4.1006e-04,
        -4.4890e-03,  1.2929e-02,  1.3506e-03, -3.7016e-03,  1.1604e-02,
         1.0731e-03, -1.5547e-03,  6.6505e-03,  4.3896e-03,  2.8720e-03,
         5.4732e-03,  7.7474e-03,  6.5549e-03, -1.1852e-02, -5.0171e-03,
         4.5612e-03, -2.1805e-03,  3.9745e-03, -4.1564e-03,  3.9614e-03,
        -1.5684e-03,  1.5952e-03, -5.6720e-03,  8.4697e-03, -1.5652e-02,
         1.1974e-02, -8.0935e-03,  6.4229e-03,  1.0088e-03,  1.2552e-03,
         1.3923e-03, -4.9066e-03,  2.8573e-03, -7.1635e-03, -1.6315e-03,
         4.2165e-03,  9.3946e-03,  1.1445e-02, -3.6543e-03, -2.0328e-03,
         3.7620e-03,  5.5068e-03, -2.2707e-02, -7.0776e-03, -3.8591e-03,
        -2.8060e-05,  7.3088e-03, -1.5579e-03, -2.0213e-03, -7.8998e-03,
         6.8400e-03,  1.1806e-02,  5.4804e-04, -7.9818e-03,  1.0288e-02,
        -8.5386e-04, -8.5529e-03, -1.0522e-02, -6.2414e-03])
##########################################################
prot_encoder.encoder.layers.0.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.1141,  0.0927, -0.1074,  ..., -0.0765, -0.1146,  0.1523],
        [ 0.1221, -0.0746,  0.0178,  ..., -0.1387, -0.2396,  0.1281],
        [ 0.1127, -0.0347, -0.0075,  ..., -0.0410, -0.0207,  0.2399],
        ...,
        [-0.2062,  0.0048, -0.1958,  ..., -0.0057,  0.1773,  0.0098],
        [-0.1605,  0.2393,  0.0039,  ...,  0.0392, -0.1067, -0.0619],
        [-0.0072, -0.2500, -0.0146,  ..., -0.0736, -0.0711, -0.1494]])
tensor([[-0.1098,  0.1022, -0.0959,  ..., -0.0714, -0.1098,  0.1561],
        [ 0.0765, -0.0741,  0.0214,  ..., -0.1369, -0.2466,  0.0970],
        [ 0.0770, -0.0427, -0.0105,  ..., -0.0682, -0.0157,  0.2209],
        ...,
        [-0.1650,  0.0176, -0.1777,  ...,  0.0196,  0.1569,  0.0053],
        [-0.1631,  0.2487,  0.0114,  ...,  0.0485, -0.1092, -0.0594],
        [-0.0106, -0.2454,  0.0007,  ..., -0.0639, -0.0698, -0.1496]])
##########################################################
prot_encoder.encoder.layers.0.linear1.bias shape: torch.Size([32])
tensor([ 0.1188,  0.0340, -0.0768,  0.0837,  0.1016,  0.0921,  0.1195, -0.0963,
         0.0369, -0.1228, -0.0421, -0.1209, -0.1041,  0.0079, -0.1006,  0.0360,
         0.0548, -0.1111, -0.1246,  0.1117,  0.1204,  0.0602, -0.0010,  0.0803,
         0.1133,  0.0833, -0.0356, -0.0206,  0.0494,  0.0563, -0.0238, -0.1003])
tensor([ 0.1012,  0.0250, -0.0787,  0.0542,  0.0838,  0.0918,  0.1248, -0.1069,
         0.0422, -0.1427, -0.0448, -0.1522, -0.1066,  0.0071, -0.0958,  0.0367,
         0.0712, -0.1307, -0.1247,  0.0847,  0.1210,  0.0451, -0.0076,  0.0733,
         0.1024,  0.0778, -0.0579, -0.0242,  0.0444,  0.0315, -0.0430, -0.1115])
##########################################################
prot_encoder.encoder.layers.0.linear2.weight shape: torch.Size([64, 32])
tensor([[-0.0691,  0.1921, -0.0209,  ...,  0.1160, -0.0274, -0.2127],
        [ 0.1775,  0.1679, -0.2192,  ..., -0.0683,  0.2003, -0.0757],
        [-0.1542,  0.2017,  0.2233,  ..., -0.1706,  0.1505,  0.1412],
        ...,
        [-0.1499, -0.0876,  0.1192,  ..., -0.0861,  0.2227, -0.0937],
        [ 0.0015,  0.1933, -0.2421,  ...,  0.1633,  0.0387, -0.1251],
        [-0.2358,  0.0793, -0.1463,  ..., -0.1198,  0.0695,  0.0391]])
tensor([[-0.0732,  0.2128, -0.0014,  ...,  0.1145, -0.0296, -0.1785],
        [ 0.1698,  0.1660, -0.2417,  ..., -0.0574,  0.2190, -0.0633],
        [-0.1476,  0.2166,  0.1986,  ..., -0.1562,  0.1701,  0.1546],
        ...,
        [-0.1749, -0.0753,  0.0261,  ..., -0.0842,  0.2259, -0.0885],
        [-0.0229,  0.1642, -0.2537,  ...,  0.1474,  0.0174, -0.1405],
        [-0.2435,  0.0603, -0.1751,  ..., -0.1313,  0.0456,  0.0290]])
##########################################################
prot_encoder.encoder.layers.0.linear2.bias shape: torch.Size([64])
tensor([-0.0917, -0.0673,  0.1518, -0.1720,  0.1531, -0.1141, -0.0946, -0.1630,
        -0.1564, -0.1414, -0.1468, -0.0911,  0.1517, -0.1334, -0.1229, -0.0349,
        -0.0884, -0.0705, -0.0524,  0.1001,  0.1085,  0.0980,  0.0773, -0.1498,
         0.0269,  0.0769, -0.1553,  0.1541, -0.0463,  0.1560, -0.0225, -0.0873,
        -0.0834,  0.1002, -0.1303,  0.1270,  0.0584, -0.1420,  0.0716, -0.0333,
         0.1244,  0.0261,  0.0679, -0.1691,  0.0713,  0.1654,  0.1096,  0.1680,
        -0.0182,  0.1345, -0.1446,  0.1100,  0.1421, -0.1611, -0.0088,  0.1346,
         0.0036, -0.1599,  0.1090,  0.1392,  0.0080, -0.0335, -0.0846, -0.0673])
tensor([-0.0855, -0.0623,  0.1500, -0.1713,  0.1457, -0.1216, -0.0718, -0.1597,
        -0.1565, -0.1345, -0.1350, -0.0934,  0.1518, -0.1310, -0.1212, -0.0220,
        -0.0816, -0.0639, -0.0439,  0.0895,  0.1075,  0.1015,  0.0808, -0.1500,
         0.0185,  0.0646, -0.1468,  0.1573, -0.0326,  0.1357, -0.0167, -0.0965,
        -0.0780,  0.0816, -0.1279,  0.1283,  0.0538, -0.1433,  0.0731, -0.0415,
         0.1255,  0.0297,  0.0709, -0.1705,  0.0672,  0.1595,  0.1173,  0.1609,
        -0.0251,  0.1304, -0.1274,  0.1121,  0.1460, -0.1546, -0.0175,  0.1449,
        -0.0046, -0.1614,  0.1084,  0.1434,  0.0096, -0.0412, -0.1032, -0.0748])
##########################################################
prot_encoder.encoder.layers.0.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0684, 0.9964, 0.9916, 1.0833, 1.0027, 1.0223, 1.0138, 1.0314, 0.9954,
        1.0302, 1.0257, 1.0270, 1.0208, 1.0260, 0.9682, 1.1194, 1.0063, 1.0256,
        1.0238, 0.9941, 0.9828, 0.9787, 0.9687, 0.9722, 1.0184, 0.9958, 0.9758,
        0.9973, 1.0223, 1.0167, 1.0652, 0.9620, 1.0071, 1.0353, 1.0732, 0.9787,
        1.0394, 1.0146, 1.0650, 0.9722, 1.0339, 0.9794, 1.0094, 1.0259, 0.9743,
        1.0197, 0.9904, 1.0285, 1.0281, 1.0269, 1.0120, 1.0076, 0.9936, 1.1485,
        1.0159, 1.0331, 0.9826, 1.0958, 0.9770, 0.9650, 1.0718, 1.0214, 1.0003,
        1.1079])
##########################################################
prot_encoder.encoder.layers.0.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 3.8196e-03,  6.9495e-04, -5.6350e-03,  2.6173e-03,  1.1367e-03,
        -5.0731e-03,  1.2184e-02, -1.0196e-03, -4.4276e-03,  1.1662e-02,
        -1.4000e-04, -2.9418e-03,  6.0917e-03,  4.4883e-03,  3.4574e-04,
         6.3184e-03,  7.4117e-03,  6.8220e-03, -1.1766e-02, -6.9885e-03,
         4.3844e-03, -1.1410e-03,  5.8684e-03, -3.9082e-03,  2.5696e-03,
        -2.3419e-03,  4.5948e-05, -3.9798e-03,  8.4251e-03, -1.6973e-02,
         1.1063e-02, -1.0297e-02,  7.6351e-03,  1.8947e-03,  8.3852e-04,
        -4.2316e-07, -4.3097e-03,  3.0167e-03, -6.4898e-03,  8.1093e-04,
         1.9986e-03,  1.0287e-02,  9.8261e-03, -2.5396e-03, -8.3836e-04,
         4.1240e-03,  3.2765e-03, -2.2891e-02, -7.6114e-03, -3.5015e-03,
         5.0696e-04,  8.2017e-03, -3.6434e-03, -3.1782e-03, -7.0907e-03,
         6.8933e-03,  1.0475e-02,  1.4201e-03, -9.0033e-03,  1.0816e-02,
        -4.6075e-04, -7.8439e-03, -9.4246e-03, -4.9251e-03])
##########################################################
prot_encoder.encoder.layers.0.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0232, 0.9971, 0.9952, 1.0384, 1.0058, 1.0524, 1.0223, 1.0094, 0.9948,
        1.0040, 0.9951, 1.0317, 1.0250, 1.0171, 0.9800, 1.0384, 1.0026, 0.9904,
        1.1034, 1.0003, 0.9842, 0.9895, 0.9849, 0.9774, 1.0220, 0.9934, 0.9847,
        1.0137, 1.0064, 0.9778, 1.0043, 0.9669, 1.0068, 0.9961, 1.0242, 0.9830,
        1.0218, 1.0024, 1.0954, 0.9834, 1.0252, 0.9942, 0.9970, 1.0336, 0.9743,
        0.9961, 0.9844, 1.0033, 0.9975, 1.0300, 0.9972, 1.0210, 0.9873, 1.0354,
        1.0150, 0.9949, 1.0060, 1.0067, 0.9840, 0.9713, 1.0373, 0.9872, 0.9877,
        1.0624])
##########################################################
prot_encoder.encoder.layers.0.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0043,  0.0053, -0.0015, -0.0008, -0.0073, -0.0067,  0.0223,  0.0028,
        -0.0007,  0.0058,  0.0095, -0.0018, -0.0027,  0.0042,  0.0019,  0.0127,
         0.0072,  0.0074,  0.0047, -0.0097,  0.0013,  0.0045,  0.0044,  0.0026,
        -0.0075, -0.0134,  0.0079,  0.0029,  0.0134, -0.0196,  0.0038, -0.0061,
         0.0048, -0.0152,  0.0055,  0.0031, -0.0033,  0.0007,  0.0037, -0.0055,
         0.0010,  0.0047,  0.0036, -0.0015, -0.0037, -0.0052,  0.0060, -0.0038,
        -0.0066, -0.0030,  0.0160, -0.0015,  0.0047,  0.0060, -0.0030,  0.0095,
        -0.0061, -0.0006, -0.0009,  0.0038,  0.0014, -0.0060, -0.0160, -0.0067])
##########################################################
prot_encoder.encoder.layers.1.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.1389,  0.0864,  0.0177,  ..., -0.0343, -0.0347, -0.0606],
        [ 0.0853, -0.0975, -0.0916,  ...,  0.0327, -0.1052, -0.0648],
        [-0.0511,  0.1404,  0.0097,  ..., -0.0347,  0.0460,  0.1434],
        ...,
        [-0.0066,  0.1418,  0.0997,  ..., -0.1376, -0.0229, -0.0357],
        [-0.0050,  0.0051, -0.0048,  ..., -0.0775, -0.0128,  0.1432],
        [ 0.1376,  0.0801,  0.1365,  ...,  0.0095,  0.0951,  0.0239]])
tensor([[-0.1420,  0.0861,  0.0067,  ..., -0.0334, -0.0214, -0.0586],
        [ 0.0802, -0.0871, -0.0814,  ...,  0.0414, -0.1075, -0.0766],
        [-0.0455,  0.1437,  0.0068,  ..., -0.0378,  0.0564,  0.1483],
        ...,
        [ 0.0052,  0.1344,  0.0921,  ..., -0.1508, -0.0264, -0.0341],
        [-0.0073, -0.0120,  0.0004,  ..., -0.0848, -0.0210,  0.1902],
        [ 0.1283,  0.0913,  0.1332,  ...,  0.0187,  0.0993,  0.0227]])
##########################################################
prot_encoder.encoder.layers.1.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 4.7518e-03, -1.0344e-02, -9.0466e-04,  6.5638e-03,  1.1022e-02,
        -2.8436e-03, -1.4619e-03, -2.7185e-02, -8.4894e-04, -6.9934e-03,
         5.8969e-03, -7.9455e-03,  1.2026e-02, -4.6139e-03,  4.0383e-03,
        -6.2596e-03,  2.3854e-04,  4.3861e-03, -5.6856e-03,  7.2312e-03,
        -5.8630e-04, -4.9620e-03, -2.4457e-03,  1.8357e-02, -1.5915e-03,
         5.0961e-03, -6.8503e-03,  4.1434e-03,  1.0719e-03,  6.9735e-03,
        -1.7102e-02, -2.0877e-02, -8.8946e-03, -4.9957e-03,  2.4325e-02,
        -1.2895e-02,  1.5115e-02,  4.1408e-03, -3.6091e-03,  8.2893e-03,
        -3.1238e-03, -2.9752e-04, -1.3617e-03,  3.3245e-03, -1.7154e-02,
        -1.2360e-02,  1.0421e-02,  2.7477e-02, -2.4350e-03, -6.4694e-03,
        -2.2947e-02,  5.9897e-03, -6.3666e-03,  2.0878e-03, -1.5338e-03,
         2.1086e-03, -2.0983e-02, -3.2752e-03,  3.4831e-04, -6.7978e-03,
        -4.0965e-03, -1.7462e-02,  1.1356e-02, -1.8901e-03, -4.2017e-06,
        -3.2725e-06, -6.8074e-06, -1.1050e-05,  9.2864e-06,  1.8711e-05,
         7.1406e-06, -1.0282e-05, -7.0295e-06, -9.3835e-06, -5.9068e-06,
        -2.2186e-06, -2.8164e-06,  4.2348e-06,  1.6098e-07,  8.4985e-06,
         9.4446e-06,  2.2957e-05,  2.0572e-06,  1.6701e-06,  1.4306e-05,
        -3.9992e-06, -5.5185e-06, -6.3205e-06, -1.2132e-06, -8.5499e-06,
         2.2596e-06,  6.1902e-06,  3.3016e-06,  2.4411e-06,  8.0173e-06,
         6.5552e-06, -5.1341e-06,  9.6888e-06, -1.2557e-06, -1.6287e-07,
        -6.5187e-06, -1.3086e-06,  9.8027e-07, -1.6604e-05,  4.6603e-06,
        -4.1439e-07, -6.5320e-06,  1.4836e-06,  2.3432e-06, -5.2683e-06,
         6.8225e-06, -1.8305e-06, -1.1796e-06, -1.5237e-06,  1.4283e-05,
        -2.4215e-06,  3.6215e-07, -5.6039e-06, -4.7821e-07, -9.0175e-06,
        -3.9755e-06,  2.5408e-06, -2.8206e-06,  5.3791e-06, -2.1191e-05,
        -1.4370e-06, -3.5306e-06, -4.0446e-06,  1.5423e-02, -7.9086e-03,
        -2.7722e-03,  1.7712e-02,  9.4651e-03, -2.4688e-03,  7.7416e-03,
        -1.1253e-02,  1.4052e-03, -3.6844e-03, -1.0955e-03, -1.9528e-03,
         7.1377e-03, -1.5878e-04, -2.4458e-03,  5.3290e-03, -7.6660e-03,
         7.3761e-03,  6.1298e-04, -1.5095e-02,  1.2139e-02, -4.9076e-04,
        -3.0554e-03,  2.1675e-03, -1.5122e-03,  4.8958e-03, -2.6728e-03,
        -6.0842e-03,  6.6944e-04,  1.1691e-03, -1.9118e-03,  2.4379e-03,
         4.1655e-03,  1.4350e-03,  4.2228e-03,  7.9025e-04, -2.5895e-03,
        -4.9287e-03, -4.4990e-03,  1.1804e-02, -5.3834e-03,  5.1337e-03,
        -2.5991e-03,  1.0295e-02, -2.8155e-03, -1.1170e-03, -1.6004e-03,
        -3.5538e-03, -3.8607e-03,  7.3429e-03, -2.5991e-04,  7.2180e-03,
        -9.7741e-04,  4.2660e-03, -5.6661e-03, -1.0150e-03,  2.5996e-03,
         2.9585e-03,  5.5816e-04,  6.9340e-03, -5.2503e-03, -6.3179e-03,
        -6.9244e-03,  6.9954e-03])
##########################################################
prot_encoder.encoder.layers.1.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[-0.0919, -0.0690, -0.0837,  ...,  0.0922, -0.0186, -0.0546],
        [ 0.0607,  0.1172,  0.0153,  ...,  0.0571, -0.0497,  0.0013],
        [-0.0438,  0.0766, -0.1010,  ..., -0.0142, -0.0172,  0.0573],
        ...,
        [ 0.0030,  0.0623,  0.0659,  ..., -0.0108, -0.0355,  0.0810],
        [-0.0243, -0.0474,  0.0117,  ...,  0.0163,  0.0175, -0.0264],
        [ 0.0260,  0.0725,  0.0015,  ...,  0.0999,  0.0904, -0.1014]])
tensor([[-0.1034, -0.0699, -0.0818,  ...,  0.0857, -0.0218, -0.0492],
        [ 0.0592,  0.1204,  0.0191,  ...,  0.0473, -0.0405, -0.0099],
        [-0.0438,  0.0760, -0.0761,  ...,  0.0081, -0.0117,  0.0566],
        ...,
        [ 0.0210,  0.0638,  0.0565,  ..., -0.0120, -0.0331,  0.0877],
        [-0.0146, -0.0410,  0.0057,  ...,  0.0154,  0.0126, -0.0188],
        [ 0.0371,  0.0548,  0.0131,  ...,  0.0934,  0.0798, -0.1020]])
##########################################################
prot_encoder.encoder.layers.1.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-6.6188e-04,  5.4039e-03, -5.3973e-03, -7.7707e-04, -7.6154e-03,
        -7.6333e-03,  1.5643e-02, -4.8451e-03, -4.6429e-03,  3.3530e-04,
         9.8539e-03, -3.0961e-03, -3.9103e-03,  4.8671e-03, -2.1113e-03,
         6.9925e-03, -6.0900e-04,  5.6583e-03, -1.1855e-03, -5.2283e-03,
         2.7749e-03, -1.1880e-03,  4.7614e-03,  7.0241e-03, -4.8317e-03,
        -7.0618e-03,  5.5059e-03, -2.9483e-03,  5.8813e-03, -1.5428e-02,
        -2.9128e-03, -4.6076e-03, -3.3357e-03, -9.2193e-03,  1.0188e-02,
         3.8799e-03, -7.4874e-03,  5.6246e-03,  3.6889e-03,  2.0140e-03,
        -2.1131e-04,  6.4589e-03,  4.9917e-03, -1.5353e-03, -7.0443e-03,
        -9.6516e-03,  3.5994e-03,  2.8630e-04, -4.0740e-03, -8.4606e-04,
         1.9161e-02, -6.7577e-03,  7.1959e-03,  3.5738e-04, -2.8166e-03,
         9.2411e-03,  2.6575e-03,  2.6687e-03, -1.3720e-03,  2.8732e-03,
         4.1119e-05, -5.8286e-03, -1.3387e-02, -1.5008e-02])
##########################################################
prot_encoder.encoder.layers.1.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0032, -0.2258, -0.1447,  ..., -0.2404, -0.0232, -0.1228],
        [ 0.0261,  0.0208, -0.0509,  ...,  0.1409, -0.2314, -0.0339],
        [ 0.2361,  0.2255,  0.1588,  ...,  0.1473,  0.2479,  0.0808],
        ...,
        [-0.1899, -0.2193,  0.2081,  ...,  0.2013,  0.2232,  0.1147],
        [-0.0770,  0.1600, -0.1732,  ..., -0.0908,  0.1955, -0.0952],
        [ 0.1740, -0.1241,  0.1940,  ...,  0.2039,  0.1136, -0.0516]])
tensor([[-0.0274, -0.2438, -0.1407,  ..., -0.2471, -0.0142, -0.1270],
        [ 0.0366,  0.0193, -0.0661,  ...,  0.1467, -0.2640, -0.0308],
        [ 0.2254,  0.2182,  0.1704,  ...,  0.1399,  0.2365,  0.0563],
        ...,
        [-0.2089, -0.2293,  0.2152,  ...,  0.1844,  0.2154,  0.1410],
        [-0.0710,  0.1571, -0.1759,  ..., -0.0917,  0.1793, -0.0935],
        [ 0.1837, -0.1347,  0.1832,  ...,  0.1760,  0.1141, -0.0557]])
##########################################################
prot_encoder.encoder.layers.1.linear1.bias shape: torch.Size([32])
tensor([ 0.1188,  0.0340, -0.0768,  0.0837,  0.1016,  0.0921,  0.1195, -0.0963,
         0.0369, -0.1228, -0.0421, -0.1209, -0.1041,  0.0079, -0.1006,  0.0360,
         0.0548, -0.1111, -0.1246,  0.1117,  0.1204,  0.0602, -0.0010,  0.0803,
         0.1133,  0.0833, -0.0356, -0.0206,  0.0494,  0.0563, -0.0238, -0.1003])
tensor([ 0.1260,  0.0291, -0.0834,  0.0707,  0.0926,  0.0855,  0.1112, -0.1072,
         0.0327, -0.1340, -0.0404, -0.1334, -0.1408,  0.0053, -0.1171,  0.0095,
         0.0399, -0.1236, -0.1082,  0.1073,  0.1062,  0.0630, -0.0080,  0.0828,
         0.1076,  0.0772, -0.0293, -0.0280,  0.0400,  0.0544, -0.0290, -0.1124])
##########################################################
prot_encoder.encoder.layers.1.linear2.weight shape: torch.Size([64, 32])
tensor([[-0.2070,  0.2176,  0.0684,  ..., -0.1596,  0.2115, -0.1400],
        [ 0.1399,  0.0460, -0.1029,  ..., -0.1225, -0.0059, -0.2097],
        [-0.1686, -0.1268,  0.1060,  ...,  0.0746,  0.0510, -0.2062],
        ...,
        [ 0.0911, -0.1510, -0.0561,  ...,  0.0641, -0.1105,  0.2026],
        [ 0.0742,  0.2374,  0.0349,  ..., -0.0023, -0.1904,  0.1799],
        [-0.0348, -0.0844, -0.1763,  ...,  0.1840,  0.0023, -0.1449]])
tensor([[-0.2041,  0.2323,  0.0671,  ..., -0.1634,  0.2174, -0.1417],
        [ 0.1527,  0.0478, -0.0951,  ..., -0.1153, -0.0082, -0.2011],
        [-0.1758, -0.1248,  0.1169,  ...,  0.0698,  0.0367, -0.2092],
        ...,
        [ 0.0920, -0.1553, -0.0582,  ...,  0.0573, -0.1113,  0.1986],
        [ 0.0701,  0.2215,  0.0247,  ..., -0.0080, -0.1759,  0.1737],
        [-0.0589, -0.0882, -0.1832,  ...,  0.1708,  0.0075, -0.1499]])
##########################################################
prot_encoder.encoder.layers.1.linear2.bias shape: torch.Size([64])
tensor([-0.0917, -0.0673,  0.1518, -0.1720,  0.1531, -0.1141, -0.0946, -0.1630,
        -0.1564, -0.1414, -0.1468, -0.0911,  0.1517, -0.1334, -0.1229, -0.0349,
        -0.0884, -0.0705, -0.0524,  0.1001,  0.1085,  0.0980,  0.0773, -0.1498,
         0.0269,  0.0769, -0.1553,  0.1541, -0.0463,  0.1560, -0.0225, -0.0873,
        -0.0834,  0.1002, -0.1303,  0.1270,  0.0584, -0.1420,  0.0716, -0.0333,
         0.1244,  0.0261,  0.0679, -0.1691,  0.0713,  0.1654,  0.1096,  0.1680,
        -0.0182,  0.1345, -0.1446,  0.1100,  0.1421, -0.1611, -0.0088,  0.1346,
         0.0036, -0.1599,  0.1090,  0.1392,  0.0080, -0.0335, -0.0846, -0.0673])
tensor([-0.0864, -0.0594,  0.1525, -0.1688,  0.1401, -0.1175, -0.0806, -0.1705,
        -0.1589, -0.1344, -0.1398, -0.0898,  0.1479, -0.1254, -0.1224, -0.0306,
        -0.0842, -0.0648, -0.0473,  0.0909,  0.1086,  0.0987,  0.0817, -0.1512,
         0.0234,  0.0636, -0.1475,  0.1499, -0.0390,  0.1301, -0.0188, -0.0840,
        -0.0824,  0.0921, -0.1180,  0.1244,  0.0484, -0.1406,  0.0750, -0.0336,
         0.1200,  0.0313,  0.0699, -0.1709,  0.0582,  0.1626,  0.1090,  0.1663,
        -0.0208,  0.1292, -0.1327,  0.1047,  0.1428, -0.1601, -0.0099,  0.1426,
         0.0059, -0.1464,  0.1004,  0.1413,  0.0045, -0.0348, -0.0941, -0.0779])
##########################################################
prot_encoder.encoder.layers.1.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0219, 0.9927, 1.0020, 1.0367, 1.0056, 1.0535, 1.0230, 1.0123, 0.9914,
        1.0013, 0.9938, 1.0209, 1.0240, 1.0109, 0.9861, 1.0472, 1.0036, 0.9886,
        1.0403, 1.0084, 0.9875, 0.9936, 0.9881, 0.9708, 1.0264, 0.9850, 0.9886,
        0.9936, 1.0033, 0.9853, 1.0067, 0.9756, 1.0085, 0.9957, 1.0261, 0.9859,
        1.0141, 1.0075, 1.0547, 0.9878, 1.0133, 0.9925, 1.0009, 1.0097, 0.9791,
        1.0080, 0.9784, 1.0048, 0.9932, 1.0211, 0.9990, 1.0180, 0.9931, 1.0290,
        1.0248, 1.0010, 1.0083, 1.0036, 0.9884, 0.9647, 1.0117, 0.9851, 0.9844,
        1.0476])
##########################################################
prot_encoder.encoder.layers.1.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0021,  0.0051, -0.0060, -0.0001, -0.0088, -0.0071,  0.0132, -0.0048,
        -0.0051, -0.0013,  0.0096, -0.0023, -0.0036,  0.0055, -0.0039,  0.0071,
        -0.0005,  0.0053, -0.0009, -0.0058,  0.0035, -0.0004,  0.0043,  0.0064,
        -0.0063, -0.0079,  0.0052, -0.0037,  0.0052, -0.0175, -0.0036, -0.0036,
        -0.0042, -0.0092,  0.0111,  0.0042, -0.0059,  0.0058,  0.0037,  0.0014,
        -0.0012,  0.0059,  0.0042, -0.0008, -0.0077, -0.0091,  0.0031,  0.0003,
        -0.0034, -0.0014,  0.0188, -0.0077,  0.0075,  0.0001, -0.0030,  0.0095,
         0.0023,  0.0029, -0.0019,  0.0029, -0.0008, -0.0058, -0.0143, -0.0136])
##########################################################
prot_encoder.encoder.layers.1.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0357, 0.9941, 1.0032, 1.0081, 1.0030, 1.0227, 1.0093, 1.0124, 0.9992,
        0.9884, 0.9895, 1.0083, 1.0254, 1.0080, 0.9966, 1.0278, 1.0072, 0.9849,
        1.0293, 1.0031, 0.9905, 0.9897, 0.9889, 0.9901, 1.0217, 0.9868, 0.9907,
        0.9763, 1.0001, 0.9736, 0.9997, 0.9941, 0.9838, 0.9993, 1.0339, 0.9806,
        1.0123, 1.0072, 1.0198, 0.9973, 1.0068, 1.0038, 1.0005, 1.0217, 0.9837,
        1.0059, 0.9708, 0.9946, 0.9890, 0.9900, 1.0144, 1.0191, 0.9845, 1.0202,
        1.0332, 0.9920, 1.0149, 1.0071, 0.9948, 0.9661, 1.0137, 0.9920, 0.9714,
        1.0344])
##########################################################
prot_encoder.encoder.layers.1.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0042,  0.0063,  0.0003,  0.0007, -0.0098, -0.0025,  0.0108, -0.0071,
        -0.0037,  0.0047,  0.0048,  0.0006, -0.0026,  0.0054, -0.0013,  0.0040,
         0.0038,  0.0057,  0.0046, -0.0079,  0.0023,  0.0012,  0.0037, -0.0022,
        -0.0009, -0.0122,  0.0092, -0.0039,  0.0049, -0.0247,  0.0020,  0.0037,
         0.0007, -0.0071,  0.0138, -0.0015, -0.0071,  0.0022,  0.0045,  0.0001,
        -0.0029,  0.0063,  0.0059, -0.0024, -0.0107,  0.0008,  0.0027, -0.0016,
        -0.0043, -0.0039,  0.0106, -0.0050,  0.0004,  0.0029,  0.0001,  0.0087,
         0.0012,  0.0142, -0.0058,  0.0026, -0.0049,  0.0009, -0.0097, -0.0083])
##########################################################
prot_encoder.encoder.layers.2.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[-0.1389,  0.0864,  0.0177,  ..., -0.0343, -0.0347, -0.0606],
        [ 0.0853, -0.0975, -0.0916,  ...,  0.0327, -0.1052, -0.0648],
        [-0.0511,  0.1404,  0.0097,  ..., -0.0347,  0.0460,  0.1434],
        ...,
        [-0.0066,  0.1418,  0.0997,  ..., -0.1376, -0.0229, -0.0357],
        [-0.0050,  0.0051, -0.0048,  ..., -0.0775, -0.0128,  0.1432],
        [ 0.1376,  0.0801,  0.1365,  ...,  0.0095,  0.0951,  0.0239]])
tensor([[-0.1477,  0.1015,  0.0203,  ..., -0.0356, -0.0636, -0.0840],
        [ 0.0861, -0.0796, -0.0733,  ...,  0.0338, -0.1301, -0.0919],
        [-0.0443,  0.1405,  0.0030,  ..., -0.0421,  0.0398,  0.1224],
        ...,
        [-0.0035,  0.1383,  0.0947,  ..., -0.1419, -0.0153, -0.0230],
        [-0.0241, -0.0025,  0.0082,  ..., -0.0606, -0.0067,  0.1670],
        [ 0.1378,  0.0829,  0.1424,  ...,  0.0171,  0.0925,  0.0314]])
##########################################################
prot_encoder.encoder.layers.2.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-1.9688e-03, -5.2585e-03, -3.3946e-03, -1.6308e-03,  1.5839e-02,
         4.9040e-04,  1.2843e-03, -6.6835e-03,  2.3296e-03, -1.8317e-03,
         4.0591e-03, -2.8722e-04,  7.7853e-03, -1.7752e-03,  5.0016e-03,
         3.3382e-04, -4.3036e-03,  1.7889e-02,  2.4292e-03, -4.1851e-04,
         5.9568e-03,  5.3886e-03, -4.1060e-03,  7.0378e-03, -5.2988e-03,
        -6.7591e-05, -1.4897e-03,  1.1876e-02,  3.1756e-03, -7.3196e-03,
        -6.8272e-03, -1.6744e-02, -2.9180e-03,  3.5250e-03, -1.0104e-02,
        -8.9409e-03,  9.2654e-03, -4.2645e-03, -1.1025e-02,  6.4379e-05,
        -1.4766e-02, -3.6317e-03,  3.4320e-03, -3.2588e-03,  7.6673e-03,
        -9.6686e-03,  7.9979e-03, -8.6001e-04, -1.9035e-05, -3.2027e-03,
        -1.8592e-03,  8.7475e-03,  3.2310e-03,  3.8293e-03, -2.9427e-03,
        -5.1110e-03, -1.9671e-02, -2.6855e-03, -2.2566e-03, -1.0439e-02,
         3.1760e-03,  9.8630e-03, -3.8055e-04,  1.6811e-02,  7.6781e-06,
         2.8110e-06,  5.8010e-06,  1.6779e-05,  1.0495e-05,  5.1361e-06,
         2.4178e-07,  2.7905e-05, -2.8542e-06, -1.5173e-05,  1.0617e-05,
        -5.5967e-06, -1.7473e-05,  6.3788e-06,  2.9205e-05, -1.2084e-05,
         3.8529e-06,  1.4953e-05, -3.4405e-06,  5.6790e-06, -6.5259e-06,
         3.6167e-06, -7.6060e-06, -2.1790e-07, -6.9627e-06,  1.9527e-06,
         1.6783e-06, -1.6569e-05,  3.9443e-06,  4.6894e-07,  7.3123e-07,
        -1.8448e-06, -6.5567e-05,  2.9265e-05,  6.5578e-05,  4.8825e-06,
         6.7678e-05, -2.2122e-05, -5.5967e-06,  8.8298e-05,  3.8842e-05,
        -6.4088e-05,  5.3195e-05,  5.9653e-05, -8.0019e-05,  4.4921e-05,
         2.9589e-07,  4.2145e-05, -1.5339e-05, -9.3777e-05, -3.7263e-05,
        -5.5527e-05, -1.3228e-05,  9.9880e-05, -2.8903e-05,  3.3960e-05,
         3.7945e-05,  5.6328e-05,  6.5510e-05,  9.3390e-06,  1.3225e-05,
        -2.1690e-05,  7.4093e-05, -7.6802e-05,  1.2034e-02, -6.3407e-03,
        -2.3247e-03,  1.5609e-02,  6.2461e-03, -5.0854e-03,  1.1412e-02,
        -9.9456e-03, -1.3830e-04, -3.6157e-03, -1.3581e-03,  1.6816e-03,
         1.3427e-02,  5.7344e-03, -2.3707e-03,  2.8313e-03, -1.7684e-03,
        -5.0369e-03,  3.8928e-05, -5.5930e-03,  2.5223e-03,  1.4266e-03,
         2.2511e-03, -1.8089e-02,  1.1185e-02,  9.4747e-04,  4.7065e-04,
        -9.5974e-03,  2.4689e-03,  7.8343e-03,  1.6579e-04, -3.7195e-03,
         7.1154e-04, -8.8180e-03, -2.6193e-03, -2.4865e-03,  5.7056e-03,
        -2.4409e-03,  5.9220e-04,  1.3039e-02, -5.8575e-03, -9.0853e-04,
        -1.0994e-03,  8.3555e-03, -4.1972e-03, -7.6497e-03, -3.1568e-03,
        -1.0336e-03,  1.6517e-03,  6.5201e-03, -1.2913e-03, -2.2387e-03,
        -4.8732e-03, -9.2235e-03,  4.8377e-03,  7.0257e-03,  6.1573e-03,
         2.7124e-03,  5.1327e-03,  7.0884e-03,  2.0352e-03, -2.3051e-03,
         5.8668e-03,  4.6982e-03])
##########################################################
prot_encoder.encoder.layers.2.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[-0.0919, -0.0690, -0.0837,  ...,  0.0922, -0.0186, -0.0546],
        [ 0.0607,  0.1172,  0.0153,  ...,  0.0571, -0.0497,  0.0013],
        [-0.0438,  0.0766, -0.1010,  ..., -0.0142, -0.0172,  0.0573],
        ...,
        [ 0.0030,  0.0623,  0.0659,  ..., -0.0108, -0.0355,  0.0810],
        [-0.0243, -0.0474,  0.0117,  ...,  0.0163,  0.0175, -0.0264],
        [ 0.0260,  0.0725,  0.0015,  ...,  0.0999,  0.0904, -0.1014]])
tensor([[-0.0956, -0.0657, -0.0774,  ...,  0.0936, -0.0129, -0.0544],
        [ 0.0619,  0.1231,  0.0205,  ...,  0.0541, -0.0415, -0.0134],
        [-0.0488,  0.0728, -0.0900,  ..., -0.0054, -0.0200,  0.0599],
        ...,
        [ 0.0035,  0.0716,  0.0649,  ..., -0.0083, -0.0332,  0.0823],
        [-0.0165, -0.0475,  0.0097,  ...,  0.0096,  0.0096, -0.0130],
        [ 0.0314,  0.0651,  0.0158,  ...,  0.0990,  0.0833, -0.0963]])
##########################################################
prot_encoder.encoder.layers.2.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0025,  0.0048, -0.0038, -0.0022, -0.0069, -0.0011,  0.0059, -0.0085,
        -0.0086, -0.0007, -0.0014, -0.0029, -0.0002,  0.0030, -0.0080,  0.0075,
        -0.0016,  0.0068,  0.0020,  0.0010,  0.0084, -0.0022,  0.0011, -0.0082,
         0.0020, -0.0087,  0.0082, -0.0027, -0.0069, -0.0216,  0.0004,  0.0059,
        -0.0025, -0.0048,  0.0118,  0.0030, -0.0065,  0.0030,  0.0085,  0.0068,
        -0.0008,  0.0075,  0.0056, -0.0046, -0.0176, -0.0091,  0.0023,  0.0043,
        -0.0028,  0.0029,  0.0075, -0.0048, -0.0007,  0.0019, -0.0006,  0.0134,
         0.0003,  0.0099, -0.0054,  0.0012, -0.0093,  0.0037, -0.0062, -0.0074])
##########################################################
prot_encoder.encoder.layers.2.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0082, -0.1589,  0.0898,  ..., -0.0118, -0.0476,  0.0534],
        [-0.0218,  0.0587, -0.0383,  ..., -0.0920,  0.1979, -0.2091],
        [ 0.2366,  0.1684, -0.1410,  ...,  0.1877,  0.0178,  0.2211],
        ...,
        [ 0.1244, -0.2095,  0.0197,  ..., -0.0245,  0.0329, -0.2068],
        [-0.1904, -0.0416,  0.0049,  ...,  0.0284, -0.1082,  0.1056],
        [ 0.2181,  0.1860, -0.0933,  ..., -0.0749, -0.0801,  0.1285]])
tensor([[-0.0003, -0.1592,  0.0902,  ..., -0.0525, -0.0667,  0.0519],
        [-0.0133,  0.0585, -0.0419,  ..., -0.1263,  0.1852, -0.2227],
        [ 0.2340,  0.1820, -0.1287,  ...,  0.1755,  0.0053,  0.2228],
        ...,
        [ 0.1356, -0.1797,  0.0248,  ..., -0.0433,  0.0273, -0.2426],
        [-0.1954, -0.0490,  0.0147,  ...,  0.0249, -0.1065,  0.1157],
        [ 0.2129,  0.1953, -0.0991,  ..., -0.0756, -0.0719,  0.1355]])
##########################################################
prot_encoder.encoder.layers.2.linear1.bias shape: torch.Size([32])
tensor([ 0.1188,  0.0340, -0.0768,  0.0837,  0.1016,  0.0921,  0.1195, -0.0963,
         0.0369, -0.1228, -0.0421, -0.1209, -0.1041,  0.0079, -0.1006,  0.0360,
         0.0548, -0.1111, -0.1246,  0.1117,  0.1204,  0.0602, -0.0010,  0.0803,
         0.1133,  0.0833, -0.0356, -0.0206,  0.0494,  0.0563, -0.0238, -0.1003])
tensor([ 0.1023,  0.0117, -0.0895,  0.0812,  0.0740,  0.0706,  0.1153, -0.1121,
         0.0210, -0.1429, -0.0585, -0.1152, -0.1000,  0.0099, -0.1152,  0.0229,
         0.0494, -0.1177, -0.1187,  0.1139,  0.1199,  0.0526,  0.0036,  0.0669,
         0.1062,  0.0827, -0.0501, -0.0225,  0.0098,  0.0239, -0.0259, -0.1055])
##########################################################
prot_encoder.encoder.layers.2.linear2.weight shape: torch.Size([64, 32])
tensor([[ 0.1650,  0.0431,  0.0692,  ..., -0.1356, -0.1580,  0.2383],
        [ 0.1140,  0.1741,  0.0318,  ..., -0.1568, -0.0983, -0.1576],
        [-0.1518,  0.0755,  0.1450,  ...,  0.0832,  0.1794, -0.1664],
        ...,
        [-0.1168,  0.0854, -0.0921,  ..., -0.1370, -0.1388,  0.2431],
        [ 0.1762, -0.0808,  0.0426,  ..., -0.0672, -0.0725, -0.0661],
        [ 0.1928, -0.1449, -0.1342,  ...,  0.0579,  0.1629,  0.2136]])
tensor([[ 0.1585,  0.0626,  0.0472,  ..., -0.1413, -0.1406,  0.2401],
        [ 0.1155,  0.1904,  0.0285,  ..., -0.0990, -0.0926, -0.1408],
        [-0.1522,  0.0877,  0.1157,  ...,  0.0383,  0.1609, -0.1935],
        ...,
        [-0.1183,  0.0929, -0.0716,  ..., -0.0992, -0.1328,  0.2435],
        [ 0.1694, -0.1120,  0.0393,  ..., -0.0411, -0.0716, -0.0713],
        [ 0.1934, -0.1602, -0.1428,  ...,  0.0339,  0.1641,  0.2234]])
##########################################################
prot_encoder.encoder.layers.2.linear2.bias shape: torch.Size([64])
tensor([-0.0917, -0.0673,  0.1518, -0.1720,  0.1531, -0.1141, -0.0946, -0.1630,
        -0.1564, -0.1414, -0.1468, -0.0911,  0.1517, -0.1334, -0.1229, -0.0349,
        -0.0884, -0.0705, -0.0524,  0.1001,  0.1085,  0.0980,  0.0773, -0.1498,
         0.0269,  0.0769, -0.1553,  0.1541, -0.0463,  0.1560, -0.0225, -0.0873,
        -0.0834,  0.1002, -0.1303,  0.1270,  0.0584, -0.1420,  0.0716, -0.0333,
         0.1244,  0.0261,  0.0679, -0.1691,  0.0713,  0.1654,  0.1096,  0.1680,
        -0.0182,  0.1345, -0.1446,  0.1100,  0.1421, -0.1611, -0.0088,  0.1346,
         0.0036, -0.1599,  0.1090,  0.1392,  0.0080, -0.0335, -0.0846, -0.0673])
tensor([-0.0936, -0.0618,  0.1383, -0.1726,  0.1484, -0.1077, -0.0899, -0.1662,
        -0.1604, -0.1461, -0.1436, -0.0947,  0.1508, -0.1328, -0.1240, -0.0319,
        -0.0938, -0.0756, -0.0458,  0.1029,  0.1168,  0.0959,  0.0725, -0.1533,
         0.0192,  0.0642, -0.1518,  0.1472, -0.0496,  0.1378, -0.0206, -0.0817,
        -0.0895,  0.1029, -0.1143,  0.1303,  0.0589, -0.1437,  0.0832, -0.0276,
         0.1258,  0.0290,  0.0737, -0.1734,  0.0654,  0.1604,  0.1146,  0.1740,
        -0.0203,  0.1395, -0.1382,  0.1011,  0.1391, -0.1582, -0.0087,  0.1409,
        -0.0027, -0.1404,  0.1059,  0.1403,  0.0064, -0.0264, -0.0914, -0.0709])
##########################################################
prot_encoder.encoder.layers.2.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0255, 0.9908, 0.9993, 1.0115, 0.9824, 1.0159, 1.0039, 1.0060, 1.0069,
        0.9801, 0.9944, 1.0075, 1.0174, 1.0049, 1.0000, 0.9997, 1.0085, 0.9723,
        1.0200, 1.0072, 0.9820, 0.9800, 0.9933, 1.0040, 1.0201, 0.9970, 0.9939,
        0.9675, 1.0083, 0.9719, 1.0045, 1.0067, 0.9805, 0.9902, 1.0248, 0.9838,
        1.0159, 1.0008, 1.0047, 0.9991, 0.9931, 1.0015, 0.9927, 1.0058, 0.9797,
        1.0104, 0.9546, 0.9958, 0.9875, 0.9969, 0.9955, 1.0191, 0.9937, 1.0044,
        1.0225, 1.0052, 1.0053, 1.0025, 1.0060, 0.9801, 1.0185, 0.9830, 0.9688,
        1.0068])
##########################################################
prot_encoder.encoder.layers.2.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0010,  0.0049, -0.0040, -0.0012, -0.0080, -0.0009,  0.0035, -0.0084,
        -0.0103, -0.0017, -0.0012, -0.0005, -0.0009,  0.0026, -0.0084,  0.0089,
        -0.0009,  0.0068,  0.0028,  0.0023,  0.0106, -0.0021, -0.0004, -0.0076,
         0.0020, -0.0088,  0.0078, -0.0027, -0.0093, -0.0231, -0.0008,  0.0082,
        -0.0039, -0.0043,  0.0140,  0.0032, -0.0030,  0.0037,  0.0086,  0.0082,
         0.0001,  0.0070,  0.0066, -0.0043, -0.0168, -0.0071,  0.0018,  0.0055,
        -0.0029,  0.0033,  0.0084, -0.0050,  0.0003,  0.0022, -0.0006,  0.0141,
         0.0004,  0.0108, -0.0046,  0.0013, -0.0093,  0.0048, -0.0072, -0.0056])
##########################################################
prot_encoder.encoder.layers.2.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0053, 0.9809, 1.0096, 0.9991, 0.9901, 0.9914, 1.0014, 0.9967, 0.9950,
        0.9602, 0.9574, 1.0165, 0.9998, 1.0056, 1.0009, 0.9782, 1.0104, 0.9590,
        1.0167, 1.0037, 0.9930, 0.9762, 0.9956, 0.9942, 1.0165, 0.9980, 1.0092,
        0.9829, 0.9944, 0.9830, 0.9874, 1.0091, 0.9831, 0.9782, 1.0202, 0.9868,
        1.0077, 0.9908, 0.9947, 0.9936, 0.9960, 0.9866, 0.9911, 0.9978, 0.9795,
        0.9977, 0.9957, 0.9864, 0.9823, 1.0033, 0.9989, 0.9991, 0.9825, 0.9926,
        1.0142, 0.9935, 0.9917, 1.0018, 0.9955, 0.9943, 1.0007, 0.9589, 0.9539,
        0.9900])
##########################################################
prot_encoder.encoder.layers.2.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0032,  0.0067, -0.0154, -0.0021, -0.0031,  0.0034,  0.0080, -0.0011,
        -0.0060, -0.0069,  0.0038, -0.0055, -0.0017, -0.0046,  0.0046,  0.0018,
        -0.0032, -0.0073,  0.0050,  0.0012,  0.0075, -0.0019, -0.0042,  0.0015,
        -0.0079, -0.0130,  0.0015, -0.0082, -0.0020, -0.0200,  0.0087,  0.0086,
        -0.0082, -0.0034,  0.0118,  0.0005, -0.0067, -0.0022,  0.0066, -0.0002,
         0.0006,  0.0043,  0.0028, -0.0043, -0.0085, -0.0035,  0.0031,  0.0010,
        -0.0039, -0.0002,  0.0038, -0.0082, -0.0042,  0.0008, -0.0005,  0.0080,
        -0.0052,  0.0108, -0.0067,  0.0024,  0.0002,  0.0046, -0.0078, -0.0056])
##########################################################
cross_encoder.encoder.layers.0.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[ 9.5480e-02, -5.3976e-02, -4.4230e-02,  ...,  4.1604e-02,
         -6.7139e-02,  1.1841e-01],
        [ 8.9119e-02,  1.0533e-01,  9.5049e-02,  ..., -8.5616e-02,
         -8.9867e-03, -8.2777e-02],
        [-1.0176e-01, -1.2663e-01, -1.2876e-01,  ..., -1.6781e-03,
         -3.7060e-02,  1.1631e-01],
        ...,
        [-9.0969e-02, -1.4966e-01,  1.5163e-01,  ...,  4.3455e-04,
         -1.2484e-01, -1.0261e-04],
        [-7.9562e-02, -6.6711e-02,  7.4263e-04,  ...,  1.0160e-01,
         -1.4774e-01,  2.3741e-02],
        [-5.7534e-02, -2.9012e-03,  7.3844e-02,  ..., -7.0345e-02,
         -5.6719e-02,  2.9196e-02]])
tensor([[ 0.1125, -0.0081, -0.0208,  ...,  0.0233, -0.0842,  0.0904],
        [ 0.0983,  0.0842,  0.0650,  ..., -0.0533, -0.0376, -0.1000],
        [-0.0862, -0.1179, -0.0879,  ..., -0.0278, -0.0424,  0.1009],
        ...,
        [-0.0735, -0.1542,  0.1235,  ..., -0.0064, -0.1268,  0.0037],
        [-0.0717, -0.0800,  0.0005,  ...,  0.0815, -0.1549,  0.0380],
        [-0.0561, -0.0097,  0.0811,  ..., -0.0582, -0.0377,  0.0121]])
##########################################################
cross_encoder.encoder.layers.0.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-5.5666e-02, -6.7876e-04, -9.0133e-03,  1.3028e-02,  6.7461e-04,
        -4.6685e-02, -4.0842e-03,  2.5740e-02, -1.1367e-03, -4.3984e-03,
        -2.4938e-02,  1.8738e-02, -8.9935e-03, -2.7489e-03,  2.1068e-02,
        -1.7708e-02,  2.6946e-02,  4.3904e-03, -9.1338e-04,  3.2070e-02,
        -5.8440e-03,  4.0294e-03, -1.6908e-02, -1.8257e-02, -3.1113e-02,
         3.1725e-02,  1.8093e-02, -4.4590e-04,  3.6704e-03,  1.6994e-02,
         3.3073e-03,  3.4640e-03,  7.5692e-03, -4.2261e-02,  5.3670e-05,
        -4.3774e-03, -3.0939e-02,  8.5719e-04, -5.7680e-03, -1.9051e-03,
        -1.7166e-03, -2.4941e-03, -7.2482e-03,  4.0344e-03,  2.7542e-02,
         1.0221e-02,  5.8799e-03,  1.4034e-02,  5.8826e-03, -1.5955e-02,
        -3.1827e-02,  3.1888e-03, -2.3831e-02,  2.1224e-02, -3.2106e-03,
         5.7192e-03,  9.9473e-03,  2.7528e-02,  1.8402e-03,  3.1594e-02,
        -1.2796e-03, -4.1043e-02,  7.3994e-03,  1.3876e-03, -3.0626e-05,
        -1.7309e-05, -3.3987e-05, -5.3254e-05, -2.9792e-05, -3.5571e-05,
        -5.0184e-06,  5.5932e-06, -1.3810e-05, -4.0773e-05, -2.9742e-05,
        -1.5520e-05, -5.1365e-05, -6.4494e-06,  1.6097e-05, -9.3685e-05,
         5.8999e-05, -3.6202e-05, -6.9381e-06,  4.3541e-05, -1.2883e-05,
         4.7486e-06, -4.1174e-05,  3.8934e-05, -4.4089e-06,  1.3468e-05,
        -1.6199e-05, -1.9040e-05, -3.8765e-05,  1.7174e-05, -4.2658e-06,
        -2.3781e-05, -3.8026e-05, -9.7597e-06,  2.6063e-06,  2.8132e-05,
         6.1686e-05,  1.3494e-06,  1.9281e-05, -2.5269e-05,  3.0313e-05,
         2.4388e-05, -2.4377e-05, -1.3697e-05,  4.0561e-05, -3.5869e-06,
         6.5282e-05,  7.0023e-06, -2.3996e-05,  2.9587e-06,  2.5829e-05,
         3.2862e-05,  2.8660e-05,  2.9477e-05,  3.9582e-05, -1.2383e-06,
         1.8315e-05,  2.3511e-05, -3.5426e-05,  8.0110e-06, -4.2441e-05,
         5.1116e-05, -2.5981e-05,  9.5556e-06,  1.5316e-03,  2.1123e-03,
        -3.9896e-04,  4.3464e-03,  4.0766e-03, -7.6844e-03, -7.9970e-03,
         1.1712e-02,  1.6730e-02, -1.1988e-02, -1.6646e-03,  4.9310e-03,
        -2.3587e-03, -8.6650e-03,  9.5585e-03,  1.4233e-02, -4.5623e-03,
        -5.2449e-03, -3.7759e-04,  7.3547e-03,  3.3435e-03,  1.1859e-03,
        -6.4029e-03, -5.5434e-04,  2.5852e-03,  2.3352e-03, -1.5704e-02,
         1.1374e-02, -2.0888e-03,  4.6708e-04, -1.5292e-04, -2.1233e-03,
         7.8102e-03, -6.9581e-03, -8.5231e-05,  6.1389e-03,  1.6917e-03,
        -1.6666e-03, -3.4687e-04, -1.7465e-02, -1.0564e-02, -6.3753e-03,
         2.0082e-03,  5.4875e-03, -1.4676e-03,  2.5676e-04, -4.5771e-03,
        -3.9320e-03,  2.9505e-03, -3.1305e-03,  1.1038e-02,  7.5172e-03,
         4.2718e-05,  5.4128e-04, -6.1804e-03,  3.0381e-03, -3.7263e-03,
         4.8932e-03,  5.6002e-03, -3.0251e-03, -4.1954e-03, -2.0300e-03,
        -8.5950e-03,  1.8013e-02])
##########################################################
cross_encoder.encoder.layers.0.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[-0.0136,  0.0440, -0.0669,  ...,  0.0623,  0.0337, -0.0594],
        [ 0.0483, -0.0645, -0.0241,  ..., -0.0390,  0.0064,  0.0038],
        [ 0.0827, -0.1105,  0.0702,  ..., -0.0449, -0.0282, -0.0116],
        ...,
        [ 0.1207, -0.0228, -0.0196,  ...,  0.0753, -0.0396,  0.0814],
        [ 0.0839,  0.0745,  0.1061,  ...,  0.0389, -0.0010, -0.1144],
        [-0.0288, -0.0658,  0.0845,  ...,  0.0897,  0.1207, -0.0189]])
tensor([[-0.0427,  0.0184, -0.0459,  ...,  0.0574,  0.0175, -0.0608],
        [ 0.0501, -0.0409, -0.0327,  ..., -0.0314,  0.0124,  0.0013],
        [ 0.0405, -0.1234,  0.0859,  ..., -0.0534, -0.0396, -0.0043],
        ...,
        [ 0.1200,  0.0062, -0.0274,  ...,  0.0857, -0.0382,  0.0882],
        [ 0.0943,  0.0421,  0.0866,  ...,  0.0354,  0.0082, -0.1009],
        [-0.0434, -0.0911,  0.0710,  ...,  0.0793,  0.1284, -0.0196]])
##########################################################
cross_encoder.encoder.layers.0.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0077,  0.0049, -0.0104, -0.0064, -0.0035,  0.0028,  0.0073,  0.0033,
         0.0022, -0.0098,  0.0081, -0.0086,  0.0023, -0.0054,  0.0047,  0.0065,
        -0.0021, -0.0008,  0.0061,  0.0063,  0.0034, -0.0005, -0.0069,  0.0051,
        -0.0087, -0.0132,  0.0063, -0.0053, -0.0095, -0.0020,  0.0015,  0.0012,
        -0.0039, -0.0054,  0.0067, -0.0008, -0.0002,  0.0067,  0.0075,  0.0028,
         0.0037,  0.0081,  0.0068,  0.0010,  0.0026,  0.0085, -0.0052,  0.0030,
         0.0010,  0.0050,  0.0015, -0.0101, -0.0019,  0.0038, -0.0078,  0.0042,
         0.0073, -0.0046,  0.0066, -0.0002, -0.0042,  0.0026, -0.0071, -0.0001])
##########################################################
cross_encoder.encoder.layers.0.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0678, -0.2337,  0.2171,  ..., -0.2188, -0.0136,  0.2359],
        [ 0.2058, -0.0004,  0.0116,  ..., -0.0927,  0.1997, -0.2277],
        [-0.0247, -0.0600, -0.0055,  ...,  0.2405, -0.0982,  0.2276],
        ...,
        [-0.1015,  0.1806,  0.1072,  ...,  0.1474, -0.1965, -0.0909],
        [ 0.2491,  0.1632,  0.1784,  ...,  0.2300, -0.1583, -0.0943],
        [ 0.0628, -0.1603, -0.1022,  ..., -0.0533, -0.1528,  0.2037]])
tensor([[-5.0834e-02, -2.4344e-01,  2.3650e-01,  ..., -2.1942e-01,
         -7.1680e-03,  2.1074e-01],
        [ 1.9931e-01,  1.9740e-02, -2.2626e-04,  ..., -9.6105e-02,
          1.8959e-01, -2.2005e-01],
        [ 2.1974e-02, -3.6532e-02, -4.4931e-02,  ...,  2.2349e-01,
         -1.0630e-01,  2.0408e-01],
        ...,
        [-9.4895e-02,  2.0069e-01,  9.9628e-02,  ...,  1.5016e-01,
         -1.9122e-01, -8.0922e-02],
        [ 2.6919e-01,  1.6482e-01,  1.9929e-01,  ...,  2.5538e-01,
         -1.7373e-01, -7.7906e-02],
        [ 5.3796e-02, -1.5181e-01, -2.5275e-02,  ..., -5.0854e-02,
         -1.5276e-01,  2.1204e-01]])
##########################################################
cross_encoder.encoder.layers.0.linear1.bias shape: torch.Size([32])
tensor([ 0.1036,  0.0769, -0.1048,  0.0900,  0.0911, -0.0530, -0.0834,  0.0725,
         0.0109,  0.0349,  0.0341,  0.0811, -0.1108,  0.0776, -0.1215, -0.0175,
        -0.0606, -0.0375, -0.0124, -0.0543, -0.0829,  0.1174, -0.0470, -0.0915,
        -0.0648, -0.0569,  0.1149, -0.0131, -0.0112,  0.0136, -0.0736, -0.0552])
tensor([ 0.0927,  0.0633, -0.1325,  0.0785,  0.0901, -0.0552, -0.0835,  0.0386,
         0.0051,  0.0270,  0.0182,  0.0735, -0.1056,  0.0763, -0.1435, -0.0212,
        -0.0631, -0.0544, -0.0244, -0.0752, -0.1157,  0.0955, -0.0592, -0.0815,
        -0.0804, -0.0629,  0.1065, -0.0314, -0.0338,  0.0114, -0.0816, -0.0732])
##########################################################
cross_encoder.encoder.layers.0.linear2.weight shape: torch.Size([64, 32])
tensor([[ 0.1131,  0.0105, -0.1796,  ...,  0.0139,  0.1910, -0.0891],
        [ 0.0489, -0.0874,  0.0807,  ..., -0.2097,  0.2121,  0.1391],
        [ 0.1806, -0.1776, -0.2453,  ...,  0.1186,  0.0975, -0.0711],
        ...,
        [-0.0617, -0.2260, -0.1390,  ..., -0.2182, -0.1682, -0.2296],
        [-0.2017, -0.0048,  0.0651,  ...,  0.0837,  0.1802,  0.1873],
        [-0.1737, -0.0012, -0.2394,  ...,  0.2209,  0.0455, -0.0173]])
tensor([[ 0.1149,  0.0109, -0.2051,  ..., -0.0166,  0.1919, -0.0490],
        [ 0.0527, -0.0873,  0.0911,  ..., -0.2085,  0.2083,  0.1489],
        [ 0.1848, -0.1835, -0.2431,  ...,  0.1187,  0.1003, -0.0660],
        ...,
        [-0.0615, -0.2261, -0.1510,  ..., -0.2124, -0.1502, -0.2403],
        [-0.2127, -0.0125,  0.0592,  ...,  0.0575,  0.1814,  0.1627],
        [-0.1693, -0.0042, -0.1817,  ...,  0.2484,  0.0623, -0.0232]])
##########################################################
cross_encoder.encoder.layers.0.linear2.bias shape: torch.Size([64])
tensor([ 0.0415,  0.1007, -0.0502,  0.0428, -0.0063,  0.0823,  0.0751, -0.0905,
         0.0573,  0.1262, -0.1460, -0.1314,  0.0484, -0.0539, -0.0791, -0.1170,
        -0.1549, -0.1228,  0.0167, -0.1681, -0.1179, -0.0561,  0.1268,  0.0229,
         0.1692,  0.0667, -0.1008,  0.0821,  0.1373,  0.1047, -0.0153, -0.1048,
        -0.0590,  0.1463, -0.1064, -0.0830,  0.0252,  0.0086, -0.0226,  0.0290,
        -0.0292, -0.0920, -0.0040, -0.1454,  0.0341,  0.0092,  0.0552, -0.1274,
        -0.0646, -0.0860, -0.1609, -0.1009,  0.0606, -0.0366,  0.0860, -0.0581,
         0.0370, -0.0633, -0.0787, -0.1207,  0.0144, -0.1087, -0.0672,  0.1562])
tensor([ 0.0365,  0.1006, -0.0504,  0.0307, -0.0073,  0.0852,  0.0770, -0.0880,
         0.0648,  0.1193, -0.1354, -0.1342,  0.0482, -0.0565, -0.0763, -0.1107,
        -0.1492, -0.1285,  0.0188, -0.1713, -0.1138, -0.0600,  0.1221,  0.0239,
         0.1614,  0.0559, -0.0928,  0.0847,  0.1293,  0.1029, -0.0126, -0.0903,
        -0.0562,  0.1384, -0.1022, -0.0794,  0.0191,  0.0104, -0.0112,  0.0247,
        -0.0219, -0.0853, -0.0004, -0.1456,  0.0358,  0.0239,  0.0501, -0.1269,
        -0.0668, -0.0764, -0.1534, -0.1069,  0.0464, -0.0313,  0.0770, -0.0522,
         0.0354, -0.0772, -0.0737, -0.1128,  0.0133, -0.1047, -0.0788,  0.1601])
##########################################################
cross_encoder.encoder.layers.0.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0124, 0.9873, 1.0125, 0.9959, 0.9984, 1.0118, 0.9971, 1.0017, 0.9990,
        0.9620, 0.9856, 0.9879, 0.9984, 1.0115, 0.9832, 1.0030, 1.0072, 0.9891,
        0.9770, 1.0101, 0.9955, 1.0032, 0.9961, 0.9903, 0.9945, 1.0138, 0.9961,
        0.9966, 0.9899, 1.0051, 0.9825, 0.9771, 0.9928, 0.9905, 1.0086, 1.0259,
        1.0135, 1.0159, 1.0027, 1.0119, 1.0211, 0.9890, 1.0081, 1.0142, 1.0180,
        0.9988, 1.0291, 1.0101, 1.0113, 1.0195, 0.9909, 1.0139, 1.0041, 1.0243,
        1.0066, 0.9946, 1.0075, 0.9704, 1.0170, 1.0150, 1.0058, 0.9835, 1.0016,
        0.9838])
##########################################################
cross_encoder.encoder.layers.0.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-7.3485e-03,  4.5871e-03, -9.6869e-03, -6.2527e-03, -2.6044e-03,
         1.7304e-03,  6.6731e-03,  1.8496e-03,  1.8051e-03, -8.9694e-03,
         7.9199e-03, -8.9080e-03,  8.6992e-04, -6.1038e-03,  4.6418e-03,
         6.7492e-03, -2.5078e-03, -3.1114e-04,  6.8581e-03,  5.8967e-03,
         3.7158e-03,  3.7427e-05, -6.9643e-03,  6.0431e-03, -9.6177e-03,
        -1.3633e-02,  6.0296e-03, -4.8704e-03, -9.2548e-03, -2.7430e-03,
         1.1142e-04,  2.8423e-03, -4.5409e-03, -4.5015e-03,  6.1816e-03,
        -4.4879e-04,  1.1783e-03,  7.7681e-03,  8.7248e-03,  3.7592e-03,
         4.2554e-03,  8.6973e-03,  5.6972e-03,  1.2506e-04,  2.3075e-03,
         1.0097e-02, -4.7487e-03,  3.9990e-03,  1.0090e-03,  5.9799e-03,
         2.1045e-03, -1.1700e-02, -2.1780e-03,  2.6692e-03, -6.4486e-03,
         3.5829e-03,  7.9313e-03, -4.3477e-03,  7.0745e-03, -6.4344e-04,
        -3.3531e-03,  2.7288e-03, -7.5664e-03,  4.2240e-04])
##########################################################
cross_encoder.encoder.layers.0.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0084, 0.9975, 1.0091, 0.9914, 1.0050, 1.0213, 0.9854, 1.0191, 0.9974,
        0.9833, 0.9892, 1.0016, 1.0046, 1.0197, 0.9831, 1.0166, 1.0035, 0.9972,
        0.9917, 1.0028, 1.0126, 1.0186, 0.9935, 0.9927, 1.0062, 1.0047, 1.0084,
        1.0041, 0.9983, 0.9984, 0.9697, 0.9945, 1.0018, 0.9832, 1.0054, 1.0238,
        1.0225, 1.0101, 1.0058, 1.0080, 1.0089, 0.9912, 1.0162, 1.0186, 1.0080,
        0.9944, 1.0045, 1.0084, 1.0026, 1.0078, 0.9911, 1.0198, 0.9904, 1.0286,
        1.0121, 1.0050, 1.0050, 0.9867, 1.0162, 0.9900, 0.9982, 0.9782, 0.9930,
        0.9852])
##########################################################
cross_encoder.encoder.layers.0.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-3.9371e-03, -4.3587e-05,  1.2101e-03, -1.1156e-02,  1.3657e-04,
         1.4150e-03,  2.9087e-03,  4.9402e-03,  2.7291e-03, -7.7210e-03,
         8.3623e-03, -1.2298e-03,  2.0621e-03, -5.0363e-03,  1.0710e-03,
         4.5366e-03,  1.0077e-02, -4.1120e-03,  1.4411e-04, -8.1691e-04,
         2.8507e-03, -1.5302e-03, -3.3219e-03,  5.8745e-03, -9.5424e-03,
        -1.3789e-02,  6.0097e-03,  2.5221e-04, -1.0483e-02, -2.2435e-04,
         2.1379e-03,  1.3516e-02,  1.0596e-03, -7.9925e-03,  5.3021e-03,
         2.2494e-03, -6.4197e-03,  1.4969e-03,  9.6710e-03, -3.0991e-03,
         3.8767e-03,  6.5966e-03,  6.1834e-03, -2.0706e-03, -2.2379e-05,
         1.5649e-02, -6.5222e-03, -2.6330e-03, -5.9436e-03,  9.0840e-03,
         5.6201e-03, -4.1565e-03, -1.3118e-02,  5.3217e-03, -9.4877e-03,
         2.7927e-03, -2.1856e-03, -7.4809e-03,  3.2582e-03,  6.5098e-03,
        -4.3897e-04,  3.3089e-03, -1.5388e-02,  5.5446e-03])
##########################################################
cross_encoder.encoder.layers.1.self_attn.in_proj_weight shape: torch.Size([192, 64])
tensor([[ 9.5480e-02, -5.3976e-02, -4.4230e-02,  ...,  4.1604e-02,
         -6.7139e-02,  1.1841e-01],
        [ 8.9119e-02,  1.0533e-01,  9.5049e-02,  ..., -8.5616e-02,
         -8.9867e-03, -8.2777e-02],
        [-1.0176e-01, -1.2663e-01, -1.2876e-01,  ..., -1.6781e-03,
         -3.7060e-02,  1.1631e-01],
        ...,
        [-9.0969e-02, -1.4966e-01,  1.5163e-01,  ...,  4.3455e-04,
         -1.2484e-01, -1.0261e-04],
        [-7.9562e-02, -6.6711e-02,  7.4263e-04,  ...,  1.0160e-01,
         -1.4774e-01,  2.3741e-02],
        [-5.7534e-02, -2.9012e-03,  7.3844e-02,  ..., -7.0345e-02,
         -5.6719e-02,  2.9196e-02]])
tensor([[ 0.0936, -0.0223, -0.0594,  ...,  0.0217, -0.0802,  0.0595],
        [ 0.0403,  0.0990,  0.1082,  ..., -0.1244, -0.0229, -0.0563],
        [-0.0611, -0.1182, -0.1122,  ..., -0.0505, -0.0526,  0.0749],
        ...,
        [-0.0821, -0.1371,  0.1251,  ..., -0.0385, -0.1274,  0.0145],
        [-0.0661, -0.0620,  0.0053,  ...,  0.0941, -0.1443,  0.0187],
        [-0.0498, -0.0187,  0.0884,  ..., -0.0632, -0.0409,  0.0123]])
##########################################################
cross_encoder.encoder.layers.1.self_attn.in_proj_bias shape: torch.Size([192])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-2.4256e-02, -3.5068e-02, -4.1274e-03, -5.3515e-03,  6.5466e-03,
        -1.5560e-02, -1.4258e-02,  2.3906e-02, -2.9570e-03,  4.4869e-03,
        -2.4827e-02, -4.3249e-03,  4.4925e-03,  6.8933e-03, -4.2636e-05,
         9.7802e-04,  3.8868e-03,  1.0839e-02, -5.6330e-04,  3.3210e-02,
        -6.5215e-03,  1.0651e-02, -9.7949e-04, -7.8904e-03, -5.1059e-03,
        -3.3134e-03,  4.5785e-03,  8.7376e-03, -1.4154e-02,  1.0101e-02,
         5.3367e-03,  4.9533e-03,  4.0955e-03, -1.9043e-03,  7.5548e-03,
        -2.3762e-02, -6.2671e-02, -4.0427e-03, -1.2770e-02,  7.6449e-03,
         2.1336e-03, -3.3687e-03,  4.7444e-03, -3.5100e-03,  7.0746e-02,
         2.6341e-02,  1.2176e-02,  2.4000e-03,  6.3053e-03, -1.5466e-02,
        -3.8586e-03, -4.7862e-03, -5.8343e-02,  5.5277e-04, -2.0887e-02,
         3.2752e-02,  4.0581e-03,  5.9543e-03,  1.1425e-02,  3.6265e-03,
        -1.4172e-02, -2.0538e-02, -3.8282e-03, -8.4104e-03, -6.8472e-06,
         1.3726e-05, -9.5012e-06, -3.5659e-05,  7.7621e-06, -2.0001e-06,
         1.3326e-05,  1.4552e-05, -8.8805e-06, -3.2151e-06,  3.3499e-05,
        -1.4934e-05, -3.5665e-06, -2.6505e-05,  9.0984e-06, -2.0379e-05,
         3.6683e-05, -4.4367e-06, -3.2670e-06, -1.1657e-05,  5.6010e-06,
        -3.4045e-06,  2.8766e-05, -3.0516e-05, -8.3356e-06,  5.3559e-05,
         3.5188e-05,  6.1451e-06,  1.4021e-05,  1.0531e-05,  2.2762e-05,
        -1.1877e-05, -1.3801e-05,  2.1874e-05, -8.0624e-06,  1.7867e-05,
        -4.1768e-06, -1.7342e-05,  4.2341e-05,  6.8213e-06,  1.0750e-05,
        -2.2452e-05,  4.2446e-06, -9.1081e-07, -2.7944e-05,  2.1281e-05,
         2.8600e-05, -4.5234e-07, -1.6347e-05, -1.3596e-06, -6.1469e-06,
        -1.1744e-05, -3.0483e-05,  3.1507e-05,  6.9602e-06, -1.6783e-05,
        -7.2472e-06,  5.4939e-06,  1.8304e-05, -1.0337e-05,  1.1501e-06,
        -9.0808e-06,  1.1275e-05, -1.0289e-05, -9.2781e-04, -4.7789e-03,
         4.0422e-03,  2.8405e-03, -7.7850e-03, -9.7668e-03, -3.1677e-03,
        -2.2890e-05,  1.7374e-02, -2.3865e-03, -6.5009e-03,  4.9089e-03,
         6.5157e-03, -4.3994e-03,  1.1277e-02,  1.2095e-02, -7.8516e-03,
         3.0531e-03, -7.2177e-03,  2.8688e-03,  4.1902e-03,  5.1212e-03,
        -4.8977e-03, -3.9269e-03,  8.7392e-03,  8.9934e-03, -1.7669e-02,
         1.4559e-02,  3.1175e-03,  2.1677e-04, -3.8394e-03,  5.3558e-03,
         6.0708e-03, -5.7286e-03,  4.7369e-03, -7.0383e-03,  4.7429e-03,
        -9.6956e-04, -7.2848e-03, -8.3701e-03, -1.3996e-02,  3.6504e-03,
         1.8516e-03,  7.5705e-03, -5.7791e-03,  6.0582e-03, -5.2236e-03,
        -2.6402e-04, -6.8206e-03,  5.1399e-04,  1.2451e-02,  1.1032e-03,
        -1.1994e-02,  2.0849e-04,  2.4883e-03,  8.2645e-03, -9.0883e-04,
         5.4808e-03,  4.5977e-03,  1.0425e-03, -1.0143e-02, -3.6876e-04,
        -1.8983e-03,  1.5353e-02])
##########################################################
cross_encoder.encoder.layers.1.self_attn.out_proj.weight shape: torch.Size([64, 64])
tensor([[-0.0136,  0.0440, -0.0669,  ...,  0.0623,  0.0337, -0.0594],
        [ 0.0483, -0.0645, -0.0241,  ..., -0.0390,  0.0064,  0.0038],
        [ 0.0827, -0.1105,  0.0702,  ..., -0.0449, -0.0282, -0.0116],
        ...,
        [ 0.1207, -0.0228, -0.0196,  ...,  0.0753, -0.0396,  0.0814],
        [ 0.0839,  0.0745,  0.1061,  ...,  0.0389, -0.0010, -0.1144],
        [-0.0288, -0.0658,  0.0845,  ...,  0.0897,  0.1207, -0.0189]])
tensor([[-0.0472,  0.0158, -0.0536,  ...,  0.0580,  0.0146, -0.0582],
        [ 0.0167, -0.0583, -0.0209,  ..., -0.0327, -0.0056,  0.0077],
        [ 0.1032, -0.1026,  0.0734,  ..., -0.0464, -0.0304, -0.0110],
        ...,
        [ 0.0776, -0.0079, -0.0119,  ...,  0.0832, -0.0285,  0.0789],
        [ 0.1099,  0.0607,  0.1108,  ...,  0.0273,  0.0119, -0.0972],
        [-0.0341, -0.0916,  0.0700,  ...,  0.0934,  0.1230, -0.0206]])
##########################################################
cross_encoder.encoder.layers.1.self_attn.out_proj.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0062, -0.0029,  0.0005, -0.0039,  0.0022,  0.0021,  0.0011,  0.0026,
         0.0046,  0.0023,  0.0025, -0.0028,  0.0060, -0.0076, -0.0060,  0.0051,
         0.0074, -0.0071, -0.0027,  0.0020, -0.0028,  0.0036, -0.0065,  0.0048,
        -0.0037, -0.0027,  0.0001,  0.0025, -0.0081,  0.0067, -0.0046,  0.0097,
         0.0096, -0.0051,  0.0086, -0.0008, -0.0051,  0.0031,  0.0120,  0.0035,
         0.0066,  0.0030,  0.0046, -0.0032,  0.0027,  0.0093, -0.0034, -0.0045,
        -0.0001,  0.0024,  0.0104, -0.0030, -0.0070, -0.0018, -0.0065,  0.0095,
         0.0040, -0.0155,  0.0019,  0.0028, -0.0083,  0.0007, -0.0120,  0.0030])
##########################################################
cross_encoder.encoder.layers.1.linear1.weight shape: torch.Size([32, 64])
tensor([[-0.0291, -0.0993, -0.0075,  ..., -0.2280,  0.1421,  0.0570],
        [-0.2254, -0.0441,  0.1274,  ..., -0.1232,  0.1677, -0.0821],
        [ 0.1022,  0.1327,  0.0039,  ..., -0.1963, -0.2222, -0.1489],
        ...,
        [ 0.1492, -0.0180,  0.2363,  ...,  0.1982, -0.0034,  0.2135],
        [-0.0640, -0.1610, -0.0842,  ...,  0.2179,  0.1270, -0.1972],
        [ 0.0739,  0.1357, -0.1649,  ...,  0.0272, -0.1650, -0.0181]])
tensor([[-0.0410, -0.0917, -0.0200,  ..., -0.2498,  0.1382,  0.0405],
        [-0.2153, -0.0220,  0.1121,  ..., -0.1177,  0.1458, -0.1038],
        [ 0.0937,  0.1479, -0.0274,  ..., -0.1571, -0.2181, -0.1240],
        ...,
        [ 0.1371, -0.0006,  0.2529,  ...,  0.1911, -0.0450,  0.1694],
        [-0.0929, -0.1968, -0.0556,  ...,  0.2076,  0.1257, -0.1974],
        [ 0.0432,  0.0843, -0.1901,  ...,  0.0167, -0.1962, -0.0348]])
##########################################################
cross_encoder.encoder.layers.1.linear1.bias shape: torch.Size([32])
tensor([ 0.1036,  0.0769, -0.1048,  0.0900,  0.0911, -0.0530, -0.0834,  0.0725,
         0.0109,  0.0349,  0.0341,  0.0811, -0.1108,  0.0776, -0.1215, -0.0175,
        -0.0606, -0.0375, -0.0124, -0.0543, -0.0829,  0.1174, -0.0470, -0.0915,
        -0.0648, -0.0569,  0.1149, -0.0131, -0.0112,  0.0136, -0.0736, -0.0552])
tensor([ 0.0793,  0.0666, -0.1001,  0.0817,  0.0777, -0.0603, -0.0813,  0.0319,
         0.0147,  0.0299,  0.0088,  0.0716, -0.1007,  0.0669, -0.1501, -0.0247,
        -0.0872, -0.0585, -0.0332, -0.0603, -0.1025,  0.1002, -0.0587, -0.0985,
        -0.0784, -0.0610,  0.1115, -0.0404, -0.0215,  0.0062, -0.0912, -0.0738])
##########################################################
cross_encoder.encoder.layers.1.linear2.weight shape: torch.Size([64, 32])
tensor([[ 2.3042e-01, -4.3780e-02, -2.1996e-01,  ..., -7.2955e-02,
         -1.3096e-01,  1.9445e-01],
        [ 1.3182e-01,  1.2537e-01,  7.4616e-02,  ...,  1.4275e-01,
         -2.0955e-01,  2.3973e-01],
        [-2.1132e-01, -1.2640e-01, -1.7529e-01,  ..., -1.2335e-01,
          1.7389e-01, -2.3743e-01],
        ...,
        [-4.6439e-02,  1.8173e-01, -2.3976e-01,  ...,  9.8373e-02,
         -9.3544e-02, -1.6879e-01],
        [ 1.5246e-01,  2.2316e-01,  5.9942e-02,  ...,  1.6274e-01,
         -5.5760e-05, -5.9709e-02],
        [-2.2634e-01,  8.8011e-02,  5.0172e-03,  ...,  1.3247e-01,
         -1.9026e-01,  1.2350e-01]])
tensor([[ 0.2085, -0.0622, -0.2091,  ..., -0.0714, -0.1346,  0.1650],
        [ 0.1219,  0.1276,  0.0575,  ...,  0.1421, -0.2452,  0.2396],
        [-0.2133, -0.1301, -0.1858,  ..., -0.1082,  0.1843, -0.2410],
        ...,
        [-0.0400,  0.1950, -0.2218,  ...,  0.0982, -0.0947, -0.1454],
        [ 0.1487,  0.2207,  0.0527,  ...,  0.1583,  0.0231, -0.0569],
        [-0.2297,  0.0779, -0.0028,  ...,  0.1357, -0.2046,  0.1174]])
##########################################################
cross_encoder.encoder.layers.1.linear2.bias shape: torch.Size([64])
tensor([ 0.0415,  0.1007, -0.0502,  0.0428, -0.0063,  0.0823,  0.0751, -0.0905,
         0.0573,  0.1262, -0.1460, -0.1314,  0.0484, -0.0539, -0.0791, -0.1170,
        -0.1549, -0.1228,  0.0167, -0.1681, -0.1179, -0.0561,  0.1268,  0.0229,
         0.1692,  0.0667, -0.1008,  0.0821,  0.1373,  0.1047, -0.0153, -0.1048,
        -0.0590,  0.1463, -0.1064, -0.0830,  0.0252,  0.0086, -0.0226,  0.0290,
        -0.0292, -0.0920, -0.0040, -0.1454,  0.0341,  0.0092,  0.0552, -0.1274,
        -0.0646, -0.0860, -0.1609, -0.1009,  0.0606, -0.0366,  0.0860, -0.0581,
         0.0370, -0.0633, -0.0787, -0.1207,  0.0144, -0.1087, -0.0672,  0.1562])
tensor([ 0.0286,  0.0935, -0.0505,  0.0424,  0.0010,  0.0734,  0.0746, -0.0706,
         0.0637,  0.1230, -0.1439, -0.1290,  0.0602, -0.0624, -0.0863, -0.1134,
        -0.1505, -0.1280,  0.0065, -0.1642, -0.1166, -0.0518,  0.1108,  0.0231,
         0.1587,  0.0689, -0.1067,  0.0817,  0.1327,  0.1127, -0.0215, -0.0945,
        -0.0473,  0.1337, -0.0975, -0.0821,  0.0171,  0.0133, -0.0090,  0.0282,
        -0.0197, -0.0801, -0.0095, -0.1454,  0.0418,  0.0266,  0.0537, -0.1172,
        -0.0613, -0.0851, -0.1558, -0.1010,  0.0544, -0.0331,  0.0765, -0.0592,
         0.0456, -0.0743, -0.0694, -0.1126, -0.0096, -0.0946, -0.0706,  0.1544])
##########################################################
cross_encoder.encoder.layers.1.norm1.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9976, 0.9906, 0.9987, 0.9875, 0.9975, 1.0037, 0.9801, 1.0096, 0.9965,
        0.9870, 0.9962, 1.0029, 0.9948, 1.0203, 0.9903, 1.0085, 1.0004, 0.9826,
        0.9925, 0.9863, 1.0043, 1.0072, 0.9967, 0.9842, 0.9953, 1.0229, 1.0091,
        1.0031, 0.9928, 0.9960, 0.9826, 0.9968, 1.0029, 0.9887, 0.9892, 1.0156,
        1.0228, 0.9944, 0.9962, 1.0088, 1.0080, 0.9873, 1.0079, 1.0151, 1.0045,
        1.0000, 0.9989, 1.0124, 1.0075, 1.0131, 1.0001, 1.0175, 0.9938, 1.0215,
        1.0045, 1.0066, 1.0063, 0.9905, 1.0158, 1.0038, 0.9892, 0.9860, 0.9982,
        0.9767])
##########################################################
cross_encoder.encoder.layers.1.norm1.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0058, -0.0031,  0.0016, -0.0027,  0.0022,  0.0006,  0.0018,  0.0019,
         0.0045,  0.0024,  0.0010, -0.0021,  0.0058, -0.0080, -0.0066,  0.0055,
         0.0084, -0.0071, -0.0016,  0.0011, -0.0033,  0.0026, -0.0078,  0.0047,
        -0.0023, -0.0025, -0.0009,  0.0038, -0.0088,  0.0074, -0.0052,  0.0121,
         0.0082, -0.0045,  0.0085, -0.0017, -0.0031,  0.0045,  0.0117,  0.0030,
         0.0061,  0.0025,  0.0037, -0.0044,  0.0027,  0.0110, -0.0031, -0.0046,
        -0.0002,  0.0019,  0.0109, -0.0038, -0.0076, -0.0029, -0.0050,  0.0098,
         0.0045, -0.0154,  0.0012,  0.0018, -0.0074,  0.0014, -0.0134,  0.0048])
##########################################################
cross_encoder.encoder.layers.1.norm2.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9641, 0.9961, 0.9638, 0.9924, 0.9652, 0.9991, 0.9775, 0.9779, 0.9560,
        0.9833, 0.9671, 0.9579, 0.9771, 0.9661, 0.9750, 0.9686, 0.9750, 0.9961,
        0.9827, 0.9957, 0.9776, 0.9676, 0.9742, 0.9698, 0.9893, 0.9610, 0.9931,
        0.9916, 0.9976, 0.9846, 0.9649, 0.9462, 0.9760, 0.9695, 0.9763, 0.9648,
        0.9633, 0.9834, 0.9901, 0.9604, 0.9875, 0.9546, 0.9763, 0.9798, 0.9988,
        0.9485, 0.9816, 0.9611, 0.9875, 0.9782, 1.0008, 0.9969, 0.9886, 0.9940,
        0.9662, 0.9724, 0.9786, 0.9852, 0.9644, 0.9960, 0.9408, 0.9789, 0.9987,
        0.9684])
##########################################################
cross_encoder.encoder.layers.1.norm2.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0374, -0.0051, -0.0152,  0.0052,  0.0122, -0.0107, -0.0077,  0.0260,
         0.0144, -0.0099,  0.0308,  0.0234,  0.0181, -0.0196, -0.0068,  0.0196,
        -0.0097, -0.0007, -0.0170,  0.0123,  0.0109, -0.0052, -0.0086,  0.0102,
        -0.0148, -0.0248, -0.0090, -0.0215, -0.0066, -0.0118, -0.0021,  0.0244,
        -0.0044, -0.0323,  0.0176,  0.0063,  0.0070,  0.0106,  0.0048, -0.0028,
        -0.0008,  0.0152,  0.0041,  0.0209,  0.0013,  0.0382, -0.0125,  0.0187,
        -0.0127,  0.0040, -0.0051, -0.0040, -0.0116,  0.0083, -0.0214, -0.0110,
         0.0035, -0.0202,  0.0300,  0.0102, -0.0489,  0.0165, -0.0088,  0.0037])
##########################################################
ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[-0.1004, -0.2193, -0.1602,  ...,  0.0205, -0.1130,  0.0143],
        [ 0.0242,  0.1250,  0.1207,  ...,  0.0157,  0.1756, -0.2392],
        [ 0.0674, -0.1989,  0.0366,  ..., -0.0122, -0.0161,  0.0125],
        ...,
        [ 0.1491, -0.2222, -0.1375,  ..., -0.2403, -0.0509,  0.1612],
        [ 0.1434, -0.2093,  0.1723,  ..., -0.2073, -0.0123,  0.1026],
        [ 0.1470,  0.0748, -0.2314,  ..., -0.1421,  0.1112, -0.0400]])
tensor([[-0.1182, -0.2282, -0.1671,  ..., -0.0219, -0.1348,  0.0169],
        [ 0.0190,  0.1054,  0.0975,  ..., -0.0123,  0.1702, -0.2382],
        [ 0.0874, -0.2074,  0.0176,  ..., -0.0126, -0.0137,  0.0080],
        ...,
        [ 0.1489, -0.2098, -0.1460,  ..., -0.1976, -0.0498,  0.1875],
        [ 0.1614, -0.2194,  0.1787,  ..., -0.2006, -0.0282,  0.1074],
        [ 0.1527,  0.0696, -0.2138,  ..., -0.1524,  0.1479, -0.0294]])
##########################################################
ffn.dense1.bias shape: torch.Size([32])
tensor([ 0.0834, -0.0790,  0.0547,  0.0750,  0.1062, -0.1151,  0.0530, -0.0486,
        -0.1062,  0.0070,  0.0142,  0.0945,  0.1059,  0.0025, -0.0798, -0.1167,
        -0.0260, -0.0927,  0.0032,  0.0155, -0.0931,  0.0774,  0.0588,  0.0031,
        -0.0934,  0.0323,  0.1236, -0.0730,  0.0895, -0.0716, -0.0681, -0.1018])
tensor([ 0.0783, -0.0824,  0.0420,  0.0504,  0.0947, -0.1205,  0.0460, -0.0571,
        -0.1185,  0.0002, -0.0074,  0.0902,  0.1045, -0.0172, -0.0789, -0.1198,
        -0.0441, -0.0891, -0.0161,  0.0100, -0.0936,  0.0699,  0.0504, -0.0032,
        -0.1217,  0.0233,  0.1072, -0.0811,  0.0757, -0.0727, -0.0770, -0.1124])
##########################################################
ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[-0.1926, -0.0813,  0.0577,  ..., -0.0575, -0.2358,  0.1643],
        [ 0.0938, -0.1875, -0.1975,  ..., -0.0705, -0.2198, -0.0328],
        [-0.1294, -0.1350, -0.0437,  ...,  0.0385,  0.1048,  0.1136],
        ...,
        [-0.1721,  0.0061,  0.1800,  ...,  0.1827,  0.0786,  0.1055],
        [-0.1891,  0.0282,  0.2309,  ..., -0.1079,  0.1880, -0.0194],
        [-0.1690, -0.1920, -0.2316,  ...,  0.1416,  0.0443, -0.0230]])
tensor([[-0.1818, -0.0725,  0.0542,  ..., -0.0688, -0.2364,  0.1596],
        [ 0.0843, -0.1767, -0.2026,  ..., -0.0572, -0.2181, -0.0202],
        [-0.1364, -0.1324, -0.0491,  ...,  0.0342,  0.0973,  0.1045],
        ...,
        [-0.1426, -0.0007,  0.1796,  ...,  0.1816,  0.0631,  0.1311],
        [-0.1884,  0.0362,  0.2385,  ..., -0.0980,  0.1946, -0.0300],
        [-0.1988, -0.1886, -0.2301,  ...,  0.1324,  0.0305, -0.0212]])
##########################################################
ffn.dense2.bias shape: torch.Size([64])
tensor([-0.1581, -0.0969, -0.0354,  0.1090,  0.0404,  0.0045, -0.0977,  0.0941,
         0.0938,  0.0958, -0.0514, -0.0981, -0.0805, -0.0024,  0.0492,  0.0564,
         0.0582, -0.1434,  0.0433, -0.0830, -0.1363,  0.0023, -0.1001, -0.1103,
         0.1042, -0.1195, -0.0879,  0.0514,  0.0674, -0.1721, -0.0879,  0.0910,
         0.0584, -0.1666,  0.0809,  0.0470, -0.1543, -0.1345, -0.0306,  0.0753,
         0.0298, -0.0408,  0.1081,  0.0907, -0.0782, -0.1364, -0.0174, -0.1097,
         0.1706,  0.0033, -0.0117, -0.0243,  0.1098, -0.0010, -0.0410, -0.1485,
        -0.1352, -0.0537, -0.1366,  0.1591, -0.1359, -0.0397, -0.1128, -0.1525])
tensor([-0.1616, -0.0889, -0.0466,  0.0979,  0.0385,  0.0075, -0.0906,  0.1058,
         0.0903,  0.0792, -0.0334, -0.1023, -0.0829, -0.0102,  0.0596,  0.0624,
         0.0569, -0.1459,  0.0485, -0.0760, -0.1277, -0.0013, -0.0992, -0.1013,
         0.0858, -0.1432, -0.0781,  0.0456,  0.0584, -0.1781, -0.0861,  0.0959,
         0.0470, -0.1702,  0.0867,  0.0456, -0.1560, -0.1358, -0.0220,  0.0762,
         0.0337, -0.0329,  0.1183,  0.0947, -0.0817, -0.1306, -0.0209, -0.1037,
         0.1682,  0.0063, -0.0118, -0.0316,  0.1051,  0.0058, -0.0465, -0.1440,
        -0.1289, -0.0577, -0.1320,  0.1588, -0.1344, -0.0392, -0.1215, -0.1540])
##########################################################
addnorm.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0313, 0.9934, 1.0280, 1.0014, 1.0171, 1.0285, 0.9970, 0.9945, 0.9926,
        0.9671, 0.9792, 0.9869, 1.0015, 1.0085, 0.9879, 0.9986, 0.9998, 1.0042,
        0.9893, 1.0132, 1.0028, 1.0147, 0.9858, 0.9875, 0.9967, 0.9916, 0.9923,
        1.0005, 0.9969, 0.9975, 0.9830, 0.9821, 0.9911, 0.9946, 1.0278, 1.0284,
        1.0147, 1.0336, 1.0038, 1.0176, 1.0318, 0.9872, 1.0151, 1.0241, 1.0169,
        1.0074, 1.0276, 1.0080, 1.0020, 1.0184, 0.9918, 1.0167, 1.0074, 1.0254,
        1.0099, 0.9886, 1.0062, 0.9713, 1.0154, 1.0129, 0.9992, 0.9838, 0.9989,
        0.9865])
##########################################################
addnorm.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0032,  0.0066, -0.0109, -0.0096, -0.0024,  0.0042,  0.0094,  0.0095,
        -0.0044, -0.0177,  0.0154, -0.0047,  0.0013, -0.0085,  0.0122,  0.0035,
         0.0029, -0.0024,  0.0074,  0.0081,  0.0086, -0.0031,  0.0009,  0.0108,
        -0.0127, -0.0245,  0.0071, -0.0068, -0.0100, -0.0040,  0.0040,  0.0068,
        -0.0125, -0.0052,  0.0053, -0.0004, -0.0033,  0.0038,  0.0103,  0.0009,
         0.0024,  0.0071,  0.0103,  0.0003, -0.0050,  0.0080, -0.0062,  0.0010,
        -0.0060,  0.0071, -0.0028, -0.0063, -0.0059,  0.0070, -0.0086,  0.0032,
         0.0040, -0.0007,  0.0040, -0.0015,  0.0032, -0.0017, -0.0079,  0.0010])
##########################################################
decoder.embedding.weight shape: torch.Size([166, 64])
tensor([[-0.7521,  0.6339, -0.0983,  ...,  2.0002, -0.6166, -0.3209],
        [-2.1833, -1.8342,  0.5069,  ..., -0.2366,  1.2468, -0.1190],
        [-1.2079, -0.0726,  2.5627,  ...,  1.3592, -0.7687, -0.2382],
        ...,
        [ 0.5198, -1.6376,  0.2172,  ..., -0.9563,  0.1353, -0.7024],
        [-0.1590,  0.7802, -1.6020,  ...,  1.4914, -1.0065, -1.2416],
        [ 0.0204,  1.0802,  1.3069,  ...,  0.1496,  0.1485, -0.5313]])
tensor([[-0.7521,  0.6339, -0.0983,  ...,  2.0002, -0.6166, -0.3209],
        [-2.1833, -1.8342,  0.5069,  ..., -0.2366,  1.2468, -0.1190],
        [-1.1713, -0.0483,  2.5107,  ...,  1.3208, -0.7607, -0.2478],
        ...,
        [ 0.5198, -1.6376,  0.2172,  ..., -0.9563,  0.1353, -0.7024],
        [-0.1590,  0.7802, -1.6020,  ...,  1.4914, -1.0065, -1.2416],
        [ 0.0204,  1.0802,  1.3069,  ...,  0.1496,  0.1485, -0.5313]])
##########################################################
decoder.blks.block0.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.0270, -0.0470,  0.0670,  ...,  0.1332, -0.1217,  0.1113],
        [-0.0299, -0.1345, -0.1970,  ...,  0.0016,  0.0805,  0.0700],
        [-0.2094, -0.1654, -0.0281,  ..., -0.2144,  0.2065, -0.2122],
        ...,
        [ 0.0100, -0.1006, -0.0063,  ...,  0.2122, -0.1412, -0.0998],
        [-0.2037, -0.1727, -0.0874,  ...,  0.1372,  0.1991,  0.0527],
        [-0.0065, -0.1384,  0.0027,  ...,  0.0716, -0.1877, -0.0375]])
tensor([[ 4.1037e-02, -4.2954e-02,  6.9867e-02,  ...,  1.6060e-01,
         -1.2705e-01,  6.9563e-02],
        [ 1.5642e-04, -1.5326e-01, -1.9440e-01,  ...,  3.0340e-02,
          1.1164e-01,  5.2444e-02],
        [-1.7672e-01, -1.6765e-01, -1.1707e-02,  ..., -1.8280e-01,
          2.2704e-01, -2.3000e-01],
        ...,
        [ 4.4162e-02, -8.1096e-02, -5.9940e-03,  ...,  2.0450e-01,
         -1.5651e-01, -6.6049e-02],
        [-1.7803e-01, -1.5624e-01, -8.7859e-02,  ...,  1.4539e-01,
          1.8020e-01,  9.0834e-02],
        [ 1.3450e-02, -1.3276e-01, -3.9237e-03,  ...,  4.5109e-02,
         -2.0655e-01, -4.2758e-02]])
##########################################################
decoder.blks.block0.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.1462, -0.1336, -0.1590,  ...,  0.0662,  0.1271,  0.0825],
        [ 0.0273, -0.0847, -0.0378,  ..., -0.1452, -0.1058,  0.0251],
        [ 0.2042, -0.0938,  0.0927,  ..., -0.0748, -0.1532,  0.0507],
        ...,
        [-0.1985, -0.0415,  0.0024,  ..., -0.0906,  0.0252,  0.0208],
        [-0.0784, -0.1324, -0.1310,  ...,  0.0469,  0.1638, -0.0826],
        [-0.0702,  0.0415,  0.1105,  ...,  0.1089,  0.0464, -0.1732]])
tensor([[ 0.1527, -0.1188, -0.1599,  ...,  0.0889,  0.1071,  0.0877],
        [ 0.0102, -0.0884, -0.0345,  ..., -0.1471, -0.1154,  0.0536],
        [ 0.2299, -0.1106,  0.1010,  ..., -0.0891, -0.1620,  0.0725],
        ...,
        [-0.2136, -0.0336,  0.0362,  ..., -0.0788,  0.0230,  0.0268],
        [-0.0450, -0.1237, -0.1177,  ...,  0.0619,  0.1639, -0.0748],
        [-0.0406,  0.0393,  0.0658,  ...,  0.1100,  0.0664, -0.1967]])
##########################################################
decoder.blks.block0.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.1718, -0.0906,  0.1161,  ..., -0.1994, -0.1679, -0.0895],
        [ 0.1725, -0.1247,  0.0467,  ..., -0.0983,  0.1437, -0.0849],
        [-0.1800,  0.1943,  0.0783,  ...,  0.1976, -0.0623,  0.0683],
        ...,
        [ 0.1217,  0.0391,  0.1201,  ..., -0.0879,  0.0108,  0.0366],
        [-0.1177, -0.0274,  0.0518,  ..., -0.0197, -0.1705,  0.1055],
        [-0.0047,  0.0500, -0.2141,  ...,  0.1964,  0.0944,  0.0749]])
tensor([[ 0.1681, -0.0974,  0.1032,  ..., -0.1816, -0.1606, -0.0732],
        [ 0.1430, -0.1594,  0.0481,  ..., -0.0971,  0.1492, -0.0723],
        [-0.1602,  0.1675,  0.0558,  ...,  0.1824, -0.0645,  0.0342],
        ...,
        [ 0.1316, -0.0011,  0.1105,  ..., -0.0774,  0.0052,  0.0062],
        [-0.1464, -0.0453,  0.0657,  ...,  0.0092, -0.1358,  0.0943],
        [-0.0021,  0.0486, -0.1949,  ...,  0.1984,  0.0953,  0.0741]])
##########################################################
decoder.blks.block0.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.0976,  0.0360,  0.1764,  ...,  0.2013, -0.1035,  0.1703],
        [ 0.0087, -0.0282,  0.1604,  ...,  0.0199, -0.0008, -0.0948],
        [ 0.2142, -0.0081,  0.0738,  ..., -0.0270, -0.0953, -0.1640],
        ...,
        [-0.0200,  0.1955, -0.0040,  ..., -0.0241,  0.0516,  0.0947],
        [-0.0813, -0.1368, -0.0133,  ...,  0.0467, -0.0143, -0.0235],
        [-0.1168,  0.1504, -0.1629,  ...,  0.1516, -0.0155,  0.1652]])
tensor([[ 0.0683,  0.0478,  0.1110,  ...,  0.1966, -0.1350,  0.2012],
        [-0.0127, -0.0280,  0.0888,  ..., -0.0141,  0.0085, -0.1093],
        [ 0.2142, -0.0096,  0.0425,  ..., -0.0161, -0.0613, -0.1272],
        ...,
        [-0.0110,  0.1641,  0.0105,  ..., -0.0424,  0.0622,  0.0946],
        [-0.0803, -0.1434, -0.0341,  ...,  0.0453,  0.0233,  0.0181],
        [-0.1409,  0.1367, -0.1348,  ...,  0.1651,  0.0091,  0.1775]])
##########################################################
decoder.blks.block0.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0077, 0.9857, 1.0669, 1.0401, 0.9975, 0.9907, 0.9962, 1.0524, 1.0055,
        1.0182, 0.9951, 1.0791, 1.0280, 0.9828, 1.0090, 0.9790, 1.0276, 0.9977,
        0.9965, 1.0136, 1.0050, 0.9902, 1.0746, 1.0109, 0.9774, 0.9804, 1.0454,
        1.0285, 1.0466, 1.0527, 1.0068, 0.9787, 0.9979, 1.0386, 1.0528, 1.0623,
        1.0333, 1.0579, 0.9939, 1.0438, 1.0414, 0.9685, 1.0691, 1.0090, 1.0379,
        1.0552, 1.0202, 1.0593, 1.0592, 1.0226, 1.0372, 0.9753, 1.0340, 1.0476,
        1.0283, 0.9666, 1.0124, 0.9773, 0.9789, 0.9991, 0.9806, 1.0369, 1.0278,
        1.0604])
##########################################################
decoder.blks.block0.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0036,  0.0137, -0.0143,  0.0060,  0.0040, -0.0076, -0.0002, -0.0085,
        -0.0028,  0.0152,  0.0199,  0.0086, -0.0075, -0.0129,  0.0219, -0.0156,
        -0.0348,  0.0209,  0.0032, -0.0044,  0.0039,  0.0011, -0.0057,  0.0058,
        -0.0064,  0.0168, -0.0003,  0.0150,  0.0087,  0.0031,  0.0055,  0.0242,
         0.0160, -0.0288,  0.0069,  0.0022,  0.0082, -0.0013, -0.0189, -0.0077,
         0.0302,  0.0022, -0.0070, -0.0149, -0.0076,  0.0099, -0.0064, -0.0132,
        -0.0063,  0.0047, -0.0068, -0.0008,  0.0045, -0.0112, -0.0025, -0.0162,
         0.0065, -0.0255, -0.0057,  0.0089, -0.0054,  0.0175, -0.0181, -0.0165])
##########################################################
decoder.blks.block0.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.1261,  0.0574, -0.1749,  ..., -0.1839, -0.0330,  0.1731],
        [ 0.1956, -0.1468, -0.1843,  ..., -0.2091, -0.0625, -0.2128],
        [ 0.0210,  0.1471, -0.0004,  ..., -0.1426, -0.0719, -0.0778],
        ...,
        [-0.0688,  0.1946,  0.1518,  ..., -0.2020,  0.1830,  0.1451],
        [ 0.0107, -0.2115,  0.1745,  ...,  0.1419,  0.0009, -0.1337],
        [ 0.0878, -0.0805,  0.1540,  ..., -0.1896, -0.1417, -0.0355]])
tensor([[ 0.1342,  0.0537, -0.2165,  ..., -0.1903,  0.0163,  0.1958],
        [ 0.1980, -0.1252, -0.1710,  ..., -0.2110, -0.1105, -0.1936],
        [-0.0020,  0.0620, -0.0427,  ..., -0.1381, -0.0473, -0.0675],
        ...,
        [-0.0793,  0.2466,  0.1838,  ..., -0.2164,  0.1856,  0.1418],
        [-0.0064, -0.2906,  0.1186,  ...,  0.1820,  0.0145, -0.1437],
        [ 0.0708, -0.1129,  0.1917,  ..., -0.1636, -0.1582, -0.0456]])
##########################################################
decoder.blks.block0.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[-3.1067e-02, -1.8960e-01, -1.5328e-03,  ...,  8.4732e-02,
         -6.5591e-02,  3.4342e-02],
        [-1.2151e-01,  1.7795e-01,  1.5040e-01,  ..., -9.1838e-02,
         -1.8684e-01, -1.5137e-01],
        [-1.0104e-01, -3.5306e-02,  1.0071e-01,  ..., -3.5428e-02,
          3.0392e-02, -3.8096e-02],
        ...,
        [ 4.3184e-02, -4.9245e-02,  1.1519e-04,  ..., -9.0321e-02,
          2.5374e-02, -7.6081e-02],
        [-1.4005e-01,  1.6128e-01, -1.3818e-01,  ...,  1.5130e-02,
          8.2667e-02,  4.4164e-02],
        [ 7.9513e-02,  2.5539e-02, -1.8662e-02,  ..., -1.9932e-02,
          1.9952e-01,  1.8670e-01]])
tensor([[-0.0483, -0.1967, -0.0156,  ...,  0.1357, -0.0571, -0.0025],
        [-0.0954,  0.1612,  0.1117,  ..., -0.0730, -0.1990, -0.1796],
        [-0.0932, -0.0290,  0.1127,  ..., -0.0532, -0.0106, -0.0344],
        ...,
        [ 0.0392, -0.1402,  0.0320,  ..., -0.0602,  0.0462, -0.1284],
        [-0.1677,  0.1690, -0.1722,  ...,  0.0365,  0.1279,  0.0799],
        [ 0.0249,  0.1106, -0.0340,  ...,  0.0192,  0.1715,  0.2256]])
##########################################################
decoder.blks.block0.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.0693, -0.1647,  0.0755,  ...,  0.1507, -0.1237, -0.2116],
        [-0.0141,  0.1773,  0.2048,  ..., -0.1858, -0.0107, -0.1812],
        [-0.1778,  0.1386, -0.1976,  ..., -0.1777,  0.0284, -0.0928],
        ...,
        [-0.1374, -0.1794, -0.1416,  ..., -0.0285, -0.0988,  0.1580],
        [ 0.1621, -0.1130, -0.0886,  ..., -0.1517,  0.0909,  0.0719],
        [ 0.1797,  0.0051,  0.1636,  ..., -0.1375,  0.1794, -0.0529]])
tensor([[ 0.0678, -0.1307,  0.0633,  ...,  0.1587, -0.0996, -0.2157],
        [-0.0442,  0.1487,  0.2230,  ..., -0.1635, -0.0297, -0.1471],
        [-0.1821,  0.1389, -0.1762,  ..., -0.1566,  0.0092, -0.0915],
        ...,
        [-0.1394, -0.1881, -0.1211,  ..., -0.0161, -0.1004,  0.1417],
        [ 0.1593, -0.1260, -0.0688,  ..., -0.1424,  0.0805,  0.0433],
        [ 0.1844, -0.0285,  0.1517,  ..., -0.1278,  0.1763, -0.1017]])
##########################################################
decoder.blks.block0.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.1960, -0.0895,  0.1074,  ...,  0.1059, -0.0550, -0.0878],
        [ 0.0472,  0.1155,  0.1070,  ..., -0.1661, -0.1525,  0.0513],
        [ 0.1162, -0.1442,  0.0236,  ...,  0.1653,  0.0753, -0.1948],
        ...,
        [ 0.1335,  0.1909, -0.1439,  ..., -0.0361,  0.0967,  0.1649],
        [ 0.1852, -0.0010,  0.1747,  ...,  0.1434,  0.1613, -0.1377],
        [-0.0369,  0.1995,  0.0920,  ..., -0.1703,  0.1407, -0.0970]])
tensor([[ 0.1761, -0.1019,  0.1157,  ...,  0.0941, -0.0479, -0.0933],
        [ 0.0549,  0.1542,  0.0773,  ..., -0.1580, -0.1313,  0.0784],
        [ 0.1304, -0.1266,  0.0094,  ...,  0.1744,  0.0837, -0.1898],
        ...,
        [ 0.1218,  0.1943, -0.1521,  ..., -0.0411,  0.0922,  0.1408],
        [ 0.1640, -0.0066,  0.1932,  ...,  0.1287,  0.1525, -0.1165],
        [-0.0332,  0.1714,  0.1174,  ..., -0.1687,  0.1361, -0.1038]])
##########################################################
decoder.blks.block0.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0002, 0.9836, 1.0310, 1.0190, 0.9701, 0.9836, 0.9793, 1.0270, 0.9921,
        1.0212, 0.9839, 1.0501, 1.0064, 0.9720, 1.0044, 0.9929, 1.0499, 0.9776,
        0.9889, 1.0127, 0.9890, 0.9751, 1.0420, 0.9968, 0.9616, 0.9582, 1.0396,
        1.0152, 1.0016, 1.0095, 0.9837, 0.9842, 0.9882, 1.0142, 1.0415, 1.0122,
        0.9972, 1.0379, 0.9781, 1.0161, 1.0208, 0.9540, 1.0008, 0.9935, 1.0139,
        1.0415, 1.0034, 1.0290, 1.0062, 1.0039, 1.0220, 0.9413, 0.9995, 1.0152,
        1.0231, 0.9562, 0.9929, 0.9776, 0.9655, 0.9903, 0.9659, 1.0180, 1.0012,
        1.0376])
##########################################################
decoder.blks.block0.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 5.9109e-03,  8.7052e-03, -1.1988e-02,  7.3006e-03,  6.0081e-04,
        -5.8375e-03, -1.4535e-03, -3.4846e-03, -3.3308e-03,  8.8878e-03,
         2.0919e-02,  1.9406e-04, -2.4606e-03, -1.5375e-02,  1.7281e-02,
        -1.9136e-02, -3.0540e-02,  8.8577e-03, -4.7089e-04, -4.3652e-03,
         2.3039e-03,  1.3417e-03, -8.9720e-03,  6.6328e-04,  4.3139e-03,
         1.7371e-02, -2.9643e-03,  9.6895e-03,  4.3535e-03, -3.2295e-03,
         7.1731e-03,  2.5773e-02,  1.1051e-02, -3.5216e-02,  4.7015e-03,
        -2.2361e-03,  1.0327e-02,  9.2288e-04, -1.2267e-02, -6.4247e-03,
         2.0208e-02, -1.1803e-03, -5.6008e-03, -6.5804e-03, -9.0162e-03,
         6.3578e-03,  4.1875e-06, -1.8708e-02, -6.8691e-04, -1.9344e-03,
        -1.0352e-03, -1.4879e-03,  8.5861e-03, -8.0115e-03, -4.9663e-03,
        -1.1959e-02,  6.2967e-03, -1.9667e-02, -1.1941e-02,  4.3459e-03,
        -6.0811e-03,  2.0355e-02, -1.6392e-02, -1.1984e-02])
##########################################################
decoder.blks.block0.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[ 0.1258,  0.1043,  0.0367,  ..., -0.1980,  0.0460,  0.2287],
        [ 0.1309,  0.2326,  0.1168,  ..., -0.0629, -0.0525,  0.1419],
        [ 0.0517,  0.1664, -0.0333,  ...,  0.1088,  0.0369, -0.1961],
        ...,
        [ 0.0489, -0.1148,  0.1970,  ...,  0.0564,  0.1024,  0.1041],
        [-0.2098, -0.1016, -0.0891,  ...,  0.0046, -0.1650,  0.0740],
        [-0.1511, -0.1902, -0.1042,  ...,  0.1380,  0.1843, -0.0378]])
tensor([[ 0.1555,  0.1388,  0.0289,  ..., -0.2107,  0.0408,  0.2252],
        [ 0.1584,  0.2632,  0.1053,  ..., -0.0342, -0.0589,  0.1577],
        [ 0.0994,  0.2812, -0.0644,  ...,  0.0789,  0.0024, -0.1874],
        ...,
        [ 0.0387, -0.1112,  0.2306,  ...,  0.0612,  0.0715,  0.1297],
        [-0.1505, -0.0802, -0.0947,  ..., -0.0166, -0.1092,  0.1253],
        [-0.1382, -0.1636, -0.0974,  ...,  0.1476,  0.2340, -0.0682]])
##########################################################
decoder.blks.block0.ffn.dense1.bias shape: torch.Size([32])
tensor([-8.9679e-02, -9.0784e-02, -9.7285e-02, -8.9327e-02,  1.1399e-01,
         6.7131e-02, -3.0980e-02, -9.3535e-02,  1.8377e-02, -6.1712e-02,
        -9.7495e-02,  3.6995e-02, -1.2121e-01, -3.6622e-02,  8.4210e-02,
        -5.4571e-02,  1.1212e-02,  2.9094e-02, -7.3940e-05, -5.4818e-02,
        -1.6460e-03, -1.0979e-01,  7.4313e-02,  2.4665e-02,  2.6072e-02,
         1.2238e-01, -1.0603e-01,  2.9080e-02, -2.7750e-02, -8.5207e-02,
        -9.7940e-02,  3.6663e-02])
tensor([-0.0749, -0.0717, -0.0928, -0.1240,  0.0928,  0.0763, -0.0127, -0.0957,
         0.0213, -0.0578, -0.1474,  0.0309, -0.1374, -0.0486,  0.0738, -0.0507,
        -0.0156,  0.0085, -0.0468, -0.0711, -0.0200, -0.1167,  0.0769, -0.0221,
         0.0377,  0.0629, -0.0906, -0.0040, -0.0518, -0.0881, -0.1433,  0.0495])
##########################################################
decoder.blks.block0.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[ 0.1673,  0.0952,  0.0629,  ...,  0.1140, -0.2340, -0.1511],
        [-0.1632, -0.0699,  0.1093,  ..., -0.0420, -0.1610, -0.2183],
        [ 0.2240,  0.1629,  0.0735,  ..., -0.0350, -0.1659,  0.0748],
        ...,
        [ 0.0526,  0.0027, -0.1973,  ...,  0.1461,  0.0102,  0.1770],
        [ 0.2409, -0.0589, -0.2055,  ...,  0.1387, -0.1288, -0.1055],
        [ 0.1883, -0.2403,  0.2077,  ...,  0.1568,  0.1763,  0.0829]])
tensor([[ 0.1435,  0.1159,  0.0595,  ...,  0.0947, -0.2632, -0.1114],
        [-0.2053, -0.0452,  0.1274,  ..., -0.0194, -0.1747, -0.1840],
        [ 0.2209,  0.1538,  0.1053,  ..., -0.0420, -0.1682,  0.0734],
        ...,
        [ 0.0858,  0.0225, -0.2044,  ...,  0.1805,  0.0163,  0.1969],
        [ 0.2514, -0.0733, -0.1963,  ...,  0.1259, -0.0740, -0.1077],
        [ 0.2300, -0.2226,  0.1897,  ...,  0.1490,  0.1800,  0.0712]])
##########################################################
decoder.blks.block0.ffn.dense2.bias shape: torch.Size([64])
tensor([ 0.0222,  0.0422, -0.1120, -0.0073,  0.0053,  0.1563, -0.0253,  0.1551,
        -0.0732,  0.0152,  0.0414, -0.1528,  0.1402,  0.0239,  0.0832,  0.0344,
         0.1208, -0.0340, -0.0403, -0.1427, -0.0921,  0.1280, -0.1518,  0.0509,
        -0.1027, -0.0456, -0.0326, -0.0973,  0.0798, -0.0006,  0.1258,  0.0538,
        -0.1212,  0.0012,  0.1351, -0.1633, -0.0959,  0.0807, -0.1353, -0.1445,
         0.1734,  0.1758, -0.1118,  0.1242, -0.1455, -0.0232, -0.0518, -0.0807,
         0.1079,  0.1500,  0.0025,  0.1645,  0.1043, -0.0387,  0.0689,  0.1427,
         0.1507,  0.0619,  0.1681,  0.0590,  0.1200, -0.0900, -0.0709, -0.0927])
tensor([ 0.0314,  0.0526, -0.1280,  0.0003, -0.0123,  0.1766, -0.0122,  0.1674,
        -0.0811,  0.0146,  0.0579, -0.1539,  0.1228,  0.0270,  0.0870,  0.0237,
         0.0859, -0.0085, -0.0361, -0.1468, -0.1007,  0.1207, -0.1322,  0.0644,
        -0.0882, -0.0310, -0.0152, -0.0938,  0.0726, -0.0144,  0.1235,  0.0555,
        -0.1066, -0.0344,  0.1474, -0.1621, -0.0786,  0.0877, -0.1436, -0.1490,
         0.1876,  0.1735, -0.1016,  0.1175, -0.1591, -0.0232, -0.0584, -0.1043,
         0.0893,  0.1370, -0.0095,  0.1559,  0.1056, -0.0350,  0.0658,  0.1340,
         0.1420,  0.0574,  0.1422,  0.0598,  0.1165, -0.0701, -0.0691, -0.0884])
##########################################################
decoder.blks.block0.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9808, 0.9834, 1.0139, 0.9933, 0.9659, 0.9696, 0.9810, 1.0071, 0.9894,
        1.0001, 0.9955, 1.0362, 0.9916, 0.9666, 0.9815, 0.9912, 0.9893, 0.9450,
        1.0151, 1.0043, 0.9521, 0.9856, 0.9983, 0.9908, 0.9798, 0.9822, 0.9864,
        1.0066, 1.0109, 1.0015, 0.9881, 0.9788, 1.0070, 0.9871, 0.9913, 1.0258,
        0.9970, 1.0298, 0.9807, 0.9916, 1.0306, 0.9955, 1.0364, 0.9542, 1.0056,
        1.0371, 0.9954, 1.0196, 1.0199, 0.9888, 1.0531, 0.9623, 1.0065, 0.9925,
        0.9656, 1.0060, 0.9686, 0.9786, 0.9481, 1.0152, 0.9903, 0.9904, 0.9970,
        1.0223])
##########################################################
decoder.blks.block0.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0101, -0.0036, -0.0102,  0.0093, -0.0248,  0.0121,  0.0055,  0.0090,
        -0.0064,  0.0016,  0.0247, -0.0100, -0.0083,  0.0155,  0.0060,  0.0041,
        -0.0302,  0.0215,  0.0124, -0.0054, -0.0013,  0.0073,  0.0075,  0.0101,
         0.0042,  0.0167,  0.0250, -0.0026, -0.0072, -0.0039,  0.0141,  0.0143,
         0.0147, -0.0102,  0.0203, -0.0083,  0.0176,  0.0028, -0.0035,  0.0006,
         0.0156, -0.0016,  0.0028, -0.0032, -0.0050,  0.0080, -0.0044, -0.0168,
        -0.0073, -0.0148,  0.0010, -0.0047,  0.0066, -0.0050,  0.0059,  0.0021,
        -0.0072,  0.0006, -0.0251,  0.0048, -0.0121,  0.0171, -0.0068,  0.0104])
##########################################################
decoder.blks.block1.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.0253, -0.0009,  0.0784,  ..., -0.1371,  0.1051,  0.0688],
        [-0.0212,  0.0808, -0.0634,  ...,  0.1010, -0.1605,  0.1224],
        [-0.0336, -0.1642,  0.1046,  ..., -0.0585, -0.0172, -0.0313],
        ...,
        [-0.0681,  0.1877, -0.0993,  ..., -0.1622, -0.1013,  0.1274],
        [ 0.2106,  0.0120,  0.2151,  ...,  0.1441, -0.0203,  0.1644],
        [ 0.1110,  0.0327,  0.0614,  ...,  0.1861,  0.1396, -0.1983]])
tensor([[ 0.0123, -0.0055,  0.0670,  ..., -0.1412,  0.0962,  0.1163],
        [-0.0385,  0.0666, -0.0593,  ...,  0.1129, -0.1606,  0.2112],
        [ 0.0008, -0.2148,  0.1141,  ..., -0.0490,  0.0183, -0.0539],
        ...,
        [-0.0503,  0.2319, -0.0297,  ..., -0.1698, -0.0864,  0.1090],
        [ 0.2135, -0.0034,  0.1173,  ...,  0.1151,  0.0163,  0.1565],
        [ 0.1011, -0.0455,  0.0337,  ...,  0.1859,  0.1596, -0.2036]])
##########################################################
decoder.blks.block1.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[-0.1078,  0.1504,  0.1418,  ...,  0.1843,  0.0145,  0.0133],
        [ 0.1770, -0.1037,  0.0935,  ...,  0.0538,  0.0688, -0.2121],
        [-0.1828, -0.0257, -0.0067,  ...,  0.1289, -0.1130,  0.0176],
        ...,
        [ 0.0159, -0.0465, -0.1308,  ..., -0.1742, -0.1894, -0.1620],
        [ 0.1034, -0.0274, -0.0162,  ..., -0.0246, -0.1231, -0.1756],
        [-0.1378,  0.0999, -0.0385,  ...,  0.1174, -0.0699,  0.0103]])
tensor([[-0.1185,  0.2042,  0.1371,  ...,  0.1848,  0.0118,  0.0502],
        [ 0.1646, -0.0605,  0.0784,  ...,  0.0769,  0.0437, -0.1684],
        [-0.1790, -0.0191,  0.0069,  ...,  0.1037, -0.1296,  0.0244],
        ...,
        [ 0.0222, -0.1084, -0.0847,  ..., -0.1580, -0.1714, -0.1633],
        [ 0.1029, -0.0251, -0.0702,  ..., -0.0318, -0.1812, -0.1333],
        [-0.1248,  0.0673, -0.0409,  ...,  0.0904, -0.0073, -0.0445]])
##########################################################
decoder.blks.block1.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[-0.1248,  0.1815,  0.0747,  ..., -0.1585, -0.0307,  0.0558],
        [ 0.2070,  0.0685, -0.1167,  ..., -0.0714,  0.1358,  0.0094],
        [-0.0804, -0.1758,  0.1304,  ..., -0.0913, -0.1839,  0.1193],
        ...,
        [ 0.2036, -0.1362,  0.1069,  ...,  0.1308, -0.1143,  0.0933],
        [ 0.0108, -0.0029, -0.1525,  ...,  0.2136, -0.1233, -0.0468],
        [ 0.1657, -0.1620,  0.1856,  ...,  0.1540,  0.0660, -0.1138]])
tensor([[-0.1520,  0.1758,  0.0845,  ..., -0.1436,  0.0358,  0.0277],
        [ 0.2329,  0.0552, -0.1430,  ..., -0.0870,  0.1336,  0.0515],
        [-0.1431, -0.1717,  0.1838,  ..., -0.0870, -0.1935,  0.1410],
        ...,
        [ 0.2271, -0.1386,  0.0828,  ...,  0.1103, -0.1925,  0.1271],
        [ 0.0078, -0.0325, -0.1653,  ...,  0.2227, -0.1237,  0.0041],
        [ 0.1464, -0.1432,  0.2032,  ...,  0.1843,  0.0357, -0.1379]])
##########################################################
decoder.blks.block1.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.1955, -0.1130,  0.1248,  ...,  0.0042,  0.1628, -0.1339],
        [-0.1943,  0.1287, -0.0894,  ..., -0.0973, -0.2018,  0.1887],
        [ 0.1088, -0.0298, -0.1228,  ...,  0.0179,  0.0162, -0.0454],
        ...,
        [ 0.0331, -0.0881,  0.1007,  ...,  0.1679, -0.1721, -0.0262],
        [-0.1236, -0.1191,  0.0855,  ...,  0.1129,  0.1316,  0.0037],
        [ 0.0308,  0.1643, -0.0834,  ..., -0.1356, -0.0040, -0.1890]])
tensor([[ 0.2096, -0.1341,  0.0769,  ..., -0.0053,  0.1407, -0.1388],
        [-0.2317,  0.1014, -0.0880,  ..., -0.0494, -0.2654,  0.2495],
        [ 0.1152, -0.0123, -0.0774,  ...,  0.0353,  0.0128, -0.0570],
        ...,
        [ 0.0522, -0.0378,  0.0918,  ...,  0.1694, -0.2017, -0.0614],
        [-0.0890, -0.0991,  0.1500,  ...,  0.1261,  0.0837,  0.0202],
        [-0.0018,  0.1877, -0.0676,  ..., -0.1586, -0.0044, -0.1974]])
##########################################################
decoder.blks.block1.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0218, 1.0206, 1.0414, 1.0392, 1.0069, 0.9769, 0.9754, 1.0321, 0.9743,
        1.0135, 1.0305, 1.0367, 1.0371, 1.0071, 1.0430, 1.0105, 1.0470, 1.0188,
        1.0372, 1.0383, 1.0203, 1.0100, 1.0239, 1.0328, 0.9867, 1.0109, 1.0382,
        1.0404, 1.0458, 1.0251, 1.0007, 0.9518, 1.0046, 1.0231, 1.0457, 1.0469,
        0.9997, 1.0178, 0.9944, 1.0400, 1.0391, 0.9889, 1.0337, 1.0118, 1.0179,
        1.0834, 1.0407, 1.0225, 1.0163, 0.9975, 1.0368, 1.0359, 1.0244, 1.0276,
        0.9955, 1.0407, 0.9993, 1.0037, 1.0061, 1.0308, 1.0378, 1.0205, 1.0271,
        1.0462])
##########################################################
decoder.blks.block1.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 3.6007e-03,  1.9259e-02, -1.4426e-02, -2.9863e-03, -6.0119e-03,
         6.3906e-03,  1.9836e-02, -2.1641e-02, -9.7867e-03, -2.9309e-03,
         1.2253e-02,  8.5170e-03, -1.2590e-02, -1.9265e-02,  3.3855e-03,
         1.4829e-02, -2.9498e-03,  1.3340e-02, -7.5579e-03, -3.8208e-03,
        -9.5564e-04, -3.0567e-03,  6.2879e-03,  7.2176e-03,  9.3486e-04,
         1.7433e-02,  6.9552e-03,  2.3243e-03, -7.1540e-03, -1.0536e-02,
         1.3704e-02, -6.9596e-03,  1.2820e-02, -6.0373e-03,  9.5854e-04,
         3.9996e-03,  5.8723e-03, -1.7864e-02,  9.0368e-03, -6.9848e-03,
         1.1785e-02, -1.0305e-02, -6.1139e-04,  7.4057e-03, -8.7767e-03,
         3.0087e-05, -9.4711e-03,  6.3303e-03,  6.8361e-03, -3.0166e-02,
        -4.0201e-03, -6.2059e-03,  1.1086e-02, -1.5995e-03, -8.8403e-04,
         1.5859e-02,  1.7219e-03, -4.7308e-03, -1.7167e-02,  3.9537e-03,
        -2.8952e-03,  5.2961e-05, -4.1542e-03, -4.7705e-03])
##########################################################
decoder.blks.block1.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[-0.0470, -0.0861,  0.0481,  ...,  0.1596, -0.0631,  0.0629],
        [-0.0472, -0.0353,  0.2124,  ..., -0.1374, -0.1985, -0.2058],
        [ 0.0515, -0.1446, -0.0781,  ...,  0.0312, -0.1375, -0.1249],
        ...,
        [-0.0371,  0.0246,  0.2086,  ..., -0.1584, -0.0510,  0.1761],
        [ 0.0502,  0.1236,  0.0355,  ..., -0.0685,  0.0661,  0.1826],
        [ 0.1295, -0.0979,  0.0558,  ...,  0.1938,  0.1807, -0.0195]])
tensor([[-0.0348, -0.0620,  0.0790,  ...,  0.1540, -0.0658,  0.0383],
        [-0.0532, -0.0267,  0.2660,  ..., -0.1251, -0.2207, -0.2018],
        [ 0.0412, -0.1746, -0.0260,  ...,  0.0412, -0.1349, -0.1266],
        ...,
        [-0.0428,  0.0223,  0.2176,  ..., -0.1649, -0.0574,  0.1666],
        [ 0.0612,  0.1033,  0.0073,  ..., -0.0508,  0.0566,  0.1764],
        [ 0.1382, -0.1094,  0.0628,  ...,  0.1795,  0.1912, -0.0284]])
##########################################################
decoder.blks.block1.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[-0.1708,  0.0940, -0.1397,  ..., -0.0740, -0.1653,  0.0736],
        [ 0.1963, -0.0202, -0.0952,  ...,  0.1176, -0.2114,  0.0433],
        [-0.2149,  0.2059, -0.0789,  ...,  0.1033,  0.1098, -0.0062],
        ...,
        [ 0.1977, -0.1741, -0.0066,  ...,  0.1228, -0.1844,  0.0358],
        [ 0.1991, -0.1837,  0.0674,  ...,  0.0418,  0.1150, -0.0551],
        [ 0.1501, -0.0171, -0.0344,  ..., -0.2059, -0.1900, -0.0174]])
tensor([[-0.1580,  0.0949, -0.1481,  ..., -0.0791, -0.1061,  0.0968],
        [ 0.1767,  0.0239, -0.0567,  ...,  0.0456, -0.2470,  0.1143],
        [-0.1758,  0.2669, -0.0851,  ...,  0.0555,  0.0623,  0.0042],
        ...,
        [ 0.2138, -0.1756,  0.0067,  ...,  0.1752, -0.2335,  0.0465],
        [ 0.2256, -0.2162,  0.0719,  ...,  0.0696,  0.1455, -0.0742],
        [ 0.1281, -0.0332, -0.1102,  ..., -0.1913, -0.1269, -0.0482]])
##########################################################
decoder.blks.block1.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.1344, -0.1516, -0.2131,  ..., -0.1254, -0.0272, -0.1599],
        [ 0.0035,  0.0101, -0.1925,  ..., -0.1588,  0.1951,  0.0312],
        [ 0.1808, -0.1681, -0.0427,  ...,  0.0519, -0.1543,  0.1358],
        ...,
        [ 0.1487, -0.0494, -0.0318,  ...,  0.0587,  0.0546, -0.1055],
        [-0.0641,  0.0040,  0.0352,  ...,  0.1572, -0.1266, -0.1686],
        [-0.2085,  0.0445, -0.1330,  ...,  0.0735,  0.0199,  0.1120]])
tensor([[ 0.1140, -0.1508, -0.2020,  ..., -0.1303, -0.0384, -0.1484],
        [-0.0040,  0.0144, -0.1852,  ..., -0.1705,  0.1915,  0.0091],
        [ 0.1808, -0.1791, -0.0483,  ...,  0.0505, -0.1667,  0.1157],
        ...,
        [ 0.1588, -0.0424, -0.0335,  ...,  0.0548,  0.0796, -0.1084],
        [-0.0886, -0.0003,  0.0093,  ...,  0.1725, -0.1475, -0.1544],
        [-0.1970,  0.0536, -0.1448,  ...,  0.0605,  0.0238,  0.1218]])
##########################################################
decoder.blks.block1.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.0328, -0.1091,  0.0997,  ..., -0.1909,  0.0099,  0.2052],
        [-0.1915, -0.0499, -0.1770,  ...,  0.1276,  0.0393, -0.1004],
        [-0.0667,  0.2066,  0.2071,  ..., -0.0496, -0.0047, -0.2014],
        ...,
        [ 0.0669,  0.1663,  0.1784,  ...,  0.0525, -0.1002,  0.0490],
        [ 0.0877,  0.1797,  0.1232,  ..., -0.0469,  0.2165,  0.1708],
        [ 0.0684,  0.1821,  0.1295,  ..., -0.2090,  0.1842,  0.0827]])
tensor([[ 0.0501, -0.0993,  0.0993,  ..., -0.1989, -0.0118,  0.1932],
        [-0.1410, -0.0640, -0.1819,  ...,  0.1069,  0.0203, -0.1189],
        [-0.0528,  0.2097,  0.1540,  ..., -0.0481, -0.0099, -0.2065],
        ...,
        [ 0.0239,  0.1533,  0.1523,  ...,  0.0285, -0.0773,  0.0251],
        [ 0.0563,  0.1834,  0.0896,  ..., -0.0880,  0.2224,  0.1876],
        [ 0.0664,  0.1735,  0.0755,  ..., -0.2172,  0.1553,  0.0718]])
##########################################################
decoder.blks.block1.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0158, 0.9958, 0.9989, 1.0125, 1.0094, 0.9585, 0.9689, 1.0096, 0.9533,
        1.0037, 1.0133, 1.0264, 1.0261, 0.9937, 1.0044, 0.9928, 1.0415, 1.0097,
        1.0285, 1.0217, 1.0039, 1.0123, 0.9925, 0.9946, 0.9667, 0.9961, 1.0239,
        1.0050, 1.0115, 0.9992, 0.9717, 0.9572, 1.0014, 1.0136, 1.0245, 1.0018,
        0.9869, 1.0110, 0.9792, 0.9987, 1.0091, 0.9833, 1.0034, 1.0113, 0.9947,
        1.0376, 1.0135, 1.0065, 1.0054, 0.9979, 1.0020, 0.9991, 1.0059, 1.0024,
        0.9955, 1.0311, 0.9659, 0.9845, 0.9814, 1.0105, 1.0082, 1.0115, 1.0103,
        1.0293])
##########################################################
decoder.blks.block1.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0065,  0.0167, -0.0184, -0.0064, -0.0043,  0.0119,  0.0181, -0.0156,
        -0.0082,  0.0035,  0.0061,  0.0073, -0.0091, -0.0195,  0.0008,  0.0218,
        -0.0025,  0.0133, -0.0033, -0.0052, -0.0018,  0.0011,  0.0063,  0.0086,
         0.0046,  0.0216,  0.0055,  0.0096, -0.0096, -0.0129,  0.0136, -0.0035,
         0.0156, -0.0055,  0.0053,  0.0122,  0.0048, -0.0187,  0.0067,  0.0052,
         0.0110, -0.0068,  0.0060,  0.0027, -0.0065, -0.0008, -0.0030,  0.0066,
         0.0122, -0.0316, -0.0087, -0.0104,  0.0131,  0.0032,  0.0001,  0.0177,
         0.0043, -0.0054, -0.0084,  0.0073,  0.0066,  0.0019, -0.0028, -0.0076])
##########################################################
decoder.blks.block1.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[-0.0261, -0.1772, -0.0917,  ..., -0.2009,  0.0604, -0.2360],
        [ 0.1278, -0.0905, -0.0673,  ...,  0.1406, -0.2462,  0.1864],
        [-0.0511,  0.2115,  0.1152,  ..., -0.2355, -0.0277,  0.1800],
        ...,
        [-0.1157, -0.0958,  0.1202,  ..., -0.2315, -0.1457, -0.0791],
        [-0.1748, -0.2079, -0.0028,  ...,  0.0771,  0.2327, -0.2085],
        [-0.0768,  0.1239, -0.0947,  ...,  0.1954,  0.1241, -0.1663]])
tensor([[-0.0777, -0.1619, -0.0948,  ..., -0.2152,  0.0372, -0.2255],
        [ 0.1678, -0.0814, -0.0118,  ...,  0.1345, -0.2354,  0.1923],
        [-0.0650,  0.2013,  0.1251,  ..., -0.2321,  0.0186,  0.1288],
        ...,
        [-0.1203, -0.0940,  0.1062,  ..., -0.2563, -0.1672, -0.0717],
        [-0.1721, -0.1919, -0.0515,  ...,  0.0895,  0.2492, -0.1760],
        [-0.0562,  0.1091, -0.1238,  ...,  0.2024,  0.1192, -0.1610]])
##########################################################
decoder.blks.block1.ffn.dense1.bias shape: torch.Size([32])
tensor([-0.1228, -0.0722, -0.0761, -0.0432, -0.0297, -0.0111,  0.1168,  0.0175,
         0.0006,  0.0411, -0.0488, -0.0860, -0.0149, -0.0331, -0.0847, -0.0099,
         0.0940, -0.0905,  0.0267,  0.0909,  0.0760, -0.0183,  0.0429, -0.1177,
        -0.0237, -0.0171,  0.0602,  0.0310, -0.0805,  0.0301,  0.1147, -0.0882])
tensor([-0.1336, -0.1006, -0.0856, -0.0701, -0.0220, -0.0415,  0.0873, -0.0009,
        -0.0280,  0.0381, -0.0626, -0.0705, -0.0454, -0.0464, -0.1091, -0.0566,
         0.0599, -0.1103,  0.0153,  0.0718,  0.0677, -0.0537,  0.0459, -0.1454,
        -0.0442, -0.0327,  0.0495,  0.0110, -0.1063,  0.0166,  0.0706, -0.0588])
##########################################################
decoder.blks.block1.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[-0.1003,  0.0938,  0.2211,  ..., -0.1518, -0.2293,  0.2402],
        [ 0.1777,  0.1134, -0.1355,  ...,  0.0055, -0.1560, -0.0540],
        [ 0.0598, -0.1378, -0.2251,  ..., -0.0053,  0.0307,  0.0945],
        ...,
        [-0.0069,  0.2000, -0.0456,  ...,  0.0891, -0.0158, -0.1008],
        [ 0.0061,  0.1738, -0.0329,  ...,  0.0012, -0.1137, -0.1087],
        [-0.2470,  0.0197, -0.1861,  ..., -0.1588, -0.0745, -0.0960]])
tensor([[-0.1093,  0.1210,  0.1768,  ..., -0.1512, -0.2211,  0.2814],
        [ 0.1563,  0.0747, -0.1407,  ...,  0.0286, -0.1857, -0.0454],
        [ 0.0859, -0.0798, -0.2052,  ...,  0.0440,  0.0017,  0.0528],
        ...,
        [ 0.0046,  0.2195, -0.0182,  ...,  0.1341, -0.0141, -0.1351],
        [-0.0167,  0.1681, -0.0460,  ..., -0.0193, -0.1215, -0.0734],
        [-0.2221, -0.0004, -0.1449,  ..., -0.1478, -0.0526, -0.0609]])
##########################################################
decoder.blks.block1.ffn.dense2.bias shape: torch.Size([64])
tensor([-0.1546,  0.0625, -0.0802,  0.0916, -0.0967, -0.1752, -0.1622,  0.0351,
         0.0479,  0.0119, -0.0123,  0.1298,  0.1554,  0.1621,  0.0283, -0.1526,
        -0.1616, -0.0141,  0.0649,  0.1694, -0.0442, -0.0114,  0.0032, -0.0938,
         0.1473, -0.0938, -0.0143,  0.0811,  0.0015, -0.0696,  0.0826,  0.0887,
         0.0137,  0.0943, -0.1076,  0.1602, -0.1610,  0.1514,  0.1194, -0.0607,
        -0.1588,  0.0820,  0.0206, -0.0343,  0.0944,  0.0084, -0.1365,  0.1383,
         0.1365,  0.1574,  0.1236, -0.1151,  0.0505,  0.0516,  0.0263, -0.0632,
         0.0094,  0.0565,  0.1620,  0.1012,  0.1355,  0.1540,  0.0192, -0.0207])
tensor([-0.1512,  0.0693, -0.0897,  0.0867, -0.0934, -0.1783, -0.1476,  0.0244,
         0.0279,  0.0105,  0.0082,  0.1379,  0.1414,  0.1335,  0.0348, -0.1392,
        -0.1683, -0.0079,  0.0483,  0.1635, -0.0593, -0.0016, -0.0042, -0.0919,
         0.1393, -0.0606, -0.0168,  0.0698, -0.0108, -0.0964,  0.0838,  0.0751,
         0.0263,  0.0938, -0.0896,  0.1720, -0.1565,  0.1255,  0.1109, -0.0706,
        -0.1516,  0.0836,  0.0241, -0.0377,  0.0856,  0.0058, -0.1568,  0.1262,
         0.1358,  0.1236,  0.1327, -0.1090,  0.0648,  0.0516,  0.0209, -0.0476,
        -0.0035,  0.0652,  0.1628,  0.1013,  0.1455,  0.1626,  0.0210,  0.0051])
##########################################################
decoder.blks.block1.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0193, 1.0004, 1.0166, 1.0236, 1.0234, 0.9956, 0.9884, 1.0266, 0.9720,
        1.0110, 0.9918, 1.0134, 1.0295, 0.9737, 0.9879, 0.9938, 1.0201, 1.0364,
        1.0168, 1.0225, 0.9916, 1.0082, 1.0109, 0.9772, 0.9762, 0.9752, 1.0146,
        1.0009, 0.9951, 1.0115, 0.9930, 1.0114, 0.9933, 0.9831, 1.0043, 0.9930,
        0.9822, 0.9925, 1.0112, 1.0108, 1.0121, 1.0058, 0.9994, 0.9646, 1.0145,
        1.0653, 1.0248, 0.9792, 0.9929, 1.0045, 1.0093, 0.9975, 0.9667, 1.0109,
        1.0038, 1.0047, 0.9872, 0.9989, 0.9841, 1.0094, 1.0251, 0.9903, 1.0064,
        1.0101])
##########################################################
decoder.blks.block1.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-3.4075e-03, -1.9770e-03, -6.0030e-03, -4.6935e-03, -1.1820e-02,
         4.3480e-03,  9.9962e-03,  1.4658e-03, -1.7798e-02,  5.3098e-03,
         7.0745e-03,  3.9559e-03, -8.9791e-03, -5.8769e-03, -1.1370e-03,
         5.2683e-03, -1.2367e-02,  3.0282e-03,  7.2062e-04, -4.8350e-05,
        -1.4223e-02,  6.4676e-03, -9.4778e-03,  2.4642e-03, -7.7113e-05,
         1.3401e-02,  1.4146e-03, -3.3880e-03, -1.2625e-02, -2.3018e-03,
         4.8286e-03, -1.3388e-02,  1.3860e-02, -1.2823e-03,  9.7124e-03,
         1.4275e-02,  4.6152e-03, -2.1266e-02, -4.5938e-03, -4.7945e-03,
         1.5090e-03, -1.6799e-03, -8.3294e-03, -5.6039e-03, -9.8162e-03,
         1.0174e-03, -1.0736e-02, -7.8798e-03,  1.1357e-03, -2.1710e-02,
         5.9434e-03,  9.6996e-03,  1.0450e-02, -1.7372e-03, -6.1997e-03,
         1.0440e-02, -1.4223e-02,  7.1178e-03, -7.2036e-03, -3.7191e-03,
         6.2764e-03,  2.8903e-03,  4.1866e-03,  1.2510e-02])
##########################################################
decoder.blks.block2.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.2159, -0.1826,  0.1565,  ...,  0.0745,  0.1242,  0.0608],
        [ 0.1651, -0.0057,  0.1219,  ..., -0.0519, -0.1900, -0.0032],
        [-0.0381, -0.0804, -0.0433,  ..., -0.0545, -0.0193,  0.0401],
        ...,
        [-0.2126, -0.1978,  0.1899,  ..., -0.1783,  0.0334,  0.1598],
        [ 0.1087, -0.2138,  0.0527,  ...,  0.0996, -0.1080,  0.1061],
        [-0.0557, -0.1852,  0.1501,  ...,  0.1881, -0.1353,  0.1955]])
tensor([[ 0.1944, -0.1342,  0.1211,  ...,  0.0517,  0.1568,  0.0483],
        [ 0.1791,  0.0033,  0.0507,  ..., -0.1298, -0.2197, -0.0277],
        [-0.0188, -0.0813, -0.0529,  ..., -0.0271, -0.0038,  0.0370],
        ...,
        [-0.1988, -0.2113,  0.2384,  ..., -0.1732,  0.0445,  0.1863],
        [ 0.0991, -0.1622,  0.0341,  ...,  0.0979, -0.1151,  0.1313],
        [-0.0563, -0.1889,  0.1433,  ...,  0.2186, -0.1144,  0.2135]])
##########################################################
decoder.blks.block2.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[-0.1826, -0.2066, -0.0369,  ..., -0.1824,  0.0183,  0.1589],
        [ 0.0805,  0.1679,  0.0789,  ...,  0.2094, -0.1925,  0.0683],
        [-0.1652, -0.0843, -0.2132,  ..., -0.0478, -0.0518, -0.0446],
        ...,
        [-0.0546,  0.0481, -0.0227,  ...,  0.2015, -0.0379,  0.0602],
        [-0.1461,  0.0029,  0.0119,  ..., -0.1175,  0.0419,  0.1664],
        [ 0.1101, -0.0586,  0.0744,  ...,  0.1235,  0.0273,  0.0919]])
tensor([[-0.1810, -0.2056,  0.0083,  ..., -0.1866,  0.0098,  0.2242],
        [ 0.1524,  0.1691,  0.0740,  ...,  0.2281, -0.1616,  0.0680],
        [-0.2241, -0.0932, -0.1805,  ..., -0.0396, -0.0332, -0.0053],
        ...,
        [-0.0775,  0.0469,  0.0353,  ...,  0.1917, -0.0984,  0.0669],
        [-0.1451, -0.0758,  0.0856,  ..., -0.0472, -0.0170,  0.2149],
        [ 0.1071, -0.1036,  0.1090,  ...,  0.1353, -0.0096,  0.0879]])
##########################################################
decoder.blks.block2.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.1160,  0.0423, -0.0447,  ...,  0.1836, -0.1066, -0.1457],
        [ 0.1497,  0.0296,  0.0034,  ..., -0.1503,  0.1195, -0.1554],
        [-0.0810,  0.2023, -0.1365,  ..., -0.1228,  0.0570, -0.1160],
        ...,
        [-0.1142, -0.1648,  0.0890,  ...,  0.1364, -0.2115, -0.0974],
        [-0.0937,  0.0902, -0.1450,  ...,  0.1343,  0.2131,  0.1347],
        [ 0.0622,  0.1890, -0.1323,  ...,  0.1265, -0.0712, -0.0781]])
tensor([[ 1.3573e-01,  3.6819e-02, -3.3620e-02,  ...,  1.7470e-01,
         -3.3415e-02, -1.5574e-01],
        [ 1.4320e-01,  2.1280e-04, -2.0525e-02,  ..., -1.4068e-01,
          9.4355e-02, -7.4202e-02],
        [-8.0626e-02,  2.1501e-01, -1.4971e-01,  ..., -1.3364e-01,
          7.7110e-02, -1.3083e-01],
        ...,
        [-1.1798e-01, -1.8048e-01,  7.8512e-02,  ...,  1.5549e-01,
         -2.8232e-01, -1.0045e-01],
        [-7.6473e-02,  6.2428e-02, -1.3573e-01,  ...,  1.1380e-01,
          1.7506e-01,  2.0140e-01],
        [ 9.4597e-02,  2.4692e-01, -1.5354e-01,  ...,  1.1631e-01,
         -4.2503e-02, -1.1854e-01]])
##########################################################
decoder.blks.block2.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[-0.0020,  0.0204,  0.1313,  ..., -0.1930,  0.0225, -0.1596],
        [ 0.0457,  0.0766, -0.2151,  ...,  0.0899,  0.1212, -0.1378],
        [ 0.1195,  0.1269,  0.0140,  ..., -0.1530, -0.1647,  0.1852],
        ...,
        [ 0.1752, -0.0291,  0.0223,  ..., -0.1201,  0.0399, -0.0964],
        [-0.1027,  0.1407, -0.0475,  ..., -0.1167,  0.1608,  0.0448],
        [ 0.1445, -0.0051, -0.1843,  ..., -0.0506,  0.0816, -0.1147]])
tensor([[-0.0233, -0.0080,  0.1512,  ..., -0.2277,  0.0191, -0.1776],
        [ 0.0624,  0.0807, -0.2077,  ...,  0.0556,  0.1371, -0.1608],
        [ 0.1054,  0.1502, -0.0319,  ..., -0.2405, -0.1243,  0.1656],
        ...,
        [ 0.1034, -0.0059,  0.0543,  ..., -0.1764,  0.0743, -0.1419],
        [-0.1544,  0.1245, -0.0441,  ..., -0.1225,  0.1789,  0.0129],
        [ 0.1468, -0.0027, -0.1877,  ..., -0.0797,  0.0686, -0.1348]])
##########################################################
decoder.blks.block2.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0627, 1.0169, 1.0036, 1.0493, 1.0657, 1.0293, 1.0204, 1.0183, 1.0109,
        1.0102, 0.9962, 1.0534, 1.0529, 1.0037, 1.0323, 1.0097, 1.0388, 1.0436,
        1.0603, 1.0294, 1.0313, 1.0516, 1.0480, 0.9979, 1.0087, 1.0252, 1.0068,
        1.0243, 1.0108, 1.0356, 1.0157, 1.0276, 1.0157, 1.0081, 1.0466, 1.0151,
        0.9992, 1.0035, 1.0452, 0.9955, 1.0510, 1.0182, 1.0207, 1.0074, 1.0680,
        1.0641, 1.0205, 0.9880, 1.0002, 1.0452, 1.0364, 1.0198, 0.9801, 1.0008,
        0.9850, 0.9887, 0.9879, 1.0004, 0.9815, 1.0070, 1.0399, 1.0343, 1.0124,
        1.0410])
##########################################################
decoder.blks.block2.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0040,  0.0075,  0.0146, -0.0171, -0.0086, -0.0195, -0.0015, -0.0056,
        -0.0105,  0.0050,  0.0044,  0.0001, -0.0067,  0.0015,  0.0132,  0.0105,
        -0.0167,  0.0004,  0.0050,  0.0129, -0.0102, -0.0056, -0.0132, -0.0072,
        -0.0119, -0.0021,  0.0099,  0.0094, -0.0167, -0.0019,  0.0178, -0.0094,
         0.0119,  0.0152, -0.0011,  0.0151,  0.0103, -0.0047, -0.0013,  0.0107,
        -0.0029, -0.0061,  0.0243, -0.0016, -0.0056,  0.0073, -0.0016, -0.0030,
        -0.0029, -0.0187,  0.0035,  0.0051, -0.0102,  0.0005, -0.0034,  0.0107,
        -0.0023,  0.0036, -0.0056, -0.0032,  0.0109,  0.0078,  0.0031, -0.0100])
##########################################################
decoder.blks.block2.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.1290,  0.1801, -0.0481,  ..., -0.1821, -0.2120, -0.1355],
        [ 0.2007,  0.1663, -0.0109,  ..., -0.0726, -0.0429, -0.0893],
        [ 0.0781, -0.1656, -0.0447,  ...,  0.0640, -0.1373, -0.2155],
        ...,
        [ 0.1712,  0.0508,  0.1152,  ...,  0.1554,  0.1635,  0.0526],
        [-0.1075, -0.0335, -0.1458,  ..., -0.1830, -0.1972, -0.0423],
        [ 0.0109,  0.1729,  0.0811,  ...,  0.1504,  0.1702, -0.0787]])
tensor([[ 0.0985,  0.1772, -0.0320,  ..., -0.1684, -0.2451, -0.0878],
        [ 0.1967,  0.1608, -0.0336,  ..., -0.0876, -0.0218, -0.1246],
        [ 0.0880, -0.2117, -0.0190,  ...,  0.1031, -0.1463, -0.2320],
        ...,
        [ 0.1712,  0.0805,  0.0902,  ...,  0.1527,  0.1795,  0.0064],
        [-0.1302, -0.0180, -0.1369,  ..., -0.2259, -0.2251, -0.0607],
        [-0.0038,  0.1489,  0.0540,  ...,  0.1413,  0.1807, -0.0284]])
##########################################################
decoder.blks.block2.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[-0.0694,  0.1333,  0.0393,  ..., -0.1232, -0.1422, -0.0749],
        [ 0.1143, -0.1454, -0.0195,  ...,  0.0550,  0.2052, -0.2160],
        [ 0.0709,  0.0641, -0.1386,  ...,  0.0919, -0.1038, -0.0079],
        ...,
        [-0.0516,  0.1379, -0.0063,  ...,  0.2006, -0.0014, -0.0045],
        [ 0.0414, -0.0832, -0.1735,  ...,  0.1657, -0.1326,  0.1833],
        [ 0.0539, -0.0459,  0.1160,  ...,  0.1001,  0.1427, -0.1911]])
tensor([[-0.0966,  0.1169,  0.0063,  ..., -0.0847, -0.0727, -0.1048],
        [ 0.1324, -0.1199,  0.0268,  ...,  0.0373,  0.1644, -0.2181],
        [ 0.0588,  0.0622, -0.1614,  ...,  0.0939, -0.0230, -0.0265],
        ...,
        [-0.1002,  0.1697, -0.0435,  ...,  0.1614,  0.0481,  0.0081],
        [-0.0021, -0.0365, -0.1630,  ...,  0.2270, -0.1214,  0.2705],
        [ 0.0758, -0.0271,  0.1164,  ...,  0.0970,  0.1631, -0.1622]])
##########################################################
decoder.blks.block2.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[-0.0626,  0.0473, -0.0045,  ..., -0.1865,  0.1716, -0.1933],
        [ 0.0254,  0.2007,  0.1174,  ..., -0.0798, -0.0361,  0.1108],
        [ 0.2130,  0.0753, -0.0330,  ...,  0.2055,  0.0392, -0.1227],
        ...,
        [-0.1094,  0.0855,  0.0540,  ...,  0.1236, -0.1692,  0.0447],
        [ 0.0530, -0.1042, -0.0725,  ..., -0.1454,  0.1362, -0.0128],
        [-0.0727, -0.0218,  0.1556,  ..., -0.0183, -0.1673,  0.1011]])
tensor([[-0.0568,  0.0359, -0.0136,  ..., -0.1987,  0.1555, -0.2062],
        [ 0.0307,  0.1976,  0.1238,  ..., -0.0608, -0.0513,  0.0651],
        [ 0.2219,  0.0720, -0.0205,  ...,  0.1829,  0.0463, -0.1484],
        ...,
        [-0.0933,  0.0355,  0.0311,  ...,  0.1122, -0.1916,  0.0118],
        [ 0.0232, -0.1607, -0.0433,  ..., -0.1175,  0.1055, -0.0396],
        [-0.0786, -0.0059,  0.1339,  ..., -0.0611, -0.1620,  0.1030]])
##########################################################
decoder.blks.block2.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.1098,  0.1476,  0.0237,  ..., -0.0848, -0.0474,  0.0946],
        [ 0.1314,  0.0761, -0.0476,  ..., -0.0164, -0.2107,  0.0167],
        [-0.0761,  0.1862,  0.1812,  ...,  0.1360,  0.1735, -0.0686],
        ...,
        [ 0.1613, -0.2101,  0.1502,  ..., -0.0342,  0.0036,  0.1428],
        [-0.0130,  0.0891,  0.1154,  ..., -0.2081, -0.1859, -0.0199],
        [ 0.1425, -0.0179, -0.1293,  ...,  0.0553, -0.1100,  0.0484]])
tensor([[ 0.0797,  0.1255,  0.0161,  ..., -0.1080, -0.0537,  0.0973],
        [ 0.1413,  0.0625, -0.0472,  ..., -0.0246, -0.1924, -0.0065],
        [-0.0875,  0.1944,  0.1751,  ...,  0.1040,  0.1902, -0.1052],
        ...,
        [ 0.1586, -0.1824,  0.1645,  ..., -0.0513, -0.0069,  0.1583],
        [ 0.0142,  0.0445,  0.1112,  ..., -0.1965, -0.1885, -0.0213],
        [ 0.1192, -0.0216, -0.1407,  ...,  0.0456, -0.1006,  0.0428]])
##########################################################
decoder.blks.block2.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0299, 1.0027, 1.0055, 1.0199, 1.0566, 0.9958, 0.9870, 0.9935, 0.9918,
        0.9851, 0.9834, 1.0290, 1.0041, 0.9839, 1.0147, 1.0175, 1.0138, 1.0098,
        1.0338, 1.0032, 1.0104, 1.0450, 1.0061, 0.9830, 0.9735, 0.9997, 0.9952,
        1.0023, 0.9759, 1.0022, 1.0060, 1.0113, 1.0010, 1.0037, 1.0264, 0.9901,
        0.9826, 0.9861, 1.0288, 0.9929, 1.0375, 0.9931, 1.0130, 0.9988, 1.0449,
        1.0376, 0.9961, 0.9850, 0.9711, 1.0508, 1.0069, 0.9998, 0.9699, 0.9811,
        0.9685, 0.9856, 0.9716, 0.9841, 0.9702, 0.9772, 1.0040, 1.0235, 1.0093,
        1.0092])
##########################################################
decoder.blks.block2.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0081,  0.0150,  0.0229, -0.0224, -0.0028, -0.0229,  0.0004, -0.0106,
        -0.0116,  0.0044,  0.0106, -0.0018,  0.0187, -0.0028,  0.0067,  0.0213,
        -0.0055,  0.0025, -0.0028,  0.0082, -0.0098, -0.0046, -0.0145, -0.0073,
        -0.0160,  0.0011,  0.0113, -0.0056, -0.0022,  0.0095,  0.0152, -0.0083,
         0.0073,  0.0237, -0.0128,  0.0117,  0.0036, -0.0032, -0.0011,  0.0023,
         0.0008, -0.0074,  0.0113, -0.0150,  0.0029,  0.0126, -0.0050, -0.0126,
         0.0008, -0.0152,  0.0081, -0.0018, -0.0241,  0.0042, -0.0166,  0.0100,
        -0.0037, -0.0066, -0.0235, -0.0055,  0.0164,  0.0014,  0.0110, -0.0118])
##########################################################
decoder.blks.block2.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[-0.1701,  0.2405,  0.1216,  ..., -0.0188,  0.1203,  0.0939],
        [ 0.0407, -0.0169,  0.0731,  ..., -0.1525, -0.0892,  0.1983],
        [-0.1199,  0.1109, -0.0317,  ...,  0.1291, -0.0194,  0.1063],
        ...,
        [ 0.0664,  0.1387,  0.1945,  ..., -0.2086, -0.1582,  0.1105],
        [ 0.2215,  0.1741,  0.0368,  ..., -0.1901,  0.2426,  0.0723],
        [-0.1613, -0.1369, -0.1379,  ...,  0.0386, -0.2033,  0.1288]])
tensor([[-0.1645,  0.2420,  0.1082,  ..., -0.0302,  0.1032,  0.0211],
        [-0.0010,  0.0123,  0.1083,  ..., -0.1586, -0.1497,  0.1900],
        [-0.0839,  0.1204, -0.0800,  ...,  0.1572, -0.0663,  0.1593],
        ...,
        [ 0.0553,  0.1024,  0.1561,  ..., -0.2189, -0.1628,  0.1175],
        [ 0.2525,  0.1680, -0.0205,  ..., -0.1667,  0.1635,  0.0774],
        [-0.2044, -0.1335, -0.1229,  ...,  0.0903, -0.1990,  0.1183]])
##########################################################
decoder.blks.block2.ffn.dense1.bias shape: torch.Size([32])
tensor([ 0.1068, -0.0478,  0.0804,  0.1127, -0.0902, -0.0627, -0.0596,  0.1168,
        -0.0017,  0.0199, -0.0055,  0.0386,  0.0743,  0.0107,  0.0671, -0.0854,
        -0.0854,  0.0434, -0.0929, -0.0530,  0.1145,  0.0421, -0.1019,  0.1055,
         0.0281,  0.0562,  0.0332, -0.0927,  0.0432,  0.0073,  0.1023,  0.0365])
tensor([ 0.0984, -0.0644,  0.0540,  0.0797, -0.0925, -0.0586, -0.0806,  0.0873,
        -0.0183,  0.0221, -0.0596,  0.0520,  0.0424, -0.0071,  0.0426, -0.0928,
        -0.0895,  0.0191, -0.0900, -0.0577,  0.0663,  0.0156, -0.1218,  0.0453,
        -0.0405,  0.0257,  0.0260, -0.0962, -0.0180, -0.0075,  0.0797,  0.0056])
##########################################################
decoder.blks.block2.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[ 0.0387, -0.2067, -0.1763,  ...,  0.0303,  0.0127,  0.0952],
        [ 0.1605,  0.0439, -0.1068,  ...,  0.2084,  0.0212,  0.2406],
        [ 0.2314,  0.1018,  0.2249,  ...,  0.1169, -0.0260, -0.2280],
        ...,
        [ 0.2319, -0.1618, -0.1419,  ...,  0.0785, -0.2337, -0.0896],
        [-0.1618,  0.1026,  0.1705,  ..., -0.2370, -0.1923, -0.2009],
        [ 0.0584, -0.0296,  0.2042,  ...,  0.1449, -0.1753, -0.0258]])
tensor([[-0.0047, -0.1953, -0.2216,  ...,  0.0440,  0.0094,  0.1147],
        [ 0.1519,  0.0286, -0.1311,  ...,  0.2226,  0.0311,  0.2508],
        [ 0.1896,  0.1097,  0.2120,  ...,  0.1128, -0.0212, -0.2173],
        ...,
        [ 0.2445, -0.1483, -0.1078,  ...,  0.0869, -0.2090, -0.1145],
        [-0.1459,  0.1157,  0.1589,  ..., -0.2053, -0.2142, -0.1673],
        [ 0.0547, -0.0629,  0.1481,  ...,  0.1306, -0.1845, -0.0720]])
##########################################################
decoder.blks.block2.ffn.dense2.bias shape: torch.Size([64])
tensor([ 0.0959,  0.0861, -0.0412,  0.1405, -0.1361, -0.0745,  0.0793, -0.1317,
         0.1198,  0.1488, -0.1477,  0.0564, -0.0925,  0.1188,  0.0735, -0.0880,
         0.0415, -0.1136,  0.1286, -0.0788, -0.0377,  0.1691,  0.0854,  0.1387,
        -0.0379,  0.1763,  0.1115, -0.1599, -0.0023,  0.0191, -0.0104, -0.0809,
        -0.1057, -0.0983,  0.0769,  0.1147, -0.1297, -0.1244, -0.1305,  0.0877,
        -0.0134,  0.0139,  0.1175,  0.0760, -0.0894,  0.1311, -0.1139, -0.0865,
        -0.1108, -0.0055, -0.1598, -0.1454, -0.0148,  0.1602, -0.1493,  0.0917,
         0.1553, -0.1020, -0.0209,  0.1460,  0.0881, -0.0454, -0.1292,  0.1523])
tensor([ 0.0993,  0.0961, -0.0491,  0.1122, -0.1472, -0.1026,  0.0741, -0.1230,
         0.1239,  0.1546, -0.1422,  0.0507, -0.0837,  0.1217,  0.0772, -0.0659,
         0.0255, -0.1033,  0.1174, -0.0350, -0.0504,  0.1563,  0.0812,  0.1259,
        -0.0368,  0.1931,  0.1082, -0.1468, -0.0225,  0.0304, -0.0085, -0.1033,
        -0.1007, -0.0916,  0.0604,  0.1344, -0.1503, -0.1316, -0.1035,  0.0880,
         0.0096, -0.0030,  0.1043,  0.0697, -0.1013,  0.1466, -0.1259, -0.0910,
        -0.1110, -0.0188, -0.1490, -0.1314, -0.0477,  0.1693, -0.1417,  0.0950,
         0.1413, -0.1044, -0.0379,  0.1486,  0.0846, -0.0358, -0.1154,  0.1404])
##########################################################
decoder.blks.block2.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0127, 0.9743, 1.0035, 1.0173, 1.0278, 0.9964, 1.0005, 1.0365, 1.0634,
        0.9996, 0.9698, 1.0618, 0.9923, 0.9822, 0.9935, 1.0431, 0.9928, 0.9888,
        1.0577, 1.0131, 1.0139, 1.0432, 1.0173, 1.0157, 0.9865, 0.9910, 1.0126,
        1.0050, 0.9897, 1.0049, 0.9626, 0.9909, 1.0094, 0.9886, 1.0414, 1.0012,
        0.9716, 1.0014, 1.0028, 0.9781, 1.0048, 0.9906, 1.0061, 0.9824, 0.9888,
        1.0264, 0.9899, 1.0049, 1.0105, 1.0065, 0.9940, 0.9760, 0.9783, 0.9901,
        0.9596, 1.0076, 0.9704, 1.0060, 1.0071, 1.0143, 1.0494, 0.9944, 1.0139,
        0.9918])
##########################################################
decoder.blks.block2.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([ 0.0045,  0.0045,  0.0149, -0.0128,  0.0019, -0.0263,  0.0072, -0.0014,
        -0.0020,  0.0122,  0.0030, -0.0078,  0.0059, -0.0007, -0.0066,  0.0029,
        -0.0279,  0.0028, -0.0076,  0.0326, -0.0116, -0.0064,  0.0018, -0.0174,
        -0.0062,  0.0110, -0.0025,  0.0043, -0.0124, -0.0114,  0.0009, -0.0088,
         0.0070,  0.0036,  0.0042,  0.0166, -0.0057, -0.0108, -0.0032,  0.0019,
         0.0044, -0.0186,  0.0021, -0.0038,  0.0004,  0.0185, -0.0116, -0.0090,
         0.0002, -0.0201, -0.0087,  0.0096, -0.0159, -0.0100, -0.0052,  0.0128,
        -0.0129, -0.0059, -0.0219,  0.0003,  0.0099,  0.0103,  0.0031,  0.0101])
##########################################################
decoder.blks.block3.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[-0.0250,  0.1247,  0.0437,  ...,  0.1512, -0.1362, -0.1385],
        [-0.1219,  0.1171, -0.0445,  ...,  0.1520,  0.2141, -0.1741],
        [-0.1443, -0.0537, -0.2102,  ...,  0.0598,  0.0660, -0.0829],
        ...,
        [-0.1130,  0.1523, -0.2142,  ...,  0.0844,  0.1203, -0.0968],
        [-0.1844, -0.1389, -0.1972,  ..., -0.1771,  0.1469, -0.1291],
        [ 0.0012, -0.0739,  0.1951,  ...,  0.1517, -0.1702,  0.0604]])
tensor([[ 0.0446,  0.1194,  0.0751,  ...,  0.1308, -0.0800, -0.1503],
        [-0.0562,  0.1141, -0.0825,  ...,  0.1262,  0.1841, -0.1987],
        [-0.1350, -0.0984, -0.1662,  ...,  0.0239,  0.0561, -0.0675],
        ...,
        [-0.1320,  0.1456, -0.1664,  ...,  0.0663,  0.1549, -0.0933],
        [-0.2470, -0.1129, -0.1302,  ..., -0.2582,  0.1652, -0.1486],
        [ 0.0063, -0.0642,  0.1902,  ...,  0.1548, -0.1625,  0.0771]])
##########################################################
decoder.blks.block3.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.0828,  0.1787, -0.1815,  ...,  0.2104, -0.1274, -0.0944],
        [ 0.1357,  0.2043,  0.0937,  ...,  0.1686, -0.2076,  0.1509],
        [-0.0330,  0.1210,  0.1024,  ..., -0.0499,  0.1141,  0.0982],
        ...,
        [-0.1441,  0.2135,  0.0758,  ...,  0.0707,  0.1155,  0.0470],
        [-0.1178,  0.0855,  0.2020,  ...,  0.0876,  0.0130,  0.0009],
        [ 0.1730,  0.1430,  0.1953,  ..., -0.1132, -0.1760, -0.1443]])
tensor([[ 0.1080,  0.1490, -0.1697,  ...,  0.1944, -0.1139, -0.0800],
        [ 0.2022,  0.2210,  0.1267,  ...,  0.1833, -0.2129,  0.1882],
        [-0.0847,  0.0842,  0.0594,  ..., -0.0160,  0.0901,  0.0803],
        ...,
        [-0.1128,  0.2554,  0.0696,  ...,  0.0360,  0.1322,  0.0056],
        [-0.0470,  0.1158,  0.2079,  ...,  0.0733,  0.0538, -0.0092],
        [ 0.2103,  0.1305,  0.1995,  ..., -0.0931, -0.1670, -0.1298]])
##########################################################
decoder.blks.block3.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.0221,  0.0418, -0.0892,  ...,  0.0701, -0.0799,  0.0776],
        [-0.0411, -0.0617, -0.0106,  ..., -0.0651, -0.0969, -0.1611],
        [-0.0899, -0.1377,  0.1754,  ..., -0.1358, -0.0089, -0.0950],
        ...,
        [-0.1149,  0.0361,  0.0503,  ..., -0.0388, -0.1757,  0.0566],
        [-0.0244, -0.0423, -0.0163,  ...,  0.1142, -0.0165,  0.0019],
        [ 0.1238, -0.0728,  0.0745,  ..., -0.0050,  0.1315,  0.1710]])
tensor([[ 0.0219,  0.0571, -0.0462,  ...,  0.0801, -0.0985,  0.0874],
        [ 0.0270, -0.0293, -0.0277,  ..., -0.0599, -0.1321, -0.1539],
        [-0.0486, -0.1139,  0.1339,  ..., -0.1173,  0.0347, -0.1074],
        ...,
        [-0.0627,  0.0746,  0.0693,  ..., -0.0370, -0.1887,  0.0044],
        [ 0.0456, -0.0026, -0.0267,  ...,  0.0994, -0.0469, -0.0328],
        [ 0.1060, -0.1013,  0.1078,  ..., -0.0312,  0.1318,  0.1693]])
##########################################################
decoder.blks.block3.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[-0.1025,  0.1854,  0.0244,  ..., -0.1348, -0.1908,  0.0962],
        [-0.1447, -0.1444, -0.1502,  ..., -0.2021,  0.0442,  0.0562],
        [ 0.0526, -0.1381, -0.1857,  ...,  0.0957,  0.0306, -0.1029],
        ...,
        [-0.1452,  0.0784,  0.1983,  ...,  0.0395, -0.0046,  0.1873],
        [ 0.1893, -0.0845, -0.0427,  ...,  0.0230,  0.2162,  0.0200],
        [ 0.1258, -0.0430,  0.1634,  ...,  0.0866, -0.1375, -0.0578]])
tensor([[-0.0952,  0.1637,  0.0089,  ..., -0.1213, -0.1760,  0.1195],
        [-0.1209, -0.1274, -0.1243,  ..., -0.2112,  0.0517,  0.0086],
        [ 0.0934, -0.1923, -0.1507,  ...,  0.0819,  0.0188, -0.0977],
        ...,
        [-0.2140,  0.0710,  0.2094,  ...,  0.0362,  0.0018,  0.1991],
        [ 0.1646, -0.1180, -0.1075,  ...,  0.0246,  0.2336,  0.0182],
        [ 0.1521, -0.0485,  0.1919,  ...,  0.1093, -0.1549, -0.0427]])
##########################################################
decoder.blks.block3.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0076, 1.0277, 1.0289, 1.0465, 1.0613, 1.0410, 1.0505, 1.0285, 1.0263,
        1.0738, 1.0154, 1.0718, 1.0211, 1.0419, 0.9865, 1.0789, 1.0203, 1.0271,
        1.0524, 1.0176, 1.0252, 1.0597, 1.0160, 0.9961, 1.0071, 1.0519, 1.0412,
        1.0003, 1.0066, 1.0245, 0.9814, 1.0044, 1.0557, 1.0270, 1.0168, 1.0127,
        1.0027, 1.0207, 1.0060, 1.0102, 1.0279, 1.0329, 1.0022, 0.9983, 0.9958,
        1.0405, 1.0174, 0.9996, 1.0349, 0.9992, 0.9807, 0.9798, 1.0121, 1.0358,
        1.0282, 1.0130, 1.0068, 1.0400, 1.0449, 1.0525, 1.0596, 1.0172, 1.0351,
        1.0353])
##########################################################
decoder.blks.block3.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-2.1302e-02, -9.5450e-03,  1.6747e-03, -1.3934e-02, -2.3296e-03,
        -9.8826e-03, -1.8848e-02,  1.6015e-02, -5.3434e-03,  2.0162e-02,
        -5.0510e-03,  7.1496e-03, -5.2978e-03, -9.6116e-03,  6.6796e-03,
         1.4788e-02,  3.1067e-03,  1.5503e-02, -7.9596e-03, -1.4174e-02,
        -1.3477e-02, -2.1251e-02,  5.1659e-03,  5.9963e-03,  6.1932e-03,
         2.8174e-02,  9.4195e-03, -3.4686e-03, -3.6708e-03, -1.3084e-02,
        -2.0821e-02,  1.5882e-02,  2.3336e-04,  9.1273e-03, -3.3935e-03,
         1.0553e-02,  1.1161e-02, -1.1200e-02,  1.2236e-02,  7.3122e-03,
         1.1950e-02, -1.0287e-03,  7.2970e-03,  7.1135e-03,  3.3852e-03,
         2.9357e-03, -1.1911e-02, -4.6713e-03, -1.0575e-02, -1.3542e-03,
         3.9189e-03,  1.2100e-02, -1.0585e-03, -2.1569e-02, -5.7909e-03,
         4.6281e-03, -1.5038e-02, -9.1391e-03, -1.0813e-02,  1.1266e-03,
         4.1397e-04,  2.0522e-05,  1.8283e-02,  1.5448e-03])
##########################################################
decoder.blks.block3.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[-0.1868,  0.0112,  0.2099,  ...,  0.1759,  0.1997,  0.0598],
        [-0.0872,  0.0531,  0.0615,  ...,  0.2068, -0.0845,  0.0565],
        [-0.0967,  0.1381,  0.1697,  ...,  0.1923, -0.0446, -0.0026],
        ...,
        [ 0.0319,  0.2134,  0.1472,  ...,  0.0178,  0.0650,  0.1543],
        [ 0.1705, -0.1474,  0.1248,  ..., -0.1176,  0.1805,  0.1996],
        [ 0.0697, -0.0971,  0.0983,  ..., -0.1236,  0.1054,  0.1346]])
tensor([[-0.2235,  0.0205,  0.2178,  ...,  0.1512,  0.1440,  0.0578],
        [-0.0632,  0.0833,  0.0600,  ...,  0.2084, -0.0219,  0.0321],
        [-0.0982,  0.1309,  0.1760,  ...,  0.1681,  0.0371,  0.0126],
        ...,
        [ 0.0409,  0.1968,  0.1647,  ...,  0.0556,  0.0813,  0.1579],
        [ 0.1908, -0.2170,  0.1349,  ..., -0.0761,  0.1723,  0.2591],
        [-0.0327, -0.1554,  0.1190,  ..., -0.1468,  0.1155,  0.1140]])
##########################################################
decoder.blks.block3.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.1482, -0.1853,  0.1155,  ...,  0.2024,  0.2006, -0.0896],
        [ 0.2162, -0.1011,  0.1475,  ...,  0.0706, -0.1086,  0.0247],
        [ 0.1503, -0.1010, -0.1917,  ..., -0.0497, -0.2161,  0.0635],
        ...,
        [-0.0493, -0.1094,  0.0331,  ..., -0.1006, -0.0438,  0.0451],
        [-0.0743, -0.0851, -0.0125,  ...,  0.1411, -0.1957,  0.1871],
        [ 0.0464,  0.0995, -0.0821,  ...,  0.0279,  0.0796, -0.0896]])
tensor([[ 0.1486, -0.2097,  0.1428,  ...,  0.2195,  0.2145, -0.1110],
        [ 0.2131, -0.0949,  0.1416,  ...,  0.0838, -0.0923,  0.0641],
        [ 0.1869, -0.1422, -0.1961,  ..., -0.0589, -0.1575,  0.0399],
        ...,
        [-0.0799, -0.0858,  0.0297,  ..., -0.0901, -0.0580,  0.0658],
        [-0.0793, -0.0916,  0.0031,  ...,  0.2053, -0.1451,  0.2194],
        [ 0.0234,  0.1223, -0.0552,  ...,  0.0404,  0.0917, -0.0612]])
##########################################################
decoder.blks.block3.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[-0.0691,  0.0758,  0.1404,  ...,  0.1877, -0.0326, -0.0757],
        [-0.1031, -0.1113,  0.1783,  ...,  0.1314,  0.1099, -0.1244],
        [-0.0850, -0.1597, -0.1802,  ...,  0.1255,  0.0430,  0.1390],
        ...,
        [ 0.0822, -0.0973, -0.0098,  ..., -0.0767,  0.0151, -0.1456],
        [ 0.1883, -0.0241,  0.1165,  ...,  0.0843, -0.1806,  0.0956],
        [ 0.1467, -0.0226, -0.1144,  ..., -0.0643,  0.1439, -0.2106]])
tensor([[-0.0648,  0.0246,  0.1271,  ...,  0.1628, -0.0338, -0.0903],
        [-0.1215, -0.1420,  0.1721,  ...,  0.1380,  0.1002, -0.1305],
        [-0.0630, -0.1867, -0.1699,  ...,  0.0965,  0.0441,  0.1336],
        ...,
        [ 0.0753, -0.0741,  0.0124,  ..., -0.0379,  0.0280, -0.1165],
        [ 0.1910, -0.0373,  0.1157,  ...,  0.0875, -0.1855,  0.0986],
        [ 0.1496, -0.0353, -0.1578,  ..., -0.0745,  0.1747, -0.1866]])
##########################################################
decoder.blks.block3.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[-0.1140, -0.1788, -0.2116,  ...,  0.0832, -0.1181, -0.1158],
        [ 0.0787,  0.0302,  0.0830,  ..., -0.1052,  0.0807, -0.1525],
        [-0.0764,  0.1545,  0.0485,  ..., -0.1538,  0.1419, -0.2147],
        ...,
        [-0.0829, -0.1888,  0.2036,  ..., -0.1339, -0.1101, -0.1939],
        [-0.1621, -0.1408, -0.0798,  ...,  0.0013,  0.1951,  0.0651],
        [-0.0210,  0.1961, -0.1125,  ..., -0.1737,  0.1177,  0.1646]])
tensor([[-0.1264, -0.1915, -0.1878,  ...,  0.0935, -0.1306, -0.1000],
        [ 0.0758,  0.0319,  0.0738,  ..., -0.1041,  0.0961, -0.1457],
        [-0.0649,  0.1465,  0.0540,  ..., -0.1544,  0.1216, -0.2125],
        ...,
        [-0.0816, -0.1937,  0.1780,  ..., -0.1320, -0.0894, -0.1996],
        [-0.1718, -0.1133, -0.1045,  ...,  0.0025,  0.1561,  0.0474],
        [-0.0213,  0.1765, -0.1102,  ..., -0.1852,  0.0805,  0.1647]])
##########################################################
decoder.blks.block3.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9642, 1.0004, 1.0169, 1.0157, 1.0359, 1.0160, 1.0093, 1.0102, 0.9793,
        1.0539, 0.9996, 1.0482, 0.9970, 1.0092, 0.9690, 1.0430, 0.9974, 1.0036,
        1.0444, 0.9999, 1.0030, 1.0476, 0.9938, 0.9738, 0.9886, 1.0082, 1.0045,
        0.9715, 0.9849, 1.0132, 0.9886, 0.9733, 1.0263, 0.9952, 1.0138, 0.9940,
        0.9659, 1.0013, 0.9861, 0.9905, 1.0076, 0.9933, 0.9854, 0.9850, 0.9622,
        0.9969, 0.9913, 1.0049, 1.0225, 0.9830, 0.9575, 0.9745, 0.9929, 1.0177,
        0.9993, 0.9845, 1.0004, 1.0359, 1.0103, 1.0523, 1.0165, 0.9914, 1.0118,
        0.9933])
##########################################################
decoder.blks.block3.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0287, -0.0064,  0.0113, -0.0118, -0.0056, -0.0117, -0.0084,  0.0125,
        -0.0057,  0.0176, -0.0169,  0.0118, -0.0164, -0.0065,  0.0073,  0.0114,
         0.0003,  0.0209, -0.0077, -0.0154, -0.0106, -0.0292,  0.0035,  0.0035,
         0.0035,  0.0139,  0.0027, -0.0033, -0.0085, -0.0106, -0.0257,  0.0147,
         0.0086,  0.0106, -0.0101,  0.0107,  0.0032, -0.0141,  0.0152,  0.0080,
         0.0050,  0.0005, -0.0013, -0.0056,  0.0059,  0.0075, -0.0163, -0.0209,
        -0.0088,  0.0056,  0.0087,  0.0053, -0.0056, -0.0151, -0.0065,  0.0022,
        -0.0139, -0.0136, -0.0054, -0.0087,  0.0008,  0.0026,  0.0236,  0.0023])
##########################################################
decoder.blks.block3.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[ 5.9782e-02,  7.0195e-02, -7.0978e-02,  ..., -5.4233e-02,
         -1.6544e-01, -1.8418e-01],
        [ 1.8437e-01,  2.3550e-01, -2.3793e-01,  ..., -9.2045e-02,
          5.7296e-02, -1.1560e-01],
        [-1.4361e-01, -5.1150e-02, -9.7195e-02,  ...,  7.4497e-02,
          7.4425e-02, -2.4189e-01],
        ...,
        [ 5.5333e-03,  1.6139e-01, -2.2779e-01,  ...,  9.2655e-05,
          8.2179e-02, -2.3221e-01],
        [ 1.3526e-01, -1.6489e-01,  1.6275e-01,  ..., -1.8818e-01,
         -1.8635e-01, -4.4066e-02],
        [-6.5078e-03, -1.7618e-01,  2.2310e-01,  ..., -2.5565e-02,
         -5.9025e-02,  1.5182e-02]])
tensor([[ 0.0894,  0.0655, -0.0659,  ..., -0.0397, -0.1000, -0.2060],
        [ 0.2371,  0.2858, -0.2503,  ...,  0.0076,  0.0833, -0.1028],
        [-0.1502, -0.0599, -0.0954,  ...,  0.0798,  0.0544, -0.2402],
        ...,
        [-0.0381,  0.1880, -0.2737,  ...,  0.0184,  0.1194, -0.2549],
        [ 0.1349, -0.1451,  0.1481,  ..., -0.2256, -0.2089, -0.0816],
        [ 0.0255, -0.1523,  0.2351,  ..., -0.0160, -0.0319,  0.0006]])
##########################################################
decoder.blks.block3.ffn.dense1.bias shape: torch.Size([32])
tensor([-0.0396, -0.0800,  0.0985,  0.0470, -0.0112,  0.0805,  0.0244, -0.1182,
        -0.0809, -0.0601,  0.0059,  0.0917, -0.0641,  0.0958, -0.0751,  0.0632,
        -0.0938, -0.0201,  0.0033, -0.0150,  0.0311,  0.0753,  0.0876,  0.0465,
        -0.0237, -0.1233,  0.0689,  0.0737, -0.0817,  0.0859, -0.1045,  0.0866])
tensor([-0.0815, -0.1134,  0.0851,  0.0133, -0.0444,  0.0562,  0.0092, -0.1491,
        -0.0900, -0.0924,  0.0018,  0.0388, -0.0663,  0.0703, -0.0826,  0.0588,
        -0.1014, -0.0098, -0.0277, -0.0283,  0.0175,  0.0729,  0.0870,  0.0406,
        -0.0693, -0.1361,  0.0132,  0.0716, -0.0848,  0.0580, -0.1188,  0.0732])
##########################################################
decoder.blks.block3.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[-0.2429, -0.1716, -0.0463,  ...,  0.2395,  0.0071, -0.2443],
        [-0.0781,  0.0243, -0.0840,  ..., -0.2460, -0.2296, -0.1756],
        [ 0.1522,  0.0822, -0.1155,  ..., -0.0677,  0.2090, -0.0440],
        ...,
        [ 0.1676,  0.1402,  0.0712,  ..., -0.1568, -0.0813, -0.1445],
        [-0.0805,  0.0128, -0.2315,  ...,  0.0595,  0.1765,  0.0626],
        [-0.1291, -0.0140, -0.1207,  ...,  0.1671, -0.0339,  0.0162]])
tensor([[-0.2889, -0.1372, -0.0897,  ...,  0.2602,  0.0019, -0.2074],
        [-0.1448, -0.0013, -0.1114,  ..., -0.2273, -0.1924, -0.1613],
        [ 0.1730,  0.0860, -0.1115,  ..., -0.0912,  0.2035, -0.0478],
        ...,
        [ 0.1447,  0.1831,  0.0939,  ..., -0.1651, -0.0502, -0.1392],
        [-0.1144, -0.0089, -0.2293,  ...,  0.0758,  0.2455,  0.0823],
        [-0.1264,  0.0096, -0.1351,  ...,  0.1634,  0.0133,  0.0101]])
##########################################################
decoder.blks.block3.ffn.dense2.bias shape: torch.Size([64])
tensor([ 0.0824,  0.1072, -0.0958, -0.1442,  0.1595,  0.0058, -0.0156,  0.0509,
        -0.0497,  0.0040,  0.0035, -0.1031, -0.1359, -0.1721, -0.0069, -0.1319,
         0.1061,  0.0198,  0.0516, -0.0158, -0.1615, -0.0536,  0.0446,  0.1026,
         0.0093,  0.1157,  0.0592, -0.1054,  0.0099, -0.1587, -0.1384,  0.0800,
        -0.1249, -0.1045,  0.1103, -0.1298,  0.0413,  0.1259,  0.1751,  0.1004,
        -0.0032, -0.0969,  0.0889,  0.0200,  0.1208, -0.1440,  0.0204, -0.0437,
        -0.1016, -0.1693, -0.1229, -0.1545,  0.0635,  0.1669,  0.1031, -0.0541,
        -0.1540,  0.0767,  0.1338, -0.1410, -0.1761,  0.0182,  0.0395,  0.1613])
tensor([ 0.0588,  0.1009, -0.0941, -0.1520,  0.1475, -0.0005, -0.0251,  0.0611,
        -0.0774,  0.0231,  0.0013, -0.0938, -0.1547, -0.1838, -0.0097, -0.1362,
         0.1080,  0.0394,  0.0493, -0.0230, -0.1671, -0.0469,  0.0369,  0.1197,
         0.0172,  0.1167,  0.0597, -0.0878, -0.0072, -0.1727, -0.1530,  0.0811,
        -0.1274, -0.1033,  0.0933, -0.1135,  0.0483,  0.1234,  0.2004,  0.1222,
        -0.0035, -0.0932,  0.0905,  0.0246,  0.1262, -0.1302,  0.0459, -0.0686,
        -0.0929, -0.1608, -0.1053, -0.1512,  0.0637,  0.1518,  0.0785, -0.0475,
        -0.1424,  0.0746,  0.1298, -0.1340, -0.1619,  0.0169,  0.0695,  0.1556])
##########################################################
decoder.blks.block3.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9868, 0.9871, 1.0284, 0.9998, 0.9843, 1.0377, 1.0163, 1.0191, 1.0090,
        1.0449, 1.0456, 1.0478, 0.9739, 1.0360, 0.9733, 1.0592, 1.0312, 1.0410,
        1.0578, 0.9936, 1.0180, 1.0493, 1.0079, 0.9745, 0.9739, 1.0054, 1.0927,
        0.9669, 0.9949, 0.9978, 0.9998, 0.9800, 1.0517, 0.9928, 1.0364, 1.0053,
        1.0096, 1.0152, 0.9973, 1.0256, 1.0367, 0.9855, 1.0171, 1.0068, 1.0021,
        1.0024, 0.9948, 1.0164, 1.0267, 1.0131, 0.9999, 0.9800, 1.0073, 1.0149,
        1.0048, 1.0023, 1.0448, 1.0343, 1.0407, 1.0200, 1.0201, 0.9971, 1.0616,
        0.9881])
##########################################################
decoder.blks.block3.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0256, -0.0092, -0.0016, -0.0014,  0.0103, -0.0002, -0.0113,  0.0134,
        -0.0234,  0.0167,  0.0048,  0.0041, -0.0228, -0.0071,  0.0002,  0.0056,
        -0.0046,  0.0177, -0.0024, -0.0035,  0.0030, -0.0004, -0.0028,  0.0003,
         0.0031,  0.0175, -0.0028,  0.0237, -0.0121, -0.0118, -0.0096,  0.0054,
        -0.0074, -0.0053,  0.0106,  0.0066,  0.0106,  0.0030,  0.0063,  0.0106,
        -0.0023,  0.0002, -0.0060,  0.0010,  0.0195,  0.0220,  0.0113, -0.0213,
        -0.0049,  0.0054,  0.0031,  0.0255, -0.0096, -0.0071, -0.0054,  0.0109,
        -0.0043,  0.0036, -0.0140,  0.0131, -0.0066,  0.0005,  0.0210,  0.0139])
##########################################################
decoder.blks.block4.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[-0.0796,  0.0483,  0.1363,  ...,  0.1566, -0.1803, -0.0987],
        [-0.1642,  0.1449,  0.1910,  ..., -0.1378, -0.1909, -0.1045],
        [ 0.0787,  0.1950,  0.1592,  ..., -0.0626,  0.0071,  0.1842],
        ...,
        [-0.0613,  0.0038,  0.1439,  ..., -0.0056, -0.0372, -0.0442],
        [ 0.1343,  0.2051,  0.1064,  ...,  0.1289,  0.1337,  0.1236],
        [-0.0041, -0.1269,  0.0846,  ..., -0.1371, -0.0754, -0.0082]])
tensor([[-0.0719,  0.0953,  0.1439,  ...,  0.1442, -0.1653, -0.1575],
        [-0.1662,  0.1296,  0.2040,  ..., -0.1010, -0.1645, -0.1149],
        [ 0.1338,  0.1889,  0.0902,  ...,  0.0082, -0.0447,  0.2147],
        ...,
        [-0.0479, -0.0108,  0.1389,  ...,  0.0139, -0.1191, -0.1443],
        [ 0.1649,  0.1970,  0.1217,  ...,  0.1689,  0.1675,  0.1201],
        [-0.0425, -0.1472,  0.0886,  ..., -0.1398, -0.0766, -0.0094]])
##########################################################
decoder.blks.block4.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.2040, -0.2071,  0.0213,  ...,  0.0270, -0.2057,  0.1255],
        [ 0.1742,  0.0724, -0.0544,  ..., -0.1049, -0.1892, -0.0736],
        [ 0.1896, -0.1045, -0.1257,  ...,  0.1155, -0.0809, -0.0738],
        ...,
        [ 0.0558, -0.1528,  0.0775,  ...,  0.0181,  0.0662, -0.0902],
        [ 0.2074,  0.0523,  0.1979,  ..., -0.1349, -0.0332, -0.1392],
        [-0.0622, -0.0790, -0.1488,  ...,  0.2121, -0.2045, -0.1094]])
tensor([[ 0.2086, -0.1867,  0.0727,  ..., -0.0601, -0.1680,  0.1362],
        [ 0.1399,  0.0563, -0.0601,  ..., -0.1148, -0.2061, -0.1046],
        [ 0.2283, -0.1039, -0.1446,  ...,  0.1249, -0.1165, -0.1058],
        ...,
        [ 0.0967, -0.1626,  0.1067,  ...,  0.0337,  0.0316, -0.0916],
        [ 0.1614,  0.0150,  0.1794,  ..., -0.1840, -0.0246, -0.1489],
        [-0.0736, -0.0552, -0.1953,  ...,  0.2287, -0.2524, -0.1695]])
##########################################################
decoder.blks.block4.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[-0.1180,  0.1010, -0.0785,  ...,  0.0135,  0.1997, -0.1754],
        [ 0.1283,  0.1196, -0.1210,  ..., -0.1150,  0.1433,  0.1118],
        [ 0.1037, -0.0975, -0.1202,  ..., -0.0658,  0.2036,  0.1521],
        ...,
        [ 0.0642, -0.1962,  0.1308,  ...,  0.2034,  0.1180, -0.1579],
        [ 0.0441,  0.0191,  0.1455,  ...,  0.1782,  0.2107,  0.1773],
        [-0.0670, -0.0918, -0.0957,  ..., -0.0211, -0.1678,  0.1084]])
tensor([[-0.1293,  0.1605, -0.0832,  ..., -0.0118,  0.1904, -0.1669],
        [ 0.1061,  0.1271, -0.1097,  ..., -0.1097,  0.2016,  0.1360],
        [ 0.1985, -0.0901, -0.1022,  ..., -0.0486,  0.2458,  0.1556],
        ...,
        [ 0.0515, -0.1911,  0.1476,  ...,  0.1807,  0.1638, -0.1463],
        [ 0.0482,  0.0198,  0.1752,  ...,  0.2537,  0.2224,  0.1072],
        [-0.0864, -0.0977, -0.1003,  ..., -0.0782, -0.1260,  0.1079]])
##########################################################
decoder.blks.block4.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.0539,  0.1572,  0.1540,  ...,  0.1592,  0.1137, -0.2091],
        [ 0.1103, -0.1725, -0.1707,  ..., -0.2120, -0.1682, -0.0235],
        [ 0.0018, -0.1595, -0.0749,  ..., -0.0454, -0.0704,  0.1103],
        ...,
        [ 0.0186,  0.1355, -0.1031,  ..., -0.1574,  0.1461, -0.1171],
        [ 0.1108, -0.1772,  0.1782,  ..., -0.1133,  0.0277, -0.0522],
        [ 0.0071,  0.1134,  0.0417,  ..., -0.2061, -0.0315, -0.0423]])
tensor([[ 0.1069,  0.2070,  0.0656,  ...,  0.0930,  0.1630, -0.1607],
        [ 0.0699, -0.1698, -0.1748,  ..., -0.2175, -0.1298,  0.0173],
        [ 0.0770, -0.1551, -0.0669,  ..., -0.0519, -0.0797,  0.1027],
        ...,
        [ 0.0670,  0.0931, -0.1417,  ..., -0.1693,  0.0993, -0.0926],
        [ 0.0574, -0.2054,  0.1572,  ..., -0.1406,  0.0742,  0.0033],
        [ 0.0344,  0.1287, -0.0061,  ..., -0.1973, -0.1174, -0.0558]])
##########################################################
decoder.blks.block4.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0320, 1.0142, 1.0228, 1.0237, 1.0154, 1.0333, 0.9839, 1.0090, 1.0443,
        1.0431, 1.0433, 1.0551, 1.0121, 1.0308, 1.0163, 1.1051, 0.9902, 1.0021,
        1.0418, 1.0053, 1.0131, 1.0475, 1.0299, 0.9764, 1.0015, 1.0029, 1.0853,
        0.9851, 0.9931, 1.0085, 0.9911, 1.0104, 1.0687, 0.9931, 1.0061, 1.0157,
        1.0062, 0.9919, 0.9942, 1.0466, 1.0596, 0.9844, 1.0632, 1.0309, 1.0255,
        1.0056, 1.0272, 1.0297, 1.0214, 1.0291, 1.0249, 1.0097, 1.0359, 1.0510,
        1.0285, 1.0358, 0.9975, 1.0353, 1.0214, 1.0464, 1.0068, 1.0332, 1.0526,
        1.0066])
##########################################################
decoder.blks.block4.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-9.9419e-03, -1.3514e-02,  5.0556e-03, -1.2474e-02,  8.7086e-03,
        -9.3974e-03,  1.3173e-02, -2.0970e-02, -2.8651e-05,  8.6578e-03,
        -1.8845e-02, -5.7376e-03, -2.2216e-03, -1.0871e-02,  1.3626e-03,
         6.4064e-03,  1.5067e-02,  2.7813e-03, -2.0780e-03, -1.1478e-02,
         1.0541e-02,  9.5677e-03, -1.2353e-02,  1.1056e-02,  4.5407e-03,
         2.2902e-03, -1.0000e-02,  1.3040e-02, -2.2439e-02, -3.8824e-03,
        -1.6259e-02,  9.9757e-04, -1.6803e-02, -2.2526e-02,  1.4244e-02,
        -5.0883e-03,  4.3506e-03,  1.6708e-02,  2.4082e-02, -9.5390e-03,
         2.3111e-03, -5.9059e-03, -8.7377e-03, -9.9003e-03,  1.2614e-02,
         1.8158e-02,  1.0153e-02, -5.9861e-03, -5.7570e-03, -3.3568e-03,
         3.9639e-03,  1.3073e-02, -7.6729e-03, -1.4220e-03,  8.1197e-03,
        -4.9844e-03, -4.8246e-04,  1.1920e-02, -5.9603e-03,  4.8549e-03,
        -5.8830e-03,  5.0180e-03,  1.3104e-02, -9.7876e-04])
##########################################################
decoder.blks.block4.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.1215, -0.2036, -0.0414,  ...,  0.2153,  0.0653, -0.0494],
        [-0.2085, -0.1176, -0.0461,  ...,  0.1126, -0.0158,  0.0806],
        [ 0.0624,  0.1461, -0.2122,  ..., -0.0509,  0.0909, -0.1441],
        ...,
        [-0.0951,  0.1423, -0.0229,  ...,  0.0422,  0.0723, -0.1373],
        [ 0.1598,  0.1558,  0.2056,  ...,  0.1996, -0.1933, -0.0460],
        [ 0.1845,  0.0374, -0.1276,  ..., -0.2034, -0.0449,  0.0754]])
tensor([[ 0.0985, -0.2232,  0.0294,  ...,  0.1815,  0.1859, -0.0700],
        [-0.2235, -0.1122, -0.0111,  ...,  0.1239,  0.0420,  0.0687],
        [ 0.0628,  0.1523, -0.1720,  ..., -0.0702,  0.1917, -0.1220],
        ...,
        [-0.0871,  0.1029, -0.0555,  ...,  0.0363,  0.1419, -0.1481],
        [ 0.1697,  0.1749,  0.2026,  ...,  0.2256, -0.1867, -0.0254],
        [ 0.2332,  0.0185, -0.1492,  ..., -0.1680, -0.0252,  0.1164]])
##########################################################
decoder.blks.block4.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[-0.1762, -0.0939, -0.0204,  ...,  0.1555, -0.0069,  0.0915],
        [ 0.1140, -0.1191,  0.1260,  ...,  0.1462,  0.2104, -0.0423],
        [-0.1771,  0.1171,  0.0109,  ..., -0.0895,  0.0580,  0.1330],
        ...,
        [-0.0567,  0.0353, -0.0481,  ..., -0.0776, -0.0806, -0.1365],
        [-0.1044,  0.1726,  0.0323,  ..., -0.2018,  0.1349,  0.0471],
        [-0.0931, -0.0772,  0.1735,  ..., -0.1515, -0.0685, -0.1494]])
tensor([[-0.1341, -0.0649, -0.0607,  ...,  0.1306, -0.0268,  0.1196],
        [ 0.1220, -0.1135,  0.0962,  ...,  0.1821,  0.2417, -0.0259],
        [-0.1227,  0.1065,  0.0433,  ..., -0.0495,  0.0260,  0.1346],
        ...,
        [-0.0953,  0.0384, -0.0607,  ..., -0.1515, -0.0270, -0.1432],
        [-0.0171,  0.2101,  0.0310,  ..., -0.2016,  0.0652,  0.0254],
        [-0.0830, -0.1157,  0.1638,  ..., -0.1577, -0.0424, -0.1759]])
##########################################################
decoder.blks.block4.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.0991,  0.1416,  0.1118,  ..., -0.0123,  0.1151, -0.1952],
        [-0.1224,  0.1650, -0.1619,  ...,  0.0931,  0.0133,  0.0561],
        [-0.1012, -0.1777, -0.0408,  ..., -0.1274,  0.0250,  0.1338],
        ...,
        [-0.1382, -0.0085, -0.0122,  ...,  0.0467, -0.1091, -0.0212],
        [-0.1034, -0.1500, -0.1460,  ..., -0.0778, -0.0181,  0.1999],
        [ 0.1758, -0.0684,  0.1269,  ..., -0.1695,  0.1695,  0.0775]])
tensor([[ 0.0841,  0.1215,  0.0834,  ...,  0.0251,  0.1163, -0.1645],
        [-0.1258,  0.1408, -0.1496,  ...,  0.1085, -0.0136,  0.0776],
        [-0.0762, -0.1713, -0.0408,  ..., -0.1313,  0.0379,  0.1152],
        ...,
        [-0.1221, -0.0064, -0.0223,  ...,  0.0402, -0.0864, -0.0433],
        [-0.0980, -0.1536, -0.1447,  ..., -0.0735,  0.0029,  0.1847],
        [ 0.1836, -0.0628,  0.1377,  ..., -0.1752,  0.1545,  0.0996]])
##########################################################
decoder.blks.block4.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[-0.1316, -0.1885,  0.0824,  ...,  0.0675, -0.1851,  0.0119],
        [ 0.0905,  0.1075,  0.0174,  ...,  0.1812, -0.0011,  0.0322],
        [ 0.0864,  0.0777,  0.0506,  ..., -0.1952, -0.1086,  0.1257],
        ...,
        [-0.1329, -0.0964, -0.1933,  ..., -0.1003, -0.1761, -0.0462],
        [-0.1585, -0.0017, -0.0723,  ...,  0.1187,  0.0522,  0.0040],
        [-0.0420,  0.0068, -0.0448,  ..., -0.2085,  0.1838, -0.0174]])
tensor([[-0.1040, -0.1888,  0.0805,  ...,  0.0401, -0.1900,  0.0343],
        [ 0.0896,  0.0798,  0.0189,  ...,  0.2001,  0.0103, -0.0189],
        [ 0.0890,  0.0485,  0.0725,  ..., -0.2045, -0.1127,  0.1224],
        ...,
        [-0.1360, -0.0928, -0.1657,  ..., -0.0915, -0.1550, -0.0482],
        [-0.1816,  0.0128, -0.0992,  ...,  0.1202,  0.0131,  0.0634],
        [ 0.0052,  0.0254, -0.0872,  ..., -0.2433,  0.1382, -0.0362]])
##########################################################
decoder.blks.block4.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0526, 0.9963, 0.9916, 0.9848, 0.9889, 1.0279, 0.9486, 1.0154, 1.0209,
        1.0261, 1.0283, 1.0263, 1.0011, 1.0173, 0.9937, 1.0817, 0.9879, 0.9969,
        1.0196, 0.9814, 0.9939, 0.9989, 1.0102, 0.9656, 0.9950, 0.9915, 1.0565,
        0.9818, 0.9960, 1.0028, 0.9820, 0.9801, 1.0721, 0.9820, 0.9858, 0.9855,
        0.9989, 0.9578, 0.9764, 1.0225, 1.0314, 0.9846, 1.0298, 1.0102, 0.9955,
        1.0056, 1.0256, 0.9972, 0.9878, 1.0075, 1.0090, 0.9456, 1.0229, 1.0145,
        1.0009, 0.9954, 0.9901, 1.0249, 1.0180, 1.0042, 0.9702, 1.0035, 0.9940,
        0.9753])
##########################################################
decoder.blks.block4.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-1.5098e-02, -1.1685e-02,  2.6268e-03, -6.5975e-03,  1.1123e-02,
        -7.9808e-03,  1.3885e-02, -2.1316e-02, -4.7917e-03,  2.8278e-03,
        -7.1692e-03, -9.1688e-03, -1.3339e-02, -7.8789e-03, -9.0334e-03,
        -8.8225e-04,  1.7296e-02,  7.0298e-03,  6.5309e-03, -6.1663e-03,
         5.0860e-03, -1.8562e-03, -1.1354e-02,  1.3928e-02, -5.4080e-03,
        -2.0766e-03, -1.1880e-02,  1.5604e-02, -1.1431e-02, -1.0132e-02,
        -1.4429e-02, -1.0573e-03, -2.5896e-02, -1.7084e-02,  1.1640e-02,
        -8.1416e-03,  3.8235e-05,  9.8827e-03,  1.2990e-02, -7.9728e-03,
         2.3481e-03, -1.1247e-02, -8.5453e-03, -1.2985e-02,  7.2165e-03,
         1.6727e-02,  5.5450e-03, -5.3293e-03, -1.1033e-02, -8.8404e-03,
         5.9351e-04,  4.4003e-03, -7.7462e-03, -4.0927e-04, -1.3155e-03,
        -2.6077e-03, -7.9970e-03,  8.3133e-03, -7.1201e-03,  7.7028e-03,
        -4.0899e-03,  4.1996e-03,  5.7193e-03, -1.7984e-03])
##########################################################
decoder.blks.block4.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[ 7.3464e-02, -2.4934e-01,  1.6016e-01,  ...,  6.9939e-02,
          1.8705e-01, -1.4699e-01],
        [ 1.0313e-01, -1.8973e-01, -1.8775e-01,  ..., -1.9692e-03,
          1.8310e-01, -2.8502e-02],
        [-5.7782e-02,  6.7745e-02, -1.6843e-01,  ..., -1.1955e-02,
          1.7684e-01,  3.8264e-02],
        ...,
        [-1.9777e-01,  8.9037e-02,  2.4732e-01,  ..., -2.1629e-01,
          2.1552e-01,  1.2132e-01],
        [-2.3780e-01,  1.6990e-01,  1.7524e-05,  ..., -4.0232e-02,
         -1.4201e-01,  1.3849e-01],
        [-1.5231e-01,  1.4394e-02,  1.4974e-01,  ..., -1.9277e-01,
         -1.1662e-01, -1.5109e-01]])
tensor([[ 0.0743, -0.2453,  0.1681,  ...,  0.0438,  0.1905, -0.1549],
        [ 0.0782, -0.2188, -0.1337,  ...,  0.0122,  0.1324, -0.0655],
        [-0.0645,  0.0313, -0.1476,  ...,  0.0419,  0.1997,  0.0646],
        ...,
        [-0.1750,  0.1221,  0.2533,  ..., -0.1822,  0.1314,  0.1254],
        [-0.2655,  0.1678,  0.0147,  ..., -0.0888, -0.0677,  0.1602],
        [-0.1575,  0.0020,  0.0864,  ..., -0.1657, -0.1627, -0.1601]])
##########################################################
decoder.blks.block4.ffn.dense1.bias shape: torch.Size([32])
tensor([ 0.0039,  0.0678, -0.0851,  0.0333, -0.1182,  0.1204, -0.0301,  0.1182,
        -0.0277, -0.0965, -0.1242, -0.0943,  0.0630, -0.0917, -0.0487,  0.0422,
         0.0069, -0.0925, -0.0349, -0.0793,  0.0638, -0.0700, -0.0306, -0.1241,
         0.0222,  0.0892, -0.0030, -0.0382,  0.0947, -0.0985,  0.1128, -0.0605])
tensor([ 0.0110,  0.0662, -0.0915,  0.0273, -0.1248,  0.1153, -0.0816,  0.0750,
        -0.0564, -0.1416, -0.1362, -0.1328,  0.0110, -0.0994, -0.0559,  0.0016,
         0.0240, -0.0862, -0.0506, -0.0802,  0.0489, -0.0840, -0.0467, -0.1552,
         0.0094,  0.0307, -0.0104, -0.0464,  0.0938, -0.1214,  0.1033, -0.0603])
##########################################################
decoder.blks.block4.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[-0.2108, -0.2384,  0.0956,  ...,  0.0828,  0.1842,  0.2295],
        [-0.0444, -0.1341,  0.1333,  ...,  0.1379,  0.1439,  0.1371],
        [-0.2406, -0.1014, -0.1576,  ...,  0.0184, -0.2059,  0.0913],
        ...,
        [-0.2327,  0.1037,  0.1560,  ...,  0.2223, -0.0812,  0.1134],
        [-0.2330,  0.0031,  0.0552,  ..., -0.0735,  0.1040,  0.1461],
        [ 0.0507,  0.1335, -0.0955,  ...,  0.2194, -0.0758,  0.2154]])
tensor([[-0.2239, -0.1884,  0.1496,  ...,  0.0823,  0.2332,  0.2129],
        [-0.0291, -0.1318,  0.1018,  ...,  0.1501,  0.1953,  0.1465],
        [-0.2447, -0.0983, -0.1250,  ...,  0.0428, -0.2284,  0.1222],
        ...,
        [-0.2473,  0.1196,  0.1898,  ...,  0.2368, -0.1225,  0.1221],
        [-0.1962,  0.0332,  0.0695,  ..., -0.1004,  0.1415,  0.1193],
        [-0.0109,  0.0875,  0.0476,  ...,  0.2118, -0.0895,  0.2203]])
##########################################################
decoder.blks.block4.ffn.dense2.bias shape: torch.Size([64])
tensor([-0.1322, -0.0229,  0.1687, -0.1436, -0.1240,  0.1251, -0.1568,  0.0872,
        -0.0826,  0.0343, -0.1647, -0.0597, -0.1758,  0.1430,  0.0636,  0.0527,
        -0.1509, -0.1737,  0.0756, -0.0796,  0.1073,  0.0365,  0.1287, -0.0053,
        -0.1353,  0.1215, -0.1258, -0.1340, -0.1218, -0.1089,  0.0801, -0.0082,
        -0.1461,  0.0315, -0.0507,  0.0502, -0.0804, -0.0673, -0.1440, -0.1211,
         0.0306,  0.0625, -0.1314,  0.1301,  0.1047, -0.0730, -0.0847, -0.1746,
         0.1118,  0.0501,  0.0887,  0.1249,  0.1489, -0.1488, -0.1013, -0.0365,
        -0.0642,  0.1753, -0.0096,  0.1196, -0.1298,  0.0096,  0.0979,  0.0815])
tensor([-0.1385, -0.0246,  0.1928, -0.1504, -0.1092,  0.1218, -0.1439,  0.0502,
        -0.0691,  0.0431, -0.1572, -0.0649, -0.1865,  0.1466,  0.0772,  0.0586,
        -0.1122, -0.1492,  0.0743, -0.0730,  0.1229,  0.0342,  0.1289,  0.0102,
        -0.1271,  0.1157, -0.1178, -0.1258, -0.1454, -0.1178,  0.0814,  0.0195,
        -0.1533,  0.0401, -0.0571,  0.0456, -0.0692, -0.0644, -0.1319, -0.1221,
         0.0411,  0.0482, -0.1183,  0.1198,  0.1006, -0.0548, -0.0719, -0.1741,
         0.0970,  0.0440,  0.1049,  0.1368,  0.1458, -0.1519, -0.1019, -0.0416,
        -0.0691,  0.1603, -0.0096,  0.1067, -0.1327,  0.0149,  0.0848,  0.0484])
##########################################################
decoder.blks.block4.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.0381, 1.0122, 1.0164, 1.0734, 1.0081, 1.0341, 0.9815, 1.0110, 1.0260,
        1.0592, 1.0044, 1.0319, 1.0411, 0.9703, 1.0129, 1.0971, 0.9418, 1.0171,
        1.0200, 0.9920, 1.0375, 1.0327, 1.0617, 0.9630, 1.0117, 1.0177, 1.0511,
        0.9688, 1.0365, 0.9814, 0.9852, 1.0194, 1.0698, 1.0286, 1.0127, 0.9835,
        1.0062, 0.9912, 0.9983, 1.0726, 1.0666, 1.0148, 0.9959, 1.0138, 1.0054,
        0.9812, 1.0120, 1.0142, 1.0133, 1.0065, 1.0291, 0.9995, 1.0769, 1.0310,
        1.0201, 1.0306, 1.0117, 1.0293, 1.0225, 1.0591, 0.9999, 1.0632, 1.0690,
        1.0087])
##########################################################
decoder.blks.block4.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-7.1535e-03,  2.1698e-03,  5.6411e-03, -2.1440e-02, -6.4896e-03,
        -9.3154e-03,  1.6132e-02, -3.1634e-02,  7.4342e-03,  1.6096e-02,
         7.5222e-03, -9.6477e-03, -1.9341e-02,  6.9732e-03, -2.2751e-03,
         5.1473e-03,  2.1581e-02,  4.5279e-03,  9.3874e-03,  2.6364e-04,
         1.5233e-02,  9.9161e-04, -1.4294e-02,  1.2226e-02,  1.0037e-02,
        -5.5966e-03, -5.8174e-03,  8.2579e-03, -7.9050e-03, -9.3389e-03,
         3.6634e-03,  1.7519e-02, -6.2763e-03, -1.0830e-02,  3.6286e-03,
        -1.4854e-02,  7.9796e-03,  1.1493e-02, -7.2083e-03, -1.2284e-02,
        -7.3210e-04, -1.0974e-02,  1.1330e-02,  2.5585e-03,  1.9559e-02,
         1.3221e-02,  4.7819e-03, -6.8568e-03,  5.2137e-03, -1.0891e-03,
         1.6972e-02,  2.1142e-02, -4.0007e-03,  1.1745e-03,  5.5185e-03,
        -1.3437e-03, -2.2889e-03,  3.0453e-05, -5.1577e-03,  3.8300e-03,
        -7.1076e-03, -6.9546e-04,  1.2002e-02, -9.0558e-04])
##########################################################
decoder.blks.block5.attention1.W_q.weight shape: torch.Size([64, 64])
tensor([[ 0.1217, -0.1858,  0.1654,  ..., -0.1121,  0.2093,  0.1673],
        [-0.0456,  0.2057, -0.1528,  ...,  0.0043,  0.1855, -0.0920],
        [ 0.0538,  0.1224,  0.0374,  ..., -0.0657,  0.1736, -0.0709],
        ...,
        [ 0.1416, -0.0501,  0.0664,  ..., -0.1606,  0.1604, -0.1389],
        [ 0.1394, -0.0838,  0.1753,  ...,  0.1203, -0.1719,  0.0201],
        [ 0.2102,  0.1272,  0.0699,  ..., -0.1300, -0.1573,  0.0142]])
tensor([[ 0.1519, -0.1552,  0.1258,  ..., -0.0975,  0.2106,  0.2044],
        [-0.1297,  0.1112, -0.1611,  ...,  0.0188,  0.2780, -0.0629],
        [ 0.1637,  0.1000, -0.0561,  ..., -0.0799,  0.0567, -0.1756],
        ...,
        [ 0.1615, -0.1029,  0.0943,  ..., -0.2017,  0.1584, -0.0966],
        [ 0.1443, -0.1201,  0.2129,  ...,  0.1115, -0.1893,  0.0775],
        [ 0.2173,  0.1149,  0.0385,  ..., -0.2068, -0.2399, -0.0007]])
##########################################################
decoder.blks.block5.attention1.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.0447, -0.1905, -0.0354,  ..., -0.1265, -0.0583, -0.1835],
        [-0.1789,  0.1132,  0.1675,  ..., -0.1557, -0.0220, -0.2026],
        [-0.0428, -0.0598,  0.0468,  ..., -0.1301, -0.0322, -0.1231],
        ...,
        [ 0.0345, -0.1110,  0.2101,  ...,  0.0534,  0.0189, -0.0689],
        [ 0.1774, -0.0561,  0.0254,  ...,  0.1286,  0.1264, -0.1492],
        [ 0.1218, -0.0118, -0.1972,  ..., -0.1129,  0.2081,  0.0584]])
tensor([[ 0.0199, -0.1693, -0.0643,  ..., -0.1336,  0.0255, -0.2175],
        [-0.1985,  0.1144,  0.1701,  ..., -0.1984,  0.0085, -0.1304],
        [-0.0200, -0.0466,  0.0399,  ..., -0.1608, -0.0166, -0.1451],
        ...,
        [ 0.0135, -0.1598,  0.2358,  ...,  0.0221,  0.1088, -0.0793],
        [ 0.1513, -0.1382,  0.0700,  ...,  0.1126,  0.1171, -0.1493],
        [ 0.1500,  0.0380, -0.1907,  ..., -0.1093,  0.1729,  0.0751]])
##########################################################
decoder.blks.block5.attention1.W_v.weight shape: torch.Size([64, 64])
tensor([[ 0.1213, -0.0023, -0.1671,  ...,  0.0025,  0.0191,  0.0345],
        [-0.1352,  0.0683,  0.0783,  ..., -0.1832, -0.2084,  0.0804],
        [-0.0803,  0.1289,  0.0513,  ..., -0.1378, -0.0632,  0.0227],
        ...,
        [ 0.1883,  0.1134,  0.1453,  ...,  0.1245, -0.1520, -0.1908],
        [-0.0981, -0.1840,  0.0920,  ..., -0.1814,  0.0668,  0.2030],
        [ 0.1807,  0.0808,  0.0375,  ...,  0.1982, -0.0678,  0.0745]])
tensor([[ 0.1352,  0.0303, -0.1231,  ...,  0.0034, -0.0026,  0.0321],
        [-0.1607,  0.0689,  0.0801,  ..., -0.1833, -0.2087,  0.0902],
        [-0.0732,  0.1401,  0.0221,  ..., -0.1559, -0.0707,  0.0252],
        ...,
        [ 0.1730,  0.1241,  0.1298,  ...,  0.1292, -0.1166, -0.1793],
        [-0.1182, -0.1662,  0.0452,  ..., -0.1367,  0.0738,  0.1907],
        [ 0.1767,  0.0730,  0.0426,  ...,  0.1860, -0.0428,  0.0878]])
##########################################################
decoder.blks.block5.attention1.W_o.weight shape: torch.Size([64, 64])
tensor([[-0.1139,  0.0684, -0.1777,  ...,  0.0079, -0.1094, -0.1674],
        [-0.1823, -0.1702, -0.0240,  ..., -0.1492, -0.1935,  0.0770],
        [ 0.0827,  0.0639,  0.2076,  ...,  0.1170,  0.0444, -0.0220],
        ...,
        [ 0.1525,  0.1220, -0.1056,  ..., -0.0514,  0.0776,  0.0346],
        [ 0.2028,  0.1312,  0.0858,  ..., -0.2025, -0.2016, -0.1901],
        [ 0.0629,  0.1465, -0.1765,  ...,  0.1980,  0.0360, -0.0372]])
tensor([[-0.1003,  0.0923, -0.1747,  ..., -0.0192, -0.0674, -0.2078],
        [-0.1835, -0.1668, -0.0304,  ..., -0.1888, -0.1652,  0.0817],
        [ 0.1138,  0.0528,  0.2095,  ...,  0.1169,  0.0665, -0.0042],
        ...,
        [ 0.1356,  0.1142, -0.0965,  ..., -0.0609,  0.0804,  0.0335],
        [ 0.1963,  0.1508,  0.1340,  ..., -0.2444, -0.2279, -0.1653],
        [ 0.0906,  0.1442, -0.1854,  ...,  0.1784,  0.0303, -0.0118]])
##########################################################
decoder.blks.block5.addnorm1.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9895, 1.0002, 1.0103, 1.0494, 0.9752, 1.0363, 0.9912, 1.0000, 1.0105,
        0.9905, 1.0242, 1.0531, 1.0188, 1.0521, 1.0364, 1.0577, 0.9618, 1.0003,
        1.0251, 1.0066, 1.0445, 1.0450, 1.0552, 0.9205, 0.9954, 1.0325, 1.0260,
        0.9558, 1.1203, 0.9787, 1.0070, 1.0120, 1.0118, 0.9601, 0.9989, 0.9831,
        1.0124, 1.0066, 0.9893, 1.0347, 1.0476, 1.0491, 0.9976, 1.0020, 0.9617,
        0.9997, 1.0023, 0.9690, 1.0187, 1.0091, 1.0087, 1.0358, 0.9849, 0.9653,
        0.9844, 1.0535, 1.0149, 1.0400, 1.0028, 1.1048, 0.9132, 1.0449, 1.0834,
        1.0151])
##########################################################
decoder.blks.block5.addnorm1.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.0101,  0.0094, -0.0098, -0.0076,  0.0064, -0.0139,  0.0296, -0.0205,
        -0.0064,  0.0183,  0.0174, -0.0082,  0.0059, -0.0124, -0.0184,  0.0054,
         0.0379,  0.0086,  0.0164, -0.0151,  0.0118,  0.0129, -0.0057,  0.0077,
         0.0093, -0.0075, -0.0202, -0.0009, -0.0039,  0.0057, -0.0121,  0.0072,
        -0.0229,  0.0035, -0.0010, -0.0076,  0.0165,  0.0134, -0.0293, -0.0148,
         0.0058, -0.0173,  0.0239,  0.0256, -0.0111,  0.0208, -0.0021, -0.0097,
         0.0156,  0.0046,  0.0191,  0.0157,  0.0174, -0.0055,  0.0090, -0.0064,
        -0.0290,  0.0135,  0.0005, -0.0141, -0.0079, -0.0024, -0.0184,  0.0127])
##########################################################
decoder.blks.block5.attention2.W_q.weight shape: torch.Size([64, 64])
tensor([[-0.1551,  0.2055, -0.0407,  ..., -0.0006,  0.1433, -0.1742],
        [ 0.0056, -0.1726, -0.0105,  ..., -0.0659,  0.2159, -0.1902],
        [-0.0997, -0.1716,  0.1801,  ...,  0.1601,  0.1101, -0.0146],
        ...,
        [-0.0515, -0.1854,  0.2058,  ..., -0.2007,  0.1237,  0.1833],
        [-0.1148, -0.0523,  0.0491,  ..., -0.0205, -0.1707, -0.0155],
        [ 0.1960, -0.1051,  0.1813,  ..., -0.1269, -0.0937, -0.0909]])
tensor([[-0.1719,  0.1454, -0.0715,  ..., -0.0298,  0.1908, -0.1751],
        [-0.0061, -0.1758, -0.0557,  ..., -0.0726,  0.3742, -0.1916],
        [-0.0994, -0.1894,  0.1888,  ...,  0.1416,  0.0958, -0.0215],
        ...,
        [-0.0577, -0.1811,  0.2523,  ..., -0.1962,  0.0671,  0.1822],
        [-0.1142, -0.0099,  0.0290,  ..., -0.0609, -0.1329, -0.0244],
        [ 0.1822, -0.0604,  0.1278,  ..., -0.2305, -0.0301, -0.0913]])
##########################################################
decoder.blks.block5.attention2.W_k.weight shape: torch.Size([64, 64])
tensor([[ 0.1090, -0.0547,  0.0842,  ..., -0.0026, -0.1917,  0.0019],
        [ 0.2092,  0.0210, -0.1496,  ...,  0.1862, -0.2006, -0.1274],
        [-0.0166, -0.0275,  0.1401,  ..., -0.1691,  0.1591,  0.0852],
        ...,
        [-0.2136, -0.0702, -0.1556,  ..., -0.0259, -0.1054,  0.2106],
        [ 0.2034, -0.1788, -0.0422,  ...,  0.0266, -0.1093,  0.1246],
        [-0.0714,  0.0982, -0.1709,  ..., -0.1680, -0.2026, -0.1735]])
tensor([[ 0.1014, -0.0717,  0.1239,  ..., -0.0595, -0.1642, -0.0175],
        [ 0.3076,  0.0736, -0.1070,  ...,  0.1754, -0.2868, -0.1157],
        [-0.0911, -0.0341,  0.1584,  ..., -0.1625,  0.1187,  0.1093],
        ...,
        [-0.1735, -0.0911, -0.0819,  ..., -0.1221, -0.0376,  0.2702],
        [ 0.2623, -0.2140, -0.0572,  ..., -0.0250, -0.1290,  0.1227],
        [-0.0213,  0.1468, -0.1657,  ..., -0.2027, -0.2603, -0.1861]])
##########################################################
decoder.blks.block5.attention2.W_v.weight shape: torch.Size([64, 64])
tensor([[-0.0528,  0.0847, -0.0303,  ..., -0.0154,  0.0353, -0.1796],
        [-0.0577, -0.1600,  0.1239,  ...,  0.1713, -0.0724,  0.0713],
        [-0.0433, -0.1774, -0.1331,  ...,  0.0490, -0.1914, -0.1054],
        ...,
        [ 0.1965, -0.1588, -0.0659,  ...,  0.1251,  0.1888,  0.1525],
        [-0.0016,  0.1102, -0.0469,  ...,  0.1352,  0.1724,  0.1054],
        [-0.1179, -0.1319,  0.0134,  ..., -0.0947, -0.1262,  0.0677]])
tensor([[-0.0711,  0.0301,  0.0293,  ..., -0.0292,  0.0275, -0.1600],
        [-0.0867, -0.1884,  0.1023,  ...,  0.1525, -0.0689,  0.0700],
        [-0.0620, -0.1788, -0.1126,  ...,  0.0329, -0.1904, -0.0905],
        ...,
        [ 0.2054, -0.1718, -0.0397,  ...,  0.1274,  0.1878,  0.1321],
        [-0.0044,  0.1294, -0.0720,  ...,  0.1470,  0.1745,  0.0924],
        [-0.1372, -0.2146, -0.0341,  ..., -0.0899, -0.1297,  0.0250]])
##########################################################
decoder.blks.block5.attention2.W_o.weight shape: torch.Size([64, 64])
tensor([[ 0.0029, -0.1510, -0.0938,  ...,  0.2031, -0.0859,  0.0109],
        [-0.1301,  0.0337, -0.1493,  ..., -0.0356, -0.1732, -0.0802],
        [-0.0045, -0.0484, -0.0126,  ..., -0.2142,  0.1388, -0.1299],
        ...,
        [ 0.1777, -0.2075, -0.0922,  ..., -0.0772, -0.1437,  0.1545],
        [ 0.1130, -0.1638,  0.1693,  ...,  0.1544,  0.1632,  0.1406],
        [-0.0738, -0.1475, -0.2130,  ...,  0.1867,  0.0328,  0.0316]])
tensor([[-0.0036, -0.1546, -0.1169,  ...,  0.2039, -0.0925,  0.0192],
        [-0.1436, -0.0077, -0.0891,  ..., -0.0164, -0.1940, -0.0016],
        [ 0.0147, -0.0904, -0.0007,  ..., -0.2026,  0.1357, -0.1134],
        ...,
        [ 0.1666, -0.1780, -0.1193,  ..., -0.0597, -0.1366,  0.2171],
        [ 0.0879, -0.1175,  0.1245,  ...,  0.2135,  0.1624,  0.0965],
        [-0.0566, -0.1458, -0.2377,  ...,  0.1740,  0.0343,  0.1212]])
##########################################################
decoder.blks.block5.addnorm2.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([0.9856, 1.0136, 0.9972, 1.0405, 0.9690, 1.0100, 1.0092, 0.9945, 0.9912,
        0.9714, 1.0012, 1.0286, 1.0088, 1.0201, 1.0435, 1.0281, 0.9703, 0.9971,
        1.0174, 0.9949, 1.0280, 1.0410, 1.0534, 0.8973, 0.9742, 1.0287, 1.0148,
        0.9721, 1.0645, 0.9520, 1.0126, 0.9910, 1.0059, 0.9612, 0.9901, 0.9316,
        1.0132, 0.9774, 0.9722, 1.0224, 1.0299, 0.9946, 1.0086, 1.0372, 0.9600,
        1.0147, 0.9852, 0.9681, 0.9666, 0.9963, 0.9931, 1.0305, 0.9653, 0.9688,
        0.9790, 1.0210, 1.0058, 1.0254, 0.9784, 1.0701, 0.9049, 1.0223, 1.0273,
        1.0119])
##########################################################
decoder.blks.block5.addnorm2.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-4.8020e-03,  2.6994e-02, -1.0294e-02, -1.2248e-02, -4.9183e-03,
        -7.3358e-03,  1.4157e-02, -2.9388e-02, -8.1887e-03,  2.2189e-02,
         4.0895e-03,  4.9620e-03, -1.3502e-03, -1.4852e-02, -1.9577e-02,
         3.3280e-03,  3.7754e-02,  9.2840e-03,  1.3820e-02, -1.1454e-02,
         5.2728e-03,  1.1241e-02, -5.3441e-04,  4.6244e-03,  1.8127e-03,
        -4.3801e-06, -2.5005e-02,  3.2317e-03, -1.3222e-02, -3.2801e-03,
        -7.4336e-03, -8.6298e-03, -1.9633e-02, -2.9181e-03,  1.9083e-02,
        -1.7101e-02,  3.0538e-02,  1.0429e-02, -1.4107e-02, -1.0062e-02,
         2.4802e-03, -2.4026e-02,  2.1311e-02,  2.4140e-02, -6.1229e-03,
         1.6689e-02, -5.1636e-03, -1.3578e-02,  9.2483e-03,  7.7735e-03,
         2.8282e-02,  1.6230e-02,  1.4603e-02, -1.5893e-02,  5.3087e-03,
        -1.5919e-02, -3.1646e-02,  1.0710e-02, -1.3170e-03, -2.1340e-02,
        -4.8611e-03, -6.3934e-04, -6.6056e-03,  1.7720e-02])
##########################################################
decoder.blks.block5.ffn.dense1.weight shape: torch.Size([32, 64])
tensor([[ 0.2321,  0.2249,  0.2221,  ...,  0.2052, -0.1792, -0.0222],
        [-0.1090,  0.0647, -0.0720,  ...,  0.0119,  0.1093,  0.1037],
        [-0.2035, -0.0791,  0.0875,  ...,  0.1420, -0.2063, -0.0345],
        ...,
        [-0.2079,  0.0880, -0.0750,  ..., -0.1035, -0.0236,  0.2265],
        [-0.1125,  0.1993, -0.0570,  ...,  0.1797, -0.1028, -0.0998],
        [ 0.0644,  0.0866,  0.1587,  ..., -0.0187, -0.1889,  0.2133]])
tensor([[ 0.1663,  0.1895,  0.2412,  ...,  0.2675, -0.2654, -0.0338],
        [-0.0883,  0.0345, -0.0209,  ..., -0.0307,  0.1588,  0.0438],
        [-0.2353, -0.1584,  0.1063,  ...,  0.0382, -0.2452, -0.0318],
        ...,
        [-0.2570,  0.0742, -0.0923,  ..., -0.2308, -0.0503,  0.2136],
        [-0.0826,  0.1907, -0.0672,  ...,  0.1513, -0.0372, -0.0852],
        [ 0.0312,  0.0508,  0.2133,  ...,  0.0068, -0.1625,  0.1700]])
##########################################################
decoder.blks.block5.ffn.dense1.bias shape: torch.Size([32])
tensor([ 0.0685, -0.0968,  0.1033,  0.1091, -0.0774, -0.0505,  0.0045,  0.0237,
         0.0007, -0.0540, -0.0229, -0.0658,  0.0600, -0.0970,  0.0649, -0.0757,
        -0.0632, -0.0052,  0.0108, -0.0480,  0.0019,  0.0334, -0.0021, -0.0569,
         0.0764, -0.0888, -0.0084, -0.0324, -0.0331,  0.0667,  0.0784,  0.0377])
tensor([ 0.0693, -0.1463,  0.0851,  0.0863, -0.1270, -0.0525, -0.0150,  0.0269,
        -0.0143, -0.0938, -0.0332, -0.0840,  0.0777, -0.1334,  0.0736, -0.0827,
        -0.0471, -0.0256,  0.0024, -0.1239, -0.0357,  0.0154, -0.0206, -0.0779,
         0.0590, -0.1285, -0.0131, -0.0854, -0.0716,  0.0342,  0.0875,  0.0010])
##########################################################
decoder.blks.block5.ffn.dense2.weight shape: torch.Size([64, 32])
tensor([[-0.1120, -0.2024,  0.2387,  ...,  0.0813, -0.2424,  0.0303],
        [-0.1780,  0.0810,  0.0711,  ..., -0.1548, -0.1649, -0.0977],
        [ 0.0944, -0.0506,  0.1490,  ...,  0.0670, -0.1993,  0.0028],
        ...,
        [ 0.1108,  0.0191, -0.0155,  ...,  0.0470,  0.0243, -0.2270],
        [ 0.1360,  0.1473, -0.0369,  ..., -0.0020,  0.2404,  0.2251],
        [ 0.0555, -0.1105,  0.0863,  ..., -0.1505, -0.2209, -0.0962]])
tensor([[-0.1038, -0.3200,  0.1572,  ...,  0.0622, -0.2666,  0.0209],
        [-0.2388,  0.0186,  0.0739,  ..., -0.1781, -0.1627, -0.0196],
        [ 0.1530, -0.0524,  0.0963,  ...,  0.0197, -0.2130,  0.0719],
        ...,
        [ 0.1225,  0.0146, -0.1723,  ..., -0.0035,  0.0140, -0.2195],
        [ 0.1371,  0.0953, -0.0235,  ..., -0.0089,  0.2327,  0.2398],
        [ 0.1736, -0.0131,  0.1747,  ..., -0.2623, -0.1895, -0.0988]])
##########################################################
decoder.blks.block5.ffn.dense2.bias shape: torch.Size([64])
tensor([-0.0982,  0.1007, -0.0149,  0.0044,  0.0434, -0.0871,  0.1405,  0.0240,
        -0.0316, -0.0944,  0.0157, -0.0900, -0.1232, -0.0995, -0.0913, -0.0134,
        -0.1105, -0.1207, -0.0291,  0.0610,  0.1342,  0.0042,  0.0216,  0.0417,
        -0.0084,  0.1050,  0.0215, -0.1376,  0.0401, -0.0176, -0.1083, -0.1087,
         0.1432, -0.0555, -0.0811,  0.0388,  0.1401,  0.0579,  0.1240, -0.0188,
         0.0562, -0.1157, -0.1282, -0.1743,  0.0148, -0.1052, -0.0255, -0.0410,
        -0.0346,  0.1595, -0.0659, -0.0808,  0.0535,  0.1646, -0.0268,  0.0017,
         0.0462, -0.0746, -0.0635,  0.0124,  0.0317,  0.0186,  0.1283, -0.1378])
tensor([-0.1139,  0.1104, -0.0546, -0.0103,  0.0209, -0.0689,  0.1486, -0.0106,
        -0.0481, -0.0725,  0.0129, -0.0788, -0.1237, -0.0977, -0.1271, -0.0072,
        -0.0556, -0.1102, -0.0118,  0.0584,  0.1394,  0.0209,  0.0048,  0.0766,
        -0.0089,  0.1145, -0.0037, -0.1300,  0.0361, -0.0288, -0.0915, -0.0802,
         0.1092, -0.0411, -0.0795,  0.0397,  0.1390,  0.0643,  0.1085, -0.0351,
         0.0656, -0.1231, -0.1199, -0.1311,  0.0218, -0.0956, -0.0274, -0.0652,
        -0.0337,  0.1607, -0.0387, -0.0695,  0.0561,  0.1470, -0.0252, -0.0067,
         0.0173, -0.0711, -0.0558, -0.0060,  0.0349,  0.0060,  0.1215, -0.0951])
##########################################################
decoder.blks.block5.addnorm3.ln.weight shape: torch.Size([64])
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
tensor([1.3009, 1.3263, 1.2752, 1.3803, 1.2025, 1.4380, 1.4779, 1.3868, 1.2932,
        1.3997, 1.2758, 1.3895, 1.1838, 1.3224, 1.4542, 1.3606, 1.2649, 1.2304,
        1.4159, 1.2502, 1.4268, 1.3560, 1.3744, 1.3159, 1.2810, 1.3902, 1.3355,
        1.2635, 1.4680, 1.2653, 1.4694, 1.3837, 1.3753, 1.2705, 1.3148, 1.2369,
        1.3567, 1.2893, 1.1445, 1.4069, 1.4321, 1.4090, 1.3273, 1.5012, 1.1772,
        1.2805, 1.1744, 1.1878, 1.1846, 1.4265, 1.3784, 1.2658, 1.2919, 1.2631,
        1.2358, 1.4341, 1.1469, 1.4427, 1.2220, 1.4822, 1.1796, 1.3422, 1.4945,
        1.3723])
##########################################################
decoder.blks.block5.addnorm3.ln.bias shape: torch.Size([64])
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
tensor([-0.1693,  0.1810, -0.1547, -0.0244,  0.1380, -0.1987,  0.1474, -0.1015,
         0.1280,  0.0903,  0.1550, -0.1260, -0.1676, -0.1920,  0.0430,  0.1802,
         0.1812,  0.1322,  0.1613, -0.1629,  0.1712,  0.1114,  0.0054,  0.1853,
        -0.1698, -0.1377, -0.1865,  0.1897, -0.1225,  0.1353, -0.1671, -0.1610,
        -0.1424, -0.1500,  0.1407, -0.2012,  0.1974,  0.1754, -0.1651, -0.1040,
         0.1057,  0.1283,  0.1731,  0.2428, -0.1706,  0.1747, -0.1633, -0.1531,
         0.1460,  0.1902,  0.1821,  0.1678,  0.1399, -0.1292,  0.1224,  0.0564,
        -0.1557,  0.1494, -0.1466, -0.0240, -0.1499,  0.0826,  0.1202,  0.2147])
##########################################################
decoder.dense.weight shape: torch.Size([166, 64])
tensor([[-0.1322,  0.1231, -0.0689,  ...,  0.0101, -0.0977,  0.0332],
        [ 0.0109,  0.0373, -0.0683,  ...,  0.0483, -0.1351,  0.0193],
        [-0.1134, -0.1548,  0.0191,  ...,  0.0967,  0.0174,  0.1423],
        ...,
        [-0.0003, -0.1402,  0.1013,  ..., -0.1526, -0.0967,  0.0179],
        [ 0.1596,  0.0554, -0.0708,  ...,  0.0040,  0.0246,  0.1519],
        [ 0.0406,  0.0920, -0.1564,  ...,  0.0353, -0.1476, -0.1347]])
tensor([[-3.9144e-02,  2.9230e-02, -2.1226e-02,  ..., -1.6959e-02,
         -1.1530e-01, -1.3382e-01],
        [ 1.1289e-01, -7.7196e-02, -1.3961e-02,  ...,  6.1927e-03,
         -1.7347e-01, -1.2938e-01],
        [-2.1810e-04, -2.4207e-01,  8.0285e-02,  ...,  4.2247e-02,
         -3.3063e-02, -3.7731e-02],
        ...,
        [ 9.9579e-02, -2.4240e-01,  1.5805e-01,  ..., -1.8841e-01,
         -1.4065e-01, -1.8641e-01],
        [ 2.5097e-01, -4.7171e-02, -1.3696e-02,  ..., -5.4521e-02,
         -3.8058e-02,  8.3127e-03],
        [ 1.2296e-01,  4.7574e-03, -1.0944e-01,  ..., -1.4542e-02,
         -1.8957e-01, -2.6010e-01]])
##########################################################
decoder.dense.bias shape: torch.Size([166])
tensor([ 3.2727e-02, -2.4946e-02,  1.1674e-01, -5.5938e-02, -8.3086e-02,
         8.4768e-02,  2.1168e-02,  3.7586e-02,  1.0750e-01,  1.0184e-01,
         5.0488e-02, -2.1582e-02,  9.4533e-02, -3.7132e-02,  8.4294e-02,
        -2.4442e-02,  6.9129e-02,  5.8578e-02, -6.6557e-02, -6.4726e-02,
        -1.1381e-01,  1.2199e-01,  1.0919e-01, -1.0953e-01, -9.4150e-02,
        -7.0724e-02,  2.2215e-02,  9.2689e-02,  1.2079e-01, -9.5053e-02,
        -1.2658e-02,  2.0707e-02,  1.1429e-01, -1.0837e-01, -6.2373e-02,
        -9.6767e-02, -1.1843e-01, -1.1849e-01,  2.3775e-02, -8.4374e-02,
        -8.3139e-02,  1.2157e-01,  1.2086e-01, -4.6357e-02,  6.6669e-02,
        -4.2831e-02,  7.8786e-02,  5.2021e-02,  1.2638e-04, -8.4701e-02,
         9.9098e-03,  7.2725e-02,  8.3685e-05, -7.3615e-02,  1.7110e-02,
         3.2243e-02,  5.0800e-02,  1.0622e-01,  9.4221e-02,  8.6245e-02,
        -1.2061e-01,  6.9492e-02,  3.3157e-02, -4.1450e-02, -4.9679e-04,
         9.0147e-02,  3.2720e-02, -7.6813e-02, -6.3208e-02,  1.1054e-02,
         1.8766e-02, -1.0364e-01, -9.4720e-02,  1.1250e-01,  6.1240e-02,
        -8.1503e-02,  1.1641e-02,  5.8132e-02,  8.8445e-02, -7.5439e-03,
        -4.1063e-02,  9.8017e-02, -8.7088e-03,  8.2011e-02,  1.6530e-02,
         4.5812e-02, -7.6797e-02, -7.7164e-02,  1.0339e-01,  3.1471e-02,
        -8.9292e-04, -4.1387e-02, -8.2425e-02, -1.0974e-01,  7.9079e-02,
         7.0265e-02, -7.7765e-02, -2.2070e-03,  4.0269e-02,  1.7481e-02,
        -1.0134e-01,  7.8462e-02, -3.0672e-02, -3.9486e-02,  1.0940e-01,
        -7.4090e-02,  1.0116e-01, -9.2400e-02, -8.7494e-02, -3.6949e-02,
        -7.2625e-02,  6.7417e-03,  5.8281e-02,  5.3660e-02,  1.5481e-03,
         8.7889e-02,  5.5100e-02,  7.9236e-02,  1.6166e-02,  8.5724e-02,
         4.2377e-02, -5.0247e-02, -1.8402e-02,  4.1446e-02,  2.6510e-02,
         7.1319e-02,  9.3968e-03,  9.6959e-02, -9.1813e-02, -6.8855e-02,
         4.8611e-02,  4.7653e-02, -9.7374e-03, -1.0378e-01, -1.1494e-01,
        -1.1269e-01,  6.1081e-03, -6.9482e-02,  1.0536e-01, -6.3534e-02,
        -1.0501e-01,  1.1241e-01, -8.2134e-02,  4.4802e-02, -6.7119e-02,
         8.6025e-02,  2.6598e-02,  2.0437e-02,  2.8293e-02, -1.9526e-02,
        -4.8351e-02,  9.1006e-02, -9.9581e-02, -1.1004e-01,  2.0572e-02,
        -1.0634e-02, -1.0357e-01, -1.4393e-03,  3.1010e-02, -5.9502e-02,
        -3.1525e-02, -5.7752e-02, -2.2894e-02,  7.3270e-02,  8.1022e-02,
        -1.2416e-01])
tensor([-6.6342e-02, -1.2691e-01,  4.1119e-03, -5.0524e-02,  2.6452e-04,
         1.7395e-01,  8.7879e-02,  1.0118e-01,  1.6282e-01,  1.9060e-01,
         1.1441e-01,  6.5393e-02,  1.5672e-01,  2.1535e-02,  1.2993e-01,
         3.9710e-02,  9.5413e-02,  7.8698e-02, -1.4680e-02, -4.4334e-03,
        -1.3158e-01,  8.7121e-02,  9.6029e-02, -1.3942e-01, -1.7245e-01,
        -8.4834e-02, -2.2851e-03,  6.9435e-02,  3.7228e-02, -1.2697e-01,
        -5.8508e-02, -1.7729e-02,  7.3448e-02, -1.5395e-01, -1.0187e-01,
        -1.7974e-01, -1.4056e-01, -1.6980e-01, -5.7606e-02, -1.4654e-01,
        -1.3450e-01,  5.3201e-02,  5.5890e-02, -1.0865e-01, -2.0631e-03,
        -1.3754e-01,  3.5715e-02, -6.7929e-02, -9.8168e-02, -1.8320e-01,
        -9.8494e-02, -4.5630e-02, -7.0777e-02, -1.4543e-01, -8.2581e-02,
        -3.3912e-02, -5.4780e-02,  1.6514e-03, -4.9752e-03, -2.3736e-02,
        -2.0790e-01, -4.0524e-02, -9.8605e-02, -9.5386e-02, -9.4137e-02,
        -2.5458e-02, -2.9780e-02, -1.7351e-01, -1.4244e-01, -1.0137e-01,
        -8.3059e-02, -2.0465e-01, -2.1185e-01,  9.3257e-03, -4.0966e-02,
        -1.6677e-01, -9.6766e-02, -5.6067e-02, -5.4113e-03, -1.2253e-01,
        -1.5256e-01,  7.7111e-03, -1.3171e-01, -1.0662e-02, -7.7371e-02,
        -7.1020e-02, -1.7210e-01, -1.7534e-01, -1.2271e-02, -7.7397e-02,
        -1.0438e-01, -1.5899e-01, -1.6787e-01, -2.1823e-01, -4.8601e-02,
        -5.6957e-02, -1.8684e-01, -8.2338e-02, -6.5755e-02, -8.4024e-02,
        -2.0508e-01, -1.7994e-02, -1.2126e-01, -1.4796e-01, -1.6283e-04,
        -2.0098e-01,  1.8426e-02, -1.8921e-01, -1.8739e-01, -1.1704e-01,
        -1.8298e-01, -8.7138e-02, -2.6223e-02, -5.5968e-02, -9.8151e-02,
        -2.5860e-02, -4.9553e-02, -3.7564e-02, -1.1654e-01, -2.0208e-02,
        -4.8626e-02, -1.5874e-01, -1.5931e-01, -6.5687e-02, -1.2102e-01,
        -3.5883e-02, -9.4240e-02, -1.5544e-02, -1.7567e-01, -1.5950e-01,
        -4.8267e-02, -6.2269e-02, -1.0963e-01, -2.1984e-01, -2.2803e-01,
        -2.1262e-01, -1.0088e-01, -1.4699e-01, -3.0108e-02, -1.7796e-01,
        -1.8370e-01,  1.7405e-02, -1.6701e-01, -4.5444e-02, -1.7822e-01,
        -4.5886e-02, -7.0494e-02, -8.0373e-02, -7.5760e-02, -1.2093e-01,
        -1.3912e-01, -2.1186e-02, -1.9638e-01, -2.0713e-01, -1.0345e-01,
        -1.4207e-01, -2.2985e-01, -8.1968e-02, -6.3583e-02, -1.8172e-01,
        -1.2586e-01, -1.7367e-01, -1.2753e-01, -4.5851e-02, -1.2962e-02,
        -2.0617e-01])
##########################################################
{'prot_encoder.encoder.layers.2.self_attn.in_proj_bias': tensor(0.0035), 'prot_encoder.encoder.layers.1.self_attn.in_proj_bias': tensor(0.0042), 'smi_encoder.encoder.layers.1.norm2.bias': tensor(0.0047), 'smi_encoder.encoder.layers.2.self_attn.out_proj.bias': tensor(0.0047), 'prot_encoder.encoder.layers.0.self_attn.in_proj_bias': tensor(0.0047), 'smi_encoder.encoder.layers.1.self_attn.out_proj.bias': tensor(0.0048), 'cross_encoder.encoder.layers.1.self_attn.out_proj.bias': tensor(0.0048), 'cross_encoder.encoder.layers.1.norm1.bias': tensor(0.0049), 'smi_encoder.encoder.layers.2.norm1.bias': tensor(0.0049), 'cross_encoder.encoder.layers.0.self_attn.out_proj.bias': tensor(0.0049), 'cross_encoder.encoder.layers.0.norm1.bias': tensor(0.0049), 'prot_encoder.encoder.layers.1.norm2.bias': tensor(0.0049), 'smi_encoder.encoder.layers.2.norm2.bias': tensor(0.0050), 'prot_encoder.encoder.layers.2.norm2.bias': tensor(0.0050), 'smi_encoder.encoder.layers.1.norm1.bias': tensor(0.0050), 'cross_encoder.encoder.layers.0.norm2.bias': tensor(0.0051), 'prot_encoder.encoder.layers.2.linear2.bias': tensor(0.0051), 'smi_encoder.encoder.layers.1.linear2.bias': tensor(0.0051), 'prot_encoder.encoder.layers.2.self_attn.out_proj.bias': tensor(0.0052), 'prot_encoder.encoder.layers.1.self_attn.out_proj.bias': tensor(0.0052), 'prot_encoder.encoder.layers.1.norm1.bias': tensor(0.0053), 'prot_encoder.encoder.layers.2.norm1.bias': tensor(0.0053), 'cross_encoder.encoder.layers.0.linear2.bias': tensor(0.0053), 'prot_encoder.encoder.layers.1.linear2.bias': tensor(0.0054), 'prot_encoder.encoder.layers.0.norm1.bias': tensor(0.0054), 'smi_encoder.encoder.layers.0.norm2.bias': tensor(0.0055), 'prot_encoder.encoder.layers.0.self_attn.out_proj.bias': tensor(0.0055), 'prot_encoder.encoder.layers.0.norm2.bias': tensor(0.0058), 'smi_encoder.encoder.layers.0.self_attn.in_proj_bias': tensor(0.0058), 'smi_encoder.encoder.layers.2.linear2.bias': tensor(0.0059), 'smi_encoder.encoder.layers.0.linear2.bias': tensor(0.0059), 'prot_encoder.addnorm.ln.bias': tensor(0.0059), 'cross_encoder.encoder.layers.1.self_attn.in_proj_bias': tensor(0.0060), 'ffn.dense2.bias': tensor(0.0060), 'addnorm.ln.bias': tensor(0.0062), 'prot_encoder.encoder.layers.0.linear2.bias': tensor(0.0063), 'cross_encoder.encoder.layers.0.self_attn.in_proj_bias': tensor(0.0063), 'smi_encoder.encoder.layers.0.self_attn.out_proj.bias': tensor(0.0064), 'smi_encoder.encoder.layers.0.norm1.bias': tensor(0.0067), 'cross_encoder.encoder.layers.1.linear2.bias': tensor(0.0067), 'decoder.blks.block1.addnorm3.ln.bias': tensor(0.0070), 'smi_encoder.encoder.layers.2.self_attn.in_proj_bias': tensor(0.0078), 'decoder.blks.block2.addnorm1.ln.bias': tensor(0.0079), 'decoder.blks.block1.addnorm1.ln.bias': tensor(0.0082), 'smi_encoder.encoder.layers.1.self_attn.in_proj_bias': tensor(0.0082), 'decoder.blks.block4.addnorm2.ln.bias': tensor(0.0083), 'prot_encoder.ffn.dense2.bias': tensor(0.0085), 'decoder.blks.block0.addnorm2.ln.bias': tensor(0.0086), 'decoder.blks.block4.addnorm3.ln.bias': tensor(0.0087), 'decoder.blks.block1.addnorm2.ln.bias': tensor(0.0087), 'decoder.blks.block2.addnorm3.ln.bias': tensor(0.0087), 'prot_encoder.conv1d.weight': tensor(0.0089), 'decoder.blks.block3.addnorm3.ln.bias': tensor(0.0089), 'cross_encoder.encoder.layers.1.norm1.weight': tensor(0.0090), 'decoder.blks.block4.addnorm1.ln.bias': tensor(0.0091), 'decoder.blks.block3.addnorm1.ln.bias': tensor(0.0092), 'decoder.blks.block2.addnorm2.ln.bias': tensor(0.0094), 'decoder.blks.block0.addnorm3.ln.bias': tensor(0.0096), 'smi_encoder.embedding.weight': tensor(0.0096), 'prot_encoder.encoder.layers.1.linear1.bias': tensor(0.0096), 'prot_encoder.encoder.layers.1.self_attn.out_proj.weight': tensor(0.0098), 'ffn.dense1.bias': tensor(0.0098), 'decoder.blks.block3.addnorm2.ln.bias': tensor(0.0099), 'prot_encoder.encoder.layers.2.self_attn.out_proj.weight': tensor(0.0100), 'cross_encoder.encoder.layers.1.self_attn.out_proj.weight': tensor(0.0100), 'decoder.blks.block3.ffn.dense2.bias': tensor(0.0101), 'decoder.blks.block1.ffn.dense2.bias': tensor(0.0102), 'smi_encoder.encoder.layers.1.norm1.weight': tensor(0.0102), 'decoder.blks.block4.ffn.dense2.bias': tensor(0.0103), 'cross_encoder.encoder.layers.0.norm2.weight': tensor(0.0103), 'decoder.blks.block0.addnorm1.ln.bias': tensor(0.0103), 'cross_encoder.encoder.layers.0.self_attn.out_proj.weight': tensor(0.0106), 'decoder.blks.block0.ffn.dense2.bias': tensor(0.0106), 'smi_encoder.encoder.layers.1.linear1.bias': tensor(0.0106), 'prot_encoder.encoder.layers.1.self_attn.in_proj_weight': tensor(0.0111), 'prot_encoder.encoder.layers.0.linear1.bias': tensor(0.0111), 'decoder.embedding.weight': tensor(0.0112), 'smi_encoder.encoder.layers.2.linear1.bias': tensor(0.0112), 'cross_encoder.encoder.layers.0.norm1.weight': tensor(0.0113), 'smi_encoder.encoder.layers.0.norm2.weight': tensor(0.0113), 'prot_encoder.encoder.layers.2.linear1.bias': tensor(0.0114), 'prot_encoder.embedding.weight': tensor(0.0115), 'decoder.blks.block2.ffn.dense2.bias': tensor(0.0117), 'smi_encoder.encoder.layers.0.linear2.weight': tensor(0.0117), 'prot_encoder.encoder.layers.2.norm2.weight': tensor(0.0117), 'prot_encoder.encoder.layers.2.norm1.weight': tensor(0.0118), 'smi_encoder.encoder.layers.1.self_attn.out_proj.weight': tensor(0.0119), 'prot_encoder.encoder.layers.0.self_attn.out_proj.weight': tensor(0.0122), 'decoder.blks.block5.addnorm2.ln.bias': tensor(0.0124), 'smi_encoder.encoder.layers.0.norm1.weight': tensor(0.0124), 'smi_encoder.encoder.layers.2.self_attn.out_proj.weight': tensor(0.0124), 'cross_encoder.encoder.layers.0.linear1.bias': tensor(0.0125), 'decoder.blks.block5.addnorm1.ln.bias': tensor(0.0125), 'smi_encoder.encoder.layers.1.linear2.weight': tensor(0.0125), 'smi_encoder.encoder.layers.0.self_attn.in_proj_weight': tensor(0.0128), 'prot_encoder.encoder.layers.0.self_attn.in_proj_weight': tensor(0.0129), 'smi_encoder.encoder.layers.0.linear1.bias': tensor(0.0129), 'prot_encoder.encoder.layers.1.linear2.weight': tensor(0.0130), 'addnorm.ln.weight': tensor(0.0130), 'prot_encoder.encoder.layers.2.self_attn.in_proj_weight': tensor(0.0130), 'smi_encoder.encoder.layers.1.norm2.weight': tensor(0.0130), 'ffn.dense2.weight': tensor(0.0133), 'decoder.blks.block4.attention2.W_v.weight': tensor(0.0133), 'decoder.blks.block3.attention2.W_v.weight': tensor(0.0134), 'prot_encoder.encoder.layers.0.linear2.weight': tensor(0.0134), 'decoder.blks.block2.attention2.W_v.weight': tensor(0.0135), 'decoder.blks.block1.attention2.W_v.weight': tensor(0.0136), 'cross_encoder.encoder.layers.1.norm2.bias': tensor(0.0136), 'decoder.blks.block0.attention2.W_v.weight': tensor(0.0136), 'prot_encoder.encoder.layers.1.norm2.weight': tensor(0.0136), 'cross_encoder.encoder.layers.0.linear2.weight': tensor(0.0136), 'cross_encoder.encoder.layers.1.linear1.bias': tensor(0.0139), 'smi_encoder.encoder.layers.2.linear2.weight': tensor(0.0140), 'prot_encoder.encoder.layers.1.linear1.weight': tensor(0.0141), 'prot_encoder.ffn.dense1.bias': tensor(0.0141), 'prot_encoder.encoder.layers.2.linear1.weight': tensor(0.0142), 'decoder.blks.block3.attention2.W_o.weight': tensor(0.0142), 'decoder.blks.block5.ffn.dense2.bias': tensor(0.0143), 'smi_encoder.encoder.layers.0.self_attn.out_proj.weight': tensor(0.0144), 'decoder.blks.block2.attention2.W_o.weight': tensor(0.0144), 'decoder.blks.block1.addnorm2.ln.weight': tensor(0.0144), 'smi_encoder.encoder.layers.2.norm1.weight': tensor(0.0146), 'smi_encoder.encoder.layers.1.linear1.weight': tensor(0.0146), 'decoder.blks.block1.addnorm3.ln.weight': tensor(0.0146), 'cross_encoder.encoder.layers.0.self_attn.in_proj_weight': tensor(0.0149), 'decoder.blks.block0.attention2.W_o.weight': tensor(0.0149), 'cross_encoder.encoder.layers.1.linear1.weight': tensor(0.0151), 'cross_encoder.encoder.layers.0.linear1.weight': tensor(0.0152), 'cross_encoder.encoder.layers.1.linear2.weight': tensor(0.0152), 'smi_encoder.encoder.layers.0.linear1.weight': tensor(0.0154), 'ffn.dense1.weight': tensor(0.0156), 'smi_encoder.encoder.layers.1.self_attn.in_proj_weight': tensor(0.0156), 'decoder.blks.block4.attention2.W_o.weight': tensor(0.0156), 'prot_encoder.encoder.layers.0.linear1.weight': tensor(0.0157), 'prot_encoder.encoder.layers.1.norm1.weight': tensor(0.0158), 'cross_encoder.encoder.layers.1.self_attn.in_proj_weight': tensor(0.0158), 'decoder.blks.block1.attention2.W_o.weight': tensor(0.0159), 'prot_encoder.ffn.dense2.weight': tensor(0.0163), 'decoder.blks.block2.addnorm2.ln.weight': tensor(0.0167), 'decoder.blks.block5.attention2.W_v.weight': tensor(0.0167), 'smi_encoder.encoder.layers.2.norm2.weight': tensor(0.0169), 'prot_encoder.encoder.layers.2.linear2.weight': tensor(0.0170), 'smi_encoder.encoder.layers.2.linear1.weight': tensor(0.0172), 'decoder.blks.block3.addnorm2.ln.weight': tensor(0.0172), 'decoder.blks.block2.addnorm3.ln.weight': tensor(0.0173), 'decoder.blks.block0.attention1.W_k.weight': tensor(0.0174), 'smi_encoder.encoder.layers.2.self_attn.in_proj_weight': tensor(0.0175), 'decoder.blks.block0.attention1.W_q.weight': tensor(0.0179), 'decoder.blks.block0.addnorm3.ln.weight': tensor(0.0183), 'prot_encoder.ffn.dense1.weight': tensor(0.0184), 'decoder.blks.block0.attention1.W_v.weight': tensor(0.0186), 'decoder.blks.block4.ffn.dense1.bias': tensor(0.0186), 'decoder.blks.block4.addnorm2.ln.weight': tensor(0.0189), 'prot_encoder.encoder.layers.0.norm2.weight': tensor(0.0191), 'decoder.blks.block0.ffn.dense1.bias': tensor(0.0193), 'decoder.blks.block3.ffn.dense1.bias': tensor(0.0195), 'decoder.blks.block5.attention2.W_o.weight': tensor(0.0195), 'decoder.blks.block1.attention2.W_k.weight': tensor(0.0197), 'decoder.blks.block0.ffn.dense2.weight': tensor(0.0198), 'decoder.blks.block0.attention2.W_k.weight': tensor(0.0203), 'decoder.blks.block0.attention1.W_o.weight': tensor(0.0204), 'decoder.blks.block1.attention2.W_q.weight': tensor(0.0204), 'decoder.blks.block2.attention1.W_v.weight': tensor(0.0205), 'decoder.blks.block0.addnorm2.ln.weight': tensor(0.0206), 'decoder.blks.block1.ffn.dense1.bias': tensor(0.0211), 'decoder.blks.block3.attention1.W_v.weight': tensor(0.0211), 'decoder.blks.block2.attention2.W_k.weight': tensor(0.0213), 'decoder.blks.block1.attention1.W_v.weight': tensor(0.0214), 'decoder.blks.block0.attention2.W_q.weight': tensor(0.0215), 'decoder.blks.block2.attention2.W_q.weight': tensor(0.0217), 'decoder.blks.block2.ffn.dense2.weight': tensor(0.0219), 'decoder.blks.block3.ffn.dense2.weight': tensor(0.0219), 'decoder.blks.block1.attention1.W_o.weight': tensor(0.0220), 'decoder.blks.block3.attention2.W_k.weight': tensor(0.0222), 'decoder.blks.block5.attention1.W_v.weight': tensor(0.0223), 'decoder.blks.block4.attention2.W_k.weight': tensor(0.0223), 'decoder.blks.block3.attention2.W_q.weight': tensor(0.0223), 'decoder.blks.block2.attention1.W_o.weight': tensor(0.0224), 'decoder.blks.block4.attention1.W_v.weight': tensor(0.0224), 'decoder.blks.block3.addnorm3.ln.weight': tensor(0.0225), 'decoder.blks.block2.ffn.dense1.bias': tensor(0.0231), 'cross_encoder.encoder.layers.1.norm2.weight': tensor(0.0231), 'decoder.blks.block3.attention1.W_o.weight': tensor(0.0233), 'prot_encoder.conv1d.bias': tensor(0.0236), 'decoder.blks.block1.ffn.dense2.weight': tensor(0.0236), 'decoder.blks.block1.attention1.W_k.weight': tensor(0.0239), 'decoder.blks.block5.attention2.W_q.weight': tensor(0.0239), 'decoder.blks.block5.ffn.dense1.bias': tensor(0.0239), 'decoder.blks.block1.attention1.W_q.weight': tensor(0.0245), 'decoder.blks.block4.attention1.W_o.weight': tensor(0.0249), 'decoder.blks.block2.addnorm1.ln.weight': tensor(0.0253), 'decoder.blks.block5.attention2.W_k.weight': tensor(0.0253), 'decoder.blks.block5.attention1.W_o.weight': tensor(0.0256), 'decoder.blks.block4.attention2.W_q.weight': tensor(0.0258), 'decoder.blks.block5.addnorm2.ln.weight': tensor(0.0259), 'decoder.blks.block1.addnorm1.ln.weight': tensor(0.0261), 'decoder.blks.block3.ffn.dense1.weight': tensor(0.0262), 'decoder.blks.block4.addnorm1.ln.weight': tensor(0.0264), 'decoder.blks.block2.ffn.dense1.weight': tensor(0.0266), 'decoder.blks.block1.ffn.dense1.weight': tensor(0.0269), 'decoder.blks.block0.ffn.dense1.weight': tensor(0.0271), 'decoder.blks.block3.addnorm1.ln.weight': tensor(0.0273), 'decoder.blks.block2.attention1.W_q.weight': tensor(0.0273), 'decoder.blks.block4.ffn.dense2.weight': tensor(0.0278), 'decoder.blks.block3.attention1.W_k.weight': tensor(0.0278), 'decoder.blks.block2.attention1.W_k.weight': tensor(0.0278), 'decoder.blks.block4.ffn.dense1.weight': tensor(0.0282), 'decoder.blks.block3.attention1.W_q.weight': tensor(0.0283), 'decoder.blks.block4.addnorm3.ln.weight': tensor(0.0285), 'decoder.blks.block5.addnorm1.ln.weight': tensor(0.0290), 'decoder.blks.block0.addnorm1.ln.weight': tensor(0.0294), 'decoder.blks.block4.attention1.W_k.weight': tensor(0.0297), 'decoder.blks.block4.attention1.W_q.weight': tensor(0.0306), 'prot_encoder.encoder.layers.0.norm1.weight': tensor(0.0309), 'decoder.blks.block5.attention1.W_q.weight': tensor(0.0320), 'decoder.blks.block5.attention1.W_k.weight': tensor(0.0334), 'prot_encoder.addnorm.ln.weight': tensor(0.0374), 'decoder.blks.block5.ffn.dense1.weight': tensor(0.0392), 'decoder.blks.block5.ffn.dense2.weight': tensor(0.0564), 'decoder.dense.weight': tensor(0.0834), 'decoder.dense.bias': tensor(0.0898), 'decoder.blks.block5.addnorm3.ln.bias': tensor(0.1460), 'decoder.blks.block5.addnorm3.ln.weight': tensor(0.3282)}